{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Cloud-Native IoT","text":"<p>Welcome to the documentation for our Cloud-Native IoT Platform\u2014an end-to-end system designed for secure onboarding, efficient resource discovery, over-the-air updates, and task offloading across the edge\u2013cloud continuum.</p> <p>This site serves as the central hub for all documentation related to the platform's architecture, components, APIs, and integration patterns.</p>"},{"location":"index.html#highlights","title":"Highlights","text":"<ul> <li>Zero-touch secure device onboarding (DICE-based)</li> <li>Seamless OTA updates for ESP32 and Linux-class devices</li> <li>Akri-based device discovery and inventory creation</li> <li>vAccel-powered offloading to heterogeneous accelerators</li> <li>Kubernetes-native architecture (CRDs, Operators)</li> </ul>"},{"location":"index.html#target-audience","title":"Target Audience","text":"<ul> <li>Platform developers</li> <li>System integrators</li> <li>Edge/cloud orchestrator maintainers</li> <li>Embedded/IoT engineers</li> </ul> <ul> <li> <p> Get started</p> <p> Start here</p> </li> <li> <p> Components</p> <p>Browse through the system basic components</p> <p> View Components</p> </li> <li> <p> Developers</p> <p>Discover how you can contribute!</p> <p> Developer</p> </li> </ul>"},{"location":"faq.html","title":"Frequently Asked Questions","text":""},{"location":"faq.html#how-does-the-flashjob-operator-ensure-the-security-of-firmware-updates","title":"How does the FlashJob Operator ensure the security of firmware updates?","text":"<p>The FlashJob Operator prioritizes security by integrating with the Attestation Server to verify device identity using DICE certificates, ensuring only trusted devices are updated. It employs mbedTLS for encrypted communication between the FlashPod and devices, and leverages Firmware Signing to cryptographically secure firmware images. Additionally, the OTA Service and Agent monitor the process, while Akri\u2019s metadata validation prevents unauthorized access, creating a robust, end-to-end secure workflow.</p>"},{"location":"faq.html#how-can-i-use-the-filter_uuidpy-script-to-manage-device-updates","title":"How can I use the <code>filter_uuid.py</code> script to manage device updates?","text":"<p>The <code>filter_uuid.py</code> script helps you select Akri-discovered devices for firmware updates. Install Python 3.x and the <code>kubernetes</code> and <code>pyyaml</code> packages, then run the script with <code>python3 filter_uuid.py</code>. Follow prompts to filter by device type, application type, or UUID, select devices interactively, specify the firmware image, and configure batch sizes and delays for gradual rollouts. The script generates a FlashJob CR, which the Operator applies, as detailed in the tutorial.</p>"},{"location":"api/index.html","title":"Overview","text":"<p>The Cloud-Native IoT platform exposes a set of RESTful APIs designed to facilitate secure device onboarding, firmware updates, and device discovery through Akri. These endpoints are structured to support both microcontroller-class (e.g., ESP32) and Linux-class devices across the edge\u2013cloud continuum.</p> <p>This section provides a detailed look at two core API groups:</p> <ul> <li>Device API   The Device API handles the lifecycle of IoT devices within the platform. From onboarding to firmware updates, these endpoints are responsible for ensuring secure and seamless device interactions.</li> </ul>"},{"location":"api/openapi-spec.html","title":"Device API","text":"<p>Version: 0.1.0 Base path: (Device-local address, e.g., <code>http://{device-ip}</code>)</p>"},{"location":"api/openapi-spec.html#endpoints","title":"\ud83d\udccb Endpoints","text":""},{"location":"api/openapi-spec.html#get-manageinfo","title":"<code>GET /manage/info</code>","text":"<p>Summary: Get device information Description: Retrieve static information about the IoT device.</p> <p>Responses:</p> <ul> <li><code>200 OK</code>: JSON representation of the device</li> </ul> <pre><code>{\n  \"device\": \"generic-iot-device\",\n  \"application\": \"example-app\",\n  \"version\": \"1.0.0\"\n}\n</code></pre>"},{"location":"api/openapi-spec.html#get-manageonboard","title":"<code>GET /manage/onboard</code>","text":"<p>Summary: Retrieve attestation certificate Description: Obtain the device\u2019s attestation certificate in PEM format.</p> <p>Responses:</p> <ul> <li><code>200 OK</code>: PEM-encoded certificate (Content-Type: <code>application/x-pem-file</code>)</li> <li><code>500 Internal Server Error</code>: Certificate retrieval error</li> </ul> <p>Example Error:</p> <pre><code>{\n  \"error\": \"Internal error\",\n  \"details\": \"Stack trace or detailed error info\"\n}\n</code></pre>"},{"location":"api/openapi-spec.html#post-manageupdate","title":"<code>POST /manage/update</code>","text":"<p>Summary: Start OTA firmware update Description: Initiates an Over-the-Air update using the provided image and optional arguments.</p> <p>Request Body (application/json):</p> <pre><code>{\n  \"image\": \"harbor.nbfc.io/drop/temp-sensor-capture:v0.1.0\",\n  \"params\": [\"server\", \"192.168.1.100\"]\n}\n</code></pre> <p>Responses:</p> <ul> <li><code>200 OK</code>: Update initiated</li> <li><code>400 Bad Request</code>: Invalid update request</li> <li><code>500 Internal Server Error</code>: Update process failed</li> </ul> <p>Error Example:</p> <pre><code>{\n  \"error\": \"Internal error\",\n  \"details\": \"Stack trace or detailed error info\"\n}\n</code></pre>"},{"location":"api/openapi-spec.html#get-appinfo","title":"<code>GET /app/info</code>","text":"<p>Summary: Get app information Description: Retrieve static information about the deployed application on the IoT device.</p> <p>Responses:</p> <ul> <li><code>200 OK</code>: JSON representation of the app</li> </ul> <pre><code>{\n  \"device\": \"temp-sensor\",\n  \"application\": \"temp-sensor-capture\",\n  \"image\": \"harbor.nbfc.io/drop/temp-sensor-capture:v0.1.0\",\n  \"version\": \"1.0.0\"\n}\n</code></pre>"},{"location":"architecture/index.html","title":"Architecture Overview","text":"<p>Our Cloud-Native IoT Platform is designed to securely manage heterogeneous IoT devices and applications across edge and cloud environments. It combines trusted onboarding, modular &amp; secure OTA updates, dynamic discovery based on Akri, and resource offloading within a Kubernetes-native control plane.</p>"},{"location":"architecture/index.html#layers-of-the-architecture","title":"Layers of the Architecture","text":"<ul> <li>Device Layer: ESP32 and Linux-class devices capable of secure boot and attestation (via DICE).</li> <li>Edge Layer: Lightweight Kubernetes clusters or single-node runtimes (e.g., K3s, MicroK8s) managing Akri, OTA agents, and agents to provide compute off-loading capabilities to clients.</li> <li>Cloud/Orchestrator Layer: Manages policies, metadata, and orchestrates device lifecycle, offloading targets, and OTA operations.</li> </ul> <p>Figure 1 presents a high-level architecture diagram of our framework.</p> <p></p>"},{"location":"architecture/index.html#key-technologies","title":"Key Technologies","text":"<ul> <li>Akri for device discovery and Kubernetes resource mapping.</li> <li>DICE Device Identifier Composition Engine) for secure onboarding.</li> <li>vAccel for portable compute offloading.</li> <li>mbedTLS for all device-to-cloud communications.</li> <li>Custom Operators/CRDs for OTA and offloading management.</li> </ul>"},{"location":"architecture/index.html#key-components","title":"Key Components","text":"<ul> <li>Attestation Server</li> <li>OTA Service</li> <li>OTA Agent</li> <li>Discovery Endpoints</li> </ul> <p>For a component-level breakdown, see Components.</p>"},{"location":"architecture/flashjobworkflow.html","title":"FlashJob Operator Lifecycle","text":"<p>The FlashJob Operator is a key part of our Cloud-Native IoT Platform, built to automate and simplify the firmware update process for IoT devices within Kubernetes-based deployments. This guide explains how the FlashJob works.</p> <p></p> <p>The lifecycle begins when a user creates a FlashJob Custom Resource (CR) in Kubernetes, specifying the device UUID, firmware, and version. The FlashJob Controller detects this creation and initiates a reconciliation loop to align the system with the desired state. It queries Akri to validate the device UUID and retrieve essential metadata, such as HOST_ENDPOINT and DEVICE details.</p> <p>With this information, the Controller sets up a Service for external access and creates a FlashPod configured with environment variables (FIRMWARE, PATH, UUID) to handle the flashing. The FlashPod fetches the firmware from the FirmwareRepo, establishes a connection to the device via the Service IP, and initiates the OTA update.</p> <p>As the update progresses, the FlashPod monitors the process and updates its status. Upon success, the Controller marks the FlashJob CR as \"Succeeded,\" deletes the FlashPod and Service, and records the device UUID in the CompletedUUIDs list. This structured flow ensures efficient firmware management across IoT devices in a cloud-native environment.</p> <p>For the full source code, see the FlashJob Operator GitHub repository and for more details about the flashjob component see here</p>"},{"location":"architecture/onboarding.html","title":"Onboarding Workflow","text":""},{"location":"architecture/onboarding.html#required-components","title":"Required Components","text":"<ol> <li>OTA Component running on the device</li> <li>Akri Component running on the device</li> <li>DICE Attestation Server to authenticate the device credentials</li> <li>Discovery Handler to discover the device and onboard it after its verification by the Attestation Server</li> </ol>"},{"location":"architecture/onboarding.html#steps-followed","title":"Steps followed","text":"<ol> <li>Start the Attestation Server and submit the UDS of the device about to update</li> <li>The flashed ESP32 device must be equipped with the OTA Component and Akri Component</li> <li>The Discovery Handler periodically sends requests on an IP address range, reaching out the devices belonging on it</li> <li>Device will then be triggered on <code>/onboard</code> with a GET request to transmit its certificate</li> <li>The Discovery Handler (after converting it from DER to PEM format) will send it to the Attestation Server</li> <li>The Attestation Server will verify the given certificate against the available Roots stored on the Redis Database</li> <li>The Attestation Server will respond with <code>200 OK</code> on success, or another HTTP error code on failure</li> <li>On success, the Discovery handler will successfully onboard the device</li> <li>On failure, the device won't be onboarded</li> </ol>"},{"location":"architecture/onboarding.html#authentication","title":"Authentication","text":"<p>Attestation is validated using the DICE chain-of-trust, based on Google's Open-DICE. We use DICE certificates to verify the devices of our fleet. More information about our authentication model can be found here.</p>"},{"location":"architecture/onboarding.html#onboarding-devices-in-akri","title":"Onboarding devices in Akri","text":"<p>The Akri project uses Discovery Handlers to abstract the discovery logic from the Agent, thus allowing developers to provide new functionality without modifying any Akri core component. This design choice allows intervention in the discovery process by implementing a custom Discovery Handler that verifies any discovered devices before returning them to the Agent.</p> <p>More specifically, the Discovery Handler will first verify that a device is indeed present at a given IP and that it matches the desired application type. Afterwards, it will request the device to send its certificate and will forward said certificate to the Attestation Server to ensure the device is trusted.</p> <p>If this process is successful\u2014and only then\u2014will the device be onboarded into the Akri installation and the Kubernetes cluster, allowing users to interact with it via Broker pods or any other method.</p> <p></p>"},{"location":"architecture/ota-workflow.html","title":"OTA Update Workflow","text":""},{"location":"architecture/ota-workflow.html#required-components","title":"Required Components","text":"<ol> <li>OTA Component running on the device</li> <li>Akri Component running on the device</li> <li>OTA Agent to communicate with the device and transmit the binary artifact</li> <li>DICE Attestation Server to authenticate the device credentials</li> </ol>"},{"location":"architecture/ota-workflow.html#steps-followed","title":"Steps followed","text":"<ol> <li>Start the Attestation Server and submit the UDS of the device about to update</li> <li>Start the OTA Agent, providing the new firmware, Attestation server IP address and TLS credentials. See more here</li> <li>The flashed ESP32 device must be equipped with the OTA Component and Akri Component</li> <li>To initialize the process send a POST request to the device, containing OTA Agent's IP address</li> <li>Device (after notified) connects to the agent over TLS</li> <li>Device transmits its attestation certificate</li> <li>Agent connects to the Attestation Server and transmits the received attestation certificate</li> <li>The Attestation Server will verify the given certificate against the available Roots stored on the Redis Database</li> <li>The Attestation Server will respond with <code>200 OK</code> on success, or another HTTP error code on failure</li> <li>On success, the agent will read the firmware from the given path and transmit it to device</li> <li>The device verifies the signature of the received binary artifact, writes it to an available partition and reboots</li> <li>On failure, the connection will be closed by the agent and no firmware will be transmitted.</li> </ol>"},{"location":"components/index.html","title":"Cloud-native IoT Project Components Overview","text":"<p>This document provides a high-level overview of the key components that make up the Cloud-native IoT project.</p>"},{"location":"components/index.html#secure-onboarding-device-registration","title":"Secure Onboarding &amp; Device Registration","text":"<ul> <li>DICE-based Attestation server: Simple entity deployed in a secure enclave that validates DICE certificates generated from leaf devices.</li> <li>Onboarding and OTA update Service: Component that integrates with the user application and provides endpoints to propagate general and attestation information to the rest of the system.</li> <li>Enhanced Akri Discovery Handler: Facilitates dynamic discovery and inventory of IoT devices within Kubernetes clusters, based on Akri.</li> </ul>"},{"location":"components/index.html#ota-over-the-air-update-framework","title":"OTA (Over-The-Air) Update Framework","text":"<ul> <li>OTA Agent: Manages firmware fetch and provides the update endpoint for devices.</li> <li>OTA Service: Runs on devices to securely receive, verify, and apply firmware updates.</li> <li>TLS Security: Ensures encrypted communication and integrity of update payloads.</li> </ul>"},{"location":"components/index.html#cloud-native-infrastructure","title":"Cloud-Native Infrastructure","text":"<ul> <li>Kubernetes &amp; Operators: All components are deployed and managed using Kubernetes primitives, custom resource definitions (CRDs), and operators.</li> <li>Application building: All components are built and packaged using standard cloud-native tooling.</li> </ul>"},{"location":"components/akri-dh.html","title":"Secure HTTP Discovery Handler","text":""},{"location":"components/akri-dh.html#overview","title":"Overview","text":"<p>To securely integrate esp32-based devices with Akri and our project, we had to develop a custom Discovery Handler in Go. To achieve that, we developed a new Go package. You can find more about the package in the Go Akri doc. Since <code>esp32</code> devices are WiFi enabled and require connection to the internet for most use-cases, we implemented an HTTP Discovery Handler that scans a given IP range to detect which IPs belong to compatible <code>esp32</code> devices. The Discovery Handler performs a GET request for each IP in that range (at the <code>/info</code> endpoint) and verifies that the device matches a given application type, as defined in the Discovery Details of the Akri configuration.</p> <p>After that, the matching devices are also tested against our attestation server to ensure that they are indeed secure and trusted. Then, the Discovery Handler sends the list of the devices that match the desired application type and are trusted to the agent and the devices are onboarded in our Akri installation as <code>akrii</code> (Akri instances).</p>"},{"location":"components/akri-dh.html#discovery-details-parsing","title":"Discovery Details parsing","text":"<p>The Discovery Details is a single string defined when creating a new Akri Configuration. Our Discovery Handler expects this string to be a valid YAML string that will be parsed into the following Go struct:</p> <pre><code>type DiscoveryDetails struct {\n  IPStart     string `yaml:\"ipStart\"` // The first IP of the IP range to scan\n  IPEnd       string `yaml:\"ipEnd\"` // The last IP of the IP range to scan\n  Application string `yaml:\"applicationType\"` // The application type to match devices\n  Secure      bool   `yaml:\"secure\"` // Whether to ensure the devices are secure with the attestation server\n}\n</code></pre> <p>An example configuration including DiscoveryDetails:</p> <pre><code>custom:\n  configuration:\n    ...\n    discoveryDetails: |\n      ipStart: 192.168.11.36\n      ipEnd: 192.168.11.45\n      applicationType: fmnist\n      secure: true\n</code></pre>"},{"location":"components/akri-dh.html#expected-device-response","title":"Expected device response","text":"<p>The Discovery Handler expects a JSON response to the GET request that send to each IP in the given IP range. That JSON response is unmarshalled into the following Go struct. The application field is used to match the devices, while all the fields are propagated to the Akri agent if the device is properly \"discovered\".</p> <pre><code>type DeviceInfo struct {\n  Device      string `json:\"device\"`\n  Application string `json:\"application\"`\n  Version     string `json:\"version\"`\n}\n</code></pre> <p>An example esp32 device response:</p> <pre><code>$ curl http://192.168.11.131/info\n{\"device\":\"esp32c6\",\"application\":\"vanilla\",\"version\":\"0.0.0\"}\n</code></pre>"},{"location":"components/akri-dh.html#packaging-the-discovery-handler","title":"Packaging the Discovery Handler","text":"<p>In order to deploy our Discovery Handler, we need to package it in a Docker image. A sample Dockerfile can be found in the DH repo.</p> <pre><code>FROM docker.io/library/golang:1.24.2-alpine3.21 AS builder\nWORKDIR /app\nCOPY . .\nRUN go mod tidy &amp;&amp; \\\n    go mod vendor &amp;&amp; \\\n    go mod verify\n\nRUN CGO_ENABLED=0 GOOS=linux go build -ldflags \"-s -w\" -ldflags \"-extldflags '-static'\" -o discovery-handler ./cmd/secure-http-discovery-handler\n\nFROM docker.io/library/alpine:3.21\n\nCOPY --from=builder /app/discovery-handler /discovery-handler\nENTRYPOINT [\"/discovery-handler\"]\n</code></pre>"},{"location":"components/akri-dh.html#deploying-the-discovery-handler","title":"Deploying the Discovery Handler","text":"<p>After building and pushing the Discovery Handler image to a registry, we are ready to create an Akri Configuration that uses this Discovery Handler to discover compatible devices.</p>"},{"location":"components/akri-dh.html#create-akri-configuration","title":"Create Akri configuration","text":"<p>The easiest way to achieve this is by using Helm template to create the a YAML file containing all the required resources based on a minimal YAML definition file.</p> <p>In this file, we can specify the name of our Akri Configuration, which Discovery Handler we will use, the discovery details that the DH will use the perform the device discovery, as well as which Broker Pod should be deployed for every discovered device:</p> <pre><code># onboarding-config-template.yaml\n\ncontroller:\n  enabled: false\nagent:\n  enabled: false\ncleanupHook:\n  enabled: false\nrbac:\n  enabled: false\nwebhookConfiguration:\n  enabled: false\nuseLatestContainers: false\ncustom:\n  configuration:\n    enabled: true\n    name: http-range-onboard # The name of akric\n    capacity: 2\n    discoveryHandlerName: http-discovery-onboard # name of discovery handler, must be unique and matching discovery.name. will be used for socket creation\n    discoveryDetails: | # make sure this is valid YAML\n      ipStart: 192.168.11.20\n      ipEnd: 192.168.11.100\n      applicationType: initial\n      secure: true\n    brokerPod:\n      image:\n        repository: docker.io/gntouts/pause\n        tag: latest\n  discovery:\n    enabled: true\n    image:\n      repository: harbor.nbfc.io/nubificus/iot/akri-discovery-handler-go\n      tag: latest\n    name: http-discovery-onboard # name of discovery handler, must be unique and matching custom.configuration.discoveryHandlerName\n</code></pre> <p>Note: The name of the Akri configuration (<code>.custom.configuration.name</code>) must be unique. Similarly, the Discovery Handler name defined in the configuration section (<code>.custom.configuration.discoveryHandlerName</code>) and the name defined in the discovery section (<code>.custom.discovery.name</code>) must both be unique and identical. It is not possible for Discovery Handlers from different Akri Configurations to share the same name, as the name is used to create the socket that the Discovery service listens on.</p> <p>Now, let's create the actual YAML file that will be applied to Kubernetes using Helm:</p> <pre><code>helm template akri akri-helm-charts/akri -f onboarding-config-template.yaml &gt; onboarding-config.yaml\n</code></pre> <p>Finally, let's apply it to create the Akri Configuration:</p> <pre><code>kubectl apply -f ./onboarding-config.yaml\n</code></pre> <p>We should now be able to see the deployed Pods of our Discovery Handler:</p> <pre><code>$ kubectl get pods | grep http-onboard\nhttp-discovery-onboard-daemonset-8r9nl                1/1     Running   0          1m\nhttp-discovery-onboard-daemonset-d5frl                1/1     Running   0          1m\nhttp-discovery-onboard-daemonset-htlbd                1/1     Running   0          1m\n</code></pre>"},{"location":"components/akri-dh.html#delete-akri-configuration","title":"Delete Akri configuration","text":"<p>If we want to delete the Akri Configuration, we need to either use the generated YAML file:</p> <pre><code>kubectl delete -f ./onboarding-config.yaml\n</code></pre> <p>Or delete the Akri Configuration and DaemonSet manually:</p> <pre><code>kubectl delete akric http-range-onboard\nkubectl delete daemonset http-discovery-onboard-daemonset\n</code></pre>"},{"location":"components/akri-integration.html","title":"Akri Integration for Onboarding","text":"<p>We extend Akri's discovery handler mechanism to incorporate device verification before exposing devices as Kubernetes resources.</p> <p>Except for the OTA Agent, which utilizes the attestation server to verify whether an incoming connection is authorized or not, we now incorporated this rationale into the Discovery handler. Therefore, a device verification is required before exposing a device as a Kubernetes resource. This enhancement ensures that only verified devices are discoverable and managed within the cluster, strengthening the overall security and preventing unauthorized devices from being represented in Kubernetes.</p> <p></p>"},{"location":"components/attestation-server.html","title":"Attestation Server","text":"<p>The attestation server is actually an HTTP server connected to a Redis database. The database is used to hold all the available device root certificates with their key (ie the MAC address). Therefore, the database could be simply described by the following table:</p> Key Certificate MAC-1 Root Cert 1 MAC-2 Root Cert 2 ..... ...... MAC-N Root Cert N <p>Thus, whenever the attestation server receives an incoming POST request with an attestation certificate on its body, it traverses its database to check whether there is any certificate that verifies the given one. In case of verification, it responds with a <code>200 OK</code> HTTP code. Otherwise, the client will receive some error HTTP code.</p> <p>It's important to clarify that the Redis Database is an example solution, to avoid any misunderstanding about security concerns. One could simply utilize another tool to store the Root certificates of the devices.</p>"},{"location":"components/attestation-server.html#dice","title":"Dice","text":"<p>DICE certificates are digital certificates issued as part of the DICE architecture, which is a chain-of-trust framework. We use DICE certificates to verify the devices of our fleet. For each device, there is a pair of DICE certificates: the root and the attestation certificate.</p>"},{"location":"components/attestation-server.html#assumptions","title":"Assumptions","text":"<ul> <li>The device contains a Unique Device Secret coming from its Vendor, and can   only be read by the bootloader. In our case, we use the MAC, which we assume   is a UDS.</li> <li>The attestation certificate is generated by the device at early boot time   (using the UDS), and can\u2019t be generated anywhere else, since there\u2019s no   access to the UDS. In our case we generate it in application, which is not very   safe.</li> </ul>"},{"location":"components/attestation-server.html#root-certificate-public","title":"Root Certificate - Public","text":"<p>The root certificate of each device is coming from its vendor. This means that every time we get a new device, we also get its root certificate, which is unique for each board, and remains the same even if we change its firmware or its bootloader. And that\u2019s because the root certificate is generated using the Unique Device Secret. More specifically, it is generated through <code>generate_uds_cert()</code>, which receives a key as input. The key buffer comes from a Key Derivation Function (KDF), using the MAC address and a 64 bytes salt (common to host and device).</p>"},{"location":"components/attestation-server.html#device-attestation-certificate","title":"Device - Attestation Certificate","text":"<p>It is presumably generated in the device at early boot time (assumption 2). Except for the Unique Device Secret, the generator also uses the bootloader hash and the application hash. The verification process involves the transfer of the attestation certificate to the attestation server. The server has access to the corresponding (public) root certificate and verifies the Attestation Cert. against the Root (that is, confirm they are a pair). By following this process, we make sure that the board is authorized to receive a new firmware image and update. Essentially, the verification of an attestation certificate against the root can be achieved with the following command:</p> <pre><code>openssl verify -verbose -ignore_critical -CAfile root.pem attestation.pem\n</code></pre>"},{"location":"components/attestation-server.html#workflow","title":"Workflow","text":"<ol> <li>Initialize HTTP server</li> <li>Wait for upcoming connections</li> <li>For each valid POST request (containing an attestation certificate on its body):</li> <li>Retrieve the root certificates contained in the Redis Database</li> <li>Check if any Root certificate verifies the incoming Attest. certificate</li> <li>In case of success, respond with <code>200 OK</code>. Otherwise respond with an error code</li> </ol> <p>For more information, see the tutorial.</p> <p></p>"},{"location":"components/esp32-akri.html","title":"ESP32 Akri Component","text":"<p>ESP32 Component for managing the akri-related HTTP endpoints of the device. The component does not contain the handlers, only the functions to setup handlers for the akri-specific endpoints. The corresponding handler functions are contained into the <code>ota-service</code> component. Furthermore, it enables us to start (prerequisite to setup endpoint) and stop the HTTP server, as well as define handlers for generic methods and endpoints.</p>"},{"location":"components/esp32-akri.html#responsibilities","title":"Responsibilities","text":"<ul> <li>Provide functions that enable the user to set handlers for various events,   like information request, onboarding request and update request.</li> <li>Manage all the rest HTTP endpoints by letting the user set handlers for any   endpoint, start and stop the HTTP server.</li> </ul>"},{"location":"components/esp32-akri.html#deployment-notes","title":"Deployment Notes","text":"<ul> <li>Packaged as an <code>ESP-IDF</code> component.</li> </ul>"},{"location":"components/esp32-akri.html#api-reference","title":"API Reference","text":"<pre><code>int akri_server_start();\n</code></pre> <p>The function can be used to initialize an underlying HTTP server, on which later one can define handler functions for any endpoint.</p> <p>Returns: <code>ESP_OK</code> on success, an error code otherwise.</p> <pre><code>int akri_server_end();\n</code></pre> <p>Correspondingly, <code>akri_server_end()</code> can be used to stop the HTTP server.</p> <p>Returns: <code>ESP_OK</code> on success, an error code otherwise.</p> <pre><code>int akri_set_update_handler(esp_err_t (*handler)(httpd_req_t *req));\n</code></pre> <p>Define a function to handle POST requests on <code>/update</code> endpoint. Keep in mind the body of the request, which should contain an IP in the following form: \"ip: X.X.X.X\"</p> <p>Parameters:</p> <ul> <li><code>handler</code>: a pointer to the function that will handle POST requests on <code>/update</code></li> </ul> <p>Returns: <code>ESP_OK</code> on success, an error code otherwise.</p> <pre><code>int akri_set_info_handler(esp_err_t (*handler)(httpd_req_t *req));\n</code></pre> <p>Define a function to handle GET requests on <code>/info</code> endpoint.</p> <p>Parameters:</p> <ul> <li><code>handler</code>: a pointer to the function that will handle GET requests on <code>/info</code></li> </ul> <p>Returns: <code>ESP_OK</code> on success, an error code otherwise.</p> <pre><code>int akri_set_onboard_handler(esp_err_t (*handler)(httpd_req_t *req));\n</code></pre> <p>Define a function to handle GET requests on <code>/onboard</code> endpoint.</p> <p>Parameters:</p> <ul> <li><code>handler</code>: a pointer to the function that will handle GET requests on <code>/onboard</code></li> </ul> <p>Returns: <code>ESP_OK</code> on success, an error code otherwise.</p> <pre><code>int akri_set_handler_generic(const char *uri,\n                             httpd_method_t method,\n                             esp_err_t (*handler)(httpd_req_t *req));\n</code></pre> <p>The generic define-handler function: You may use it to define functions to handle any endpoint of any method.</p> <p>Parameters:</p> <ul> <li><code>uri</code>: the endpoint uri to configure</li> <li><code>method</code>: the HTTP method that will be handled. See esp-idf.</li> <li><code>handler</code>: a pointer to the function that will handle <code>method</code> requests on <code>/&lt;uri&gt;</code></li> </ul> <p>Returns: <code>ESP_OK</code> on success, an error code otherwise.</p> <p>Make sure you have connected the device on the internet previously.</p>"},{"location":"components/esp32-akri.html#endpoints","title":"Endpoints","text":"<p>The exported endpoints from esp32-akri are:</p> <ul> <li><code>/info</code></li> <li><code>/onboard</code></li> <li><code>/update</code></li> </ul>"},{"location":"components/esp32-akri.html#info","title":"<code>/info</code>","text":"<p>By sending a GET request to <code>/info</code>, one should retrieve information about the device (device type, firmware version, firmware type etc) in JSON format.</p>"},{"location":"components/esp32-akri.html#update","title":"<code>/update</code>","text":"<p>On the other side, the update should be initialized through a POST request. More specifically, the body of the request should include the IP address of the OTA agent in the form: \"ip: A.B.C.D\". The handler then will extract the IP from the request and initialize a TLS (secure) connection between the device and the Agent. If the authentication succeeds, the device will receive the new firmware.</p>"},{"location":"components/esp32-akri.html#onboard","title":"<code>/onboard</code>","text":"<p>Currently, the <code>/onboard</code> endpoint waits for GET requests, and responds with the Attestation Certificate in PEM format. The purpose of this endpoint is to enable the onboarding process of the device. Important!! However, the current state is not secure at all, since the certificate is not transferred over a TLS connection, thus it could get stolen by a malicious user with the upper goal to impersonate a trusted device. Saying that, this endpoint should probably receive POST requests, containing the IP address of an external TLS server that could communicate securely with the IoT. For installation instructions see the tutorial.</p>"},{"location":"components/esp32-akri.html#note-linux-akri","title":"Note: Linux-Akri","text":"<p>Except for ESP32 devices there's also support for OTA updates on Linux devices. Linux-Akri is an onboarding and updating system for Linux, not in terms of firmware updates, but for updating currently running containers by providing a new container image.</p>"},{"location":"components/esp32-akri.html#requirements","title":"Requirements","text":"<p>Python 3.5.2+</p>"},{"location":"components/esp32-akri.html#usage","title":"Usage","text":"<p>To run the server, please execute the following from the root directory:</p> <pre><code>pip3 install -r requirements.txt\npython3 -m openapi_server\n</code></pre> <p>To launch the integration tests, use tox:</p> <pre><code>sudo pip install tox\ntox\n</code></pre>"},{"location":"components/esp32-akri.html#running-with-docker","title":"Running with Docker","text":"<p>To run the server on a Docker container, please execute the following from the root directory:</p> <pre><code># building the image\ndocker build -t openapi_server .\n\n# starting up a container\ndocker run -p 8080:8080 openapi_server\n</code></pre>"},{"location":"components/esp32-akri.html#endpoints_1","title":"Endpoints","text":"<p>The API Specification is described below:</p> <ul> <li><code>/info</code>: a GET request on this endpoint will return useful information about   the device, like device type, version etc. For example:</li> </ul> <pre><code>$ curl 192.168.122.67/info\n{\n  \"application\": \"generic\",\n  \"device\": \"rpi5-5\",\n  \"version\": \"0.0.10\"\n}\n</code></pre> <p>Meanwhile, the device console shows:</p> <pre><code>192.168.122.67 - - [03/Jul/2025 08:14:32] \"GET /info HTTP/1.1\" 200 -\n</code></pre> <ul> <li><code>/onboard</code>: The <code>/onboard</code> endpoint returns a DICE Attestation Certificate,   used to prove the device's identity. The certificate can be verified against   an Attestation Server, like Dice-Auth.   Example:</li> </ul> <pre><code>$ curl 192.168.122.67/onboard\n-----BEGIN CERTIFICATE-----\n[...]\n-----END CERTIFICATE-----\n</code></pre> <p>Correspondingly, we see the following output on device's console:</p> <pre><code>52:54:00:24:7d:77\n192.168.122.67 - - [03/Jul/2025 08:20:20] \"GET /onboard HTTP/1.1\" 200 -\n</code></pre> <p>The first line shows the MAC address, which is used as the Unique Device Secret during certificate generation.</p> <ul> <li><code>/update</code>: The <code>/update</code> endpoint handles POST requests to switch the   currently running container image with a new one, provided in the request.   Now, there are two options to update the current container image: The non   secure and the secure. In the non-secure case, the update proceeds without   authentication. In the secure case, end-to-end device authentication is   required before the image is provided. A non-secure example, where the   container image is given directly:</li> </ul> <pre><code>$ curl -H 'Content-Type: application/json' \\\n  -d '{ \"docker_image\": \"hello-world\" }' \\\n  -X POST 192.168.122.67/update\n\"Container was initiated with the provided image!\"\n</code></pre> <p>The following messages appear on the device console:</p> <pre><code>Docker image to use:  hello-world\nDeleting the container..\nworkload\n192.168.122.67 - - [03/Jul/2025 09:21:11] \"POST /update HTTP/1.1\" 200 -\n</code></pre> <p>which means that the current container was deleted before running a new one with the given \"hello-world\" image.</p> <p>Of course, the secure case is a bit more complex. Instead of directly passing the \"docker-image\" argument in the POST request, we leave that attribute empty. However, additional arguments must be provided. The secure update process redirects <code>linux-akri</code> to a secure agent, which authenticates the device using its DICE Attestation certificate and then delivers the new container image.</p> <pre><code>export AGENT_IP=...\ncurl -H 'Content-Type: application/json' \\\n  -d '{ \"args\": [\"--ip\", \"$AGENT_IP\"], \"docker_image\" : \"\" }' \\\n  -X POST 192.168.122.67/update\n</code></pre> <p>Now the agent here is the same as the ESP32 OTA Agent, except for the different environment variable we use to define the content to be sent. Instead of defining <code>NEW_FIRMWARE_PATH</code>, as we do in ESP32 OTA updates, we now define <code>CONTAINER_IMG</code> to transmit the new image descriptor.</p> <p>After having built the agent by following the instructions of the aforementioned repository:</p> <pre><code>export CONTAINER_IMG=hello-world\nexport DICE_AUTH_URL=http://localhost:8000\nexport SERVER_KEY_PATH=crt/key.pem\nexport SERVER_CRT_PATH=crt/cert.pem\n./ota-agent\n</code></pre> <p>Furthermore, a Dice-Auth Attestation server is required to work along the Agent. See the instructions.</p> <p>The output on the device console:</p> <pre><code>Agent IP:  localhost\n52:54:00:24:7d:77\nDocker image to use:  hello-world\nDeleting the container..\nworkload\n192.168.122.67 - - [03/Jul/2025 10:15:38] \"POST /update HTTP/1.1\" 200 -\n</code></pre>"},{"location":"components/firmware-signing.html","title":"Firmware Signing","text":"<p>Firmware authenticity and integrity are essential to prevent malicious updates and bricking attacks.</p>"},{"location":"components/firmware-signing.html#signing-workflow","title":"Signing Workflow","text":"<ol> <li>Firmware is signed using an offline private key.</li> <li>OTA Service embeds signature in metadata descriptor.</li> <li>OTA Agent verifies the signature before applying the update.</li> </ol>"},{"location":"components/firmware-signing.html#cryptographic-tools","title":"Cryptographic Tools","text":"<ul> <li>ed25519 or ECDSA for digital signatures</li> <li>SHA-256 checksum for integrity verification</li> <li>mbedTLS used for TLS and crypto on-device (ESP32)</li> </ul>"},{"location":"components/firmware-signing.html#example-signing-script","title":"Example Signing Script","text":"<pre><code>openssl dgst -sha256 -sign fw-private.pem -out firmware.sig firmware.bin\n</code></pre> <pre><code>{\n  \"version\": \"1.3.2\",\n  \"signature\": \"base64:MEUCIQD...\",\n  \"checksum\": \"sha256:...\",\n  \"public_key_hint\": \"esp32_ca\"\n}\n</code></pre>"},{"location":"components/flashjob-pod.html","title":"FlashJob Pod","text":"<p>The FlashJob Pod is a custom Pod deployed by the FlashJob Operator in order to perform the OTA update of a specific ESP32 device.</p> <p>It contains two components:</p> <ul> <li>the esp32-flashjob   component</li> <li>the ota-agent</li> </ul>"},{"location":"components/flashjob-pod.html#esp32-flashjob","title":"esp32-flashjob","text":"<p>The <code>esp32-flashjob</code> component is responsible for downloading and extracting the firmware from an OCI image registry, setting up the environment and executing the ota-agent.</p>"},{"location":"components/flashjob-pod.html#platform-specific-oci-images","title":"Platform-specific OCI images","text":"<p>We take advantage of multi-platform OCI manifest to help us build and distribute firmware for a number of supported devices and platforms (eg <code>esp32</code>, <code>esp32s2</code>, <code>esp32s3</code> and more).</p> <p>Using our automated build workflow we are able to build and package firmware built for each device type under a single OCI manifest.</p> <p>That way we can have the same version of a firmware built and packaged under the same OCI image tag:</p> <pre><code>$ docker buildx imagetools inspect harbor.nbfc.io/cloud-iot/nubificus/fmnist-esp-ota:resnet-4.4.4-ESP32_KEY3\nName:      harbor.nbfc.io/cloud-iot/nubificus/fmnist-esp-ota:resnet-4.4.4-ESP32_KEY3\nMediaType: application/vnd.docker.distribution.manifest.list.v2+json\nDigest:    sha256:fee40c0d537d1ac83ef003784db3ec586be25f618f5717dc4a482d558310d9d7\n\nManifests:\n  Name:      harbor.nbfc.io/cloud-iot/nubificus/fmnist-esp-ota:resnet-4.4.4-ESP32_KEY3@sha256:1a567013c7245a9cfe44b4015ef3fd805713fbf6017026d907b699c80f7c012f\n  MediaType: application/vnd.docker.distribution.manifest.v2+json\n  Platform:  custom/esp32s2r2\n\n  Name:      harbor.nbfc.io/cloud-iot/nubificus/fmnist-esp-ota:resnet-4.4.4-ESP32_KEY3@sha256:f4040645c64786b86fc5b5f7d90703d071126093d3311329acf01492492d599b\n  MediaType: application/vnd.docker.distribution.manifest.v2+json\n  Platform:  custom/esp32s3\n\n  Name:      harbor.nbfc.io/cloud-iot/nubificus/fmnist-esp-ota:resnet-4.4.4-ESP32_KEY3@sha256:a082451cc409a41e601ce08213eee1a817952a612394a08820979ac567dd0273\n  MediaType: application/vnd.docker.distribution.manifest.v2+json\n  Platform:  custom/esp32s3r8\n</code></pre>"},{"location":"components/flashjob-pod.html#esp32-flashjob-workflow","title":"esp32-flashjob workflow","text":"<p>The lifecycle of the <code>esp32-flashjob</code> is the following:</p> <ul> <li>spawns and loads any information for the device and the OTA update from the   environment</li> <li>downloads and extracts the firmware package in the OCI image based on the   requested platform</li> <li>sends a request to the esp32 device to enable OTA flash mode</li> <li>executes the ota-agent capturing all logs</li> </ul>"},{"location":"components/flashjob-pod.html#environment-variables","title":"Environment variables","text":"<p>In order to properly download the firmware and setup the environment for ota-agent with the correct parameters, <code>eps32-flashjob</code> requires the following environment variables to be set by the flashjob operator or Akri:</p> <ul> <li><code>DEVICE</code>: The device type (eg esp32s3/esp32s2)</li> <li><code>HOST</code> or <code>HOST_ENDPOINT_*</code>: The IP address of the device</li> <li><code>FIRMWARE</code>: The OCI image with the tag</li> <li><code>DICE_AUTH_SERVICE_SERVICE_HOST</code>: The IP address of the attestation server</li> </ul>"},{"location":"components/flashjob.html","title":"Flashjob Operator","text":"<p>The FlashJob Operator is a Kubernetes operator designed to automate the process of flashing firmware to devices using Akri instances. It manages the lifecycle of FlashJob custom resources, which define the parameters for firmware updates, and orchestrates the necessary Kubernetes resources such as Pods and Services to perform the flashing operations.</p> <p>FlashJob is composed of a CRD, a controller, and CR. Below, each of these components is described in detail.</p>"},{"location":"components/flashjob.html#custom-resource-definition-crd","title":"Custom Resource Definition (CRD)","text":"<p>The FlashJob CRD defines the schema for the custom resource managed by the operator. It is located at <code>config/crd/bases/application.flashjob.nbfc.io_flashjobs.yaml</code>.</p>"},{"location":"components/flashjob.html#spec","title":"Spec","text":"<ul> <li>UUID: Unique identifier for the device.</li> <li>Firmware: The firmware image to be flashed.</li> <li>Version: The version of the firmware.</li> <li>HostEndpoint: The endpoint of the host where the device is connected.</li> <li>Device: The type of device (e.g., <code>esp32s2</code>).</li> <li>ApplicationType: The type of application (e.g., <code>thermo</code>).</li> <li>ExternalIP: The external IP address of the service.</li> <li>FlashjobPodImage: The container image used from the flash pod.</li> </ul>"},{"location":"components/flashjob.html#status","title":"Status","text":"<ul> <li>Conditions: A list of conditions representing the current state of the FlashJob.</li> <li>Message: A human-readable message describing the current state.</li> <li>HostEndpoint: The endpoint of the host where the device is connected.</li> <li>Phase: Current phase (InProgress, Completed, Failed).</li> <li>CompletedUUIDs:List of UUIDs for devices that have completed flashing</li> </ul>"},{"location":"components/flashjob.html#flashjob-controller","title":"FlashJob Controller","text":"<p>The controller, implemented in <code>internal/controller/flashjob_controller.go</code>, manages the lifecycle of FlashJob resources through a reconciliation loop. It ensures the desired state specified in the FlashJob resource is achieved by handling the creation, updating, and deletion of associated Pods and Services.</p>"},{"location":"components/flashjob.html#key-functions","title":"Key Functions","text":"<ul> <li> <p>Reconcile:</p> </li> <li> <p>Reconciliation Loop</p> </li> <li>The main reconciliation loop that handles the creation and updating of FlashJob resources.</li> <li>Ensures that the desired state (defined in the <code>FlashJobSpec</code>) matches the observed state.</li> <li> <p>Manages the lifecycle of associated Pods and Services.</p> </li> <li> <p>getAkriInstanceDetails</p> </li> <li> <p>Retrieves details about the Akri instance associated with the device UUID.</p> </li> <li> <p>handleFlashingPod</p> </li> <li> <p>Manages the creation and updating of the flashing Pod.</p> </li> <li> <p>Creates a Pod using the <code>FlashjobPodImage</code> and configures it with environment variables such as <code>FIRMWARE</code>, <code>UUID</code>, <code>HOST_ENDPOINT</code>, and <code>DEVICE</code>.</p> </li> <li> <p>createService</p> </li> <li> <p>Creates a <code>LoadBalancer</code> Service per Pod with a unique external IP.</p> </li> <li> <p>waitForServiceIP</p> </li> <li> <p>Waits for the Service to acquire an external IP.</p> </li> <li> <p>Updates the <code>FlashJob</code> resource with the external IP once it is available.</p> </li> <li> <p>updateFlashJobStatus</p> </li> <li> <p>Updates the <code>FlashJob</code> status based on Pod phase and deletes completed resources.</p> </li> <li> <p>handleDeletion</p> </li> <li>Handles the deletion of <code>FlashJob</code> resources.</li> <li>Cleans up associated resources such as Pods and Services.</li> <li>Removes the finalizer to allow the resource to be deleted from the cluster.</li> </ul>"},{"location":"components/flashjob.html#example-flashjob-resource","title":"Example FlashJob Resource","text":"<p>Below is an example FlashJob resource definition, located at <code>config/samples/application_v1alpha1_flashjob.yaml</code>:</p> <pre><code>apiVersion: application.flashjob.nbfc.io/v1alpha1\nkind: FlashJob\nmetadata:\n  name: flashjob\n  namespace: default\nspec:\n  uuid:\n    - d95c7c2d-7dc5-427b-9bf7-51a5d299c99e\n    - 44606d10-7c29-4098-9d6a-dc16f95090d1\n  device: esp32\n  hostEndpoint:\n  firmware: harbor.nbfc.io/nubificus/esp32:x.x.xxxxxxx\n  version: 0.2.0\n  applicationType: thermo\n  externalIP:\n  flashjobPodImage: harbor.nbfc.io/nubificus/iot/esp32-sota:xxx.x-debug\n</code></pre>"},{"location":"components/flashjob.html#fields","title":"Fields","text":"<ul> <li> <p>uuid: The unique identifier for the device.</p> </li> <li> <p>device: The type of device (e.g., esp32).</p> </li> <li> <p>firmware: The firmware image to be flashed.</p> </li> <li> <p>version: The version of the firmware.</p> </li> <li> <p>applicationType: The type of application (e.g., thermo).</p> </li> <li> <p>flashjobPodImage: The container image used from the pod.</p> </li> </ul>"},{"location":"components/flashjob.html#how-it-works","title":"How It Works","text":"<p>For a detailed step-by-step explanation of the FlashJob Operator workflow, including all involved components and lifecycle diagrams, see FlashJob Operator Workflow.</p> <p>For implementation details and the full source code, see the FlashJob Operator GitHub repository.</p>"},{"location":"components/go-akri.html","title":"Akri Discovery Handler package for Go","text":""},{"location":"components/go-akri.html#overview","title":"Overview","text":"<p>As stated in Akri documentation, a Discovery Handler is anything that implements the DiscoveryHandler service and Registration client defined in the Akri's discovery gRPC proto file. To enable the discovery of resources (aka devices), we need to implement a Discovery Handler (DH), which performs the actual discovery on behalf of the Agent.</p> <p>The Discovery Handler component has the following lifecycle:</p> <ul> <li>Register with the agent   Upon starting, creates a Registration client and registers itself   with the agent</li> <li>Start DiscoveryHandler service   After registering, creates a DiscoveryHandler service and listens   for Discovery requests</li> <li>Perform discovery   Upon receiving a Discovery request from the agent, parses the Discovery details,   performs the relevant discovery based on said details and returns   a streaming Response containing discovered devices. This is then repeated in a loop   to ensure that the Akri agent is updated with the latest devices.</li> </ul> <p>Akri provides a Discovery Handler template as well as a walk-through on how to implement a custom Discovery Handler. This is very helpful if you are looking to build a Discovery Handler in Rust.</p> <p>To develop a custom Discovery Handler in Go, we created a new Go package (similar to Akri's template) that streamlines the Discovery Handler's lifecycle. This approach requires users to only define the custom device discovery logic and discovery details parsing.</p>"},{"location":"components/go-akri.html#usage","title":"Usage","text":"<p>The only logic we need to implement is the actual discovery process. The rest is taken care of by the package.</p>"},{"location":"components/go-akri.html#discovery-function","title":"Discovery Function","text":"<p>The Discovery logic must be implemented in a <code>DiscoverFunc</code> as shown below and must be passed to a new DiscoveryApp instance.</p> <pre><code>type DiscoverFunc func(string) ([]*pb.Device, error)\n</code></pre> <p>The input string is the raw discovery details. The developer is responsible to parse them (and set them at deploy time). This function should return a list containing the discovered devices and an error, if any occurred.</p> <p>A sample discovery function can be found in the go-akri repo:</p> <pre><code>func discovery(_ string) ([]*pb.Device, error) {\n    device := &amp;pb.Device{\n        Id: \"dummy-device\",\n        Properties: map[string]string{\n            \"AKRI_HTTP\":        \"http\",\n            \"VERSION\":          \"0.0.1\",\n        },\n        Mounts:      []*pb.Mount{},\n        DeviceSpecs: []*pb.DeviceSpec{},\n    }\n    devices := []*pb.Device{device}\n    return devices, nil\n}\n</code></pre>"},{"location":"components/go-akri.html#running-the-app","title":"Running the App","text":"<p>To run the app, we need to define a minimal new DiscoveryApp instance, configure it with the desired discovery function and options and run it:</p> <pre><code>package main\n\nimport (\n    akri \"github.com/nubificus/go-akri/pkg/discovery-handler\"\n    \"github.com/nubificus/go-akri/pkg/pb\"\n)\n\nfunc discovery(_ string) ([]*pb.Device, error) {\n    return nil, nil\n}\n\nfunc main() {\n    app := akri.NewApp(discovery, akri.WithLogLevel(akri.DebugLevel))\n    app.Run()\n}\n</code></pre>"},{"location":"components/go-akri.html#configuration-options","title":"Configuration options","text":"<p>The available configuration options are the following:</p>"},{"location":"components/go-akri.html#withregisterretries","title":"WithRegisterRetries","text":"<p><code>WithRegisterRetries</code> sets the amount of retries for registering the discovery handler with the Akri agent. (Default is 10)</p>"},{"location":"components/go-akri.html#withgrpcshutdowndelay","title":"WithgRPCShutdownDelay","text":"<p><code>WithgRPCShutdownDelay</code> sets the forced shutdown delay for the gRPC server. Normally the gRPC server will shutdown gracefully, but if that takes longer than the forcedGRPCShutdownDelay, the server will stop immediately. (Default is 5 seconds)</p>"},{"location":"components/go-akri.html#withdiscoversleep","title":"WithDiscoverSleep","text":"<p><code>WithDiscoverSleep</code> sets the sleep duration between discovery scans. (Default is 30 seconds)</p>"},{"location":"components/go-akri.html#withloglevel","title":"WithLogLevel","text":"<p><code>WithLogLevel</code> sets the log level for the discovery handler app. (Default is INFO)</p>"},{"location":"components/go-akri.html#withshared","title":"WithShared","text":"<p><code>WithShared</code> sets whether the discovered devices could be used by multiple nodes or can only be ever be discovered by a single node. (Default is false)</p>"},{"location":"components/go-akri.html#grpc-code-generation","title":"gRPC code generation","text":"<p>Note: If you are not intending to dig deeper into the package internals (eg. to bring the package up to date with the latest Akri release the package), feel free to skip this section.</p> <p>The first step to build or update this package is to generate the gRPC Client/Service code in Go based on the Akri proto file. The easiest way to achieve this is by using our protobuf generator tool, which is packaged in a Docker image.</p> <p>You can list the latest Akri tags:</p> <pre><code>$ docker run --rm harbor.nbfc.io/nubificus/akri-protobuf:latest --list\n\ud83d\udce6 Latest tags (sorted, limited to 5):\nv0.13.8\nv0.12.20\nv0.12.9\nv0.10.4\nv0.8.23\n</code></pre> <p>You can generate the Go code under <code>/pkg/pb</code> from a specific Akri tag:</p> <pre><code>$ mkdir -p $PWD/pkg/pb\n$ docker run --rm --user $(id -u):$(id -g) -v $PWD/pkg/pb:/out harbor.nbfc.io/nubificus/akri-protobuf:latest v0.12.20\nAkri target tag: v0.12.20\nDownloading protobuf file from https://raw.githubusercontent.com/project-akri/akri/v0.12.20/discovery-utils/proto/discovery.proto\nModifying protobuf file...\nGenerating Go code from protobuf file...\nGo code generated successfully\n</code></pre> <p>Or you can use the latest release by omitting the tag parameter:</p> <pre><code>$ mkdir -p $PWD/pkg/pb\n$ docker run --rm --user $(id -u):$(id -g) -v $PWD/pkg/pb:/out harbor.nbfc.io/nubificus/akri-protobuf:latest\nWarning: No target tag provided.\nUsing latest tag as default.\nAkri target tag: v0.13.8\nDownloading protobuf file from https://raw.githubusercontent.com/project-akri/akri/v0.13.8/discovery-utils/proto/discovery.proto\nModifying protobuf file...\nGenerating Go code from protobuf file...\nGo code generated successfully\n</code></pre>"},{"location":"components/mbedtls.html","title":"mbedTLS","text":""},{"location":"components/ota-agent.html","title":"OTA Agent","text":"<p>The OTA agent is responsible for communicating with the device and for authenticating it. Actually, the program operates as a TLS server (thus, the communication is secure) and waits for an upcoming connection from the microcontroller that has been requested to update its firmware. As being described in Figures 1 and 2, when it's about to update, the microcontroller will receive a POST request to its <code>/update</code> endpoint. The request will contain an IP address on its body, like <code>ip: A.B.C.D</code>. This IP belongs to the agent, which should have been executed earlier. The agent requires the following arguments to run, which are given as environment variables:</p> <ul> <li><code>NEW_FIRMWARE_PATH</code>: The path to the firmware that will be sent to the   microcontroller (on success)</li> <li><code>DICE_AUTH_URL</code>: The URL to connect to Dice-Auth HTTP server, to authenticate   the connected microcontroller. Under the hood, the agent will send the   received Attestation Certificate, while Dice-Auth will verify it against the   saved Root certificates.</li> <li><code>SERVER_CRT_PATH</code>: The certificate to be used by the TLS server.</li> <li><code>SERVER_KEY_PATH</code>: The private key to be used by the TLS server.</li> </ul> <p>The OTA Agent runs on each device and manages update retrieval and installation in a secure and verifiable manner.</p>"},{"location":"components/ota-agent.html#responsibilities","title":"Responsibilities","text":"<ul> <li>Verify the connected device against an attestation server</li> <li>On success, transmit the firmware to leaf device</li> <li>On failure, close the connection</li> </ul>"},{"location":"components/ota-agent.html#configuration","title":"Configuration","text":"<ul> <li><code>DICE_AUTH_URL</code>: URL of the attestation server</li> <li><code>NEW_FIRMWARE_PATH</code>: Where to find the new firmware to be used in OTA update</li> <li><code>SERVER_CRT_PATH</code> &amp; <code>SERVER_KEY_PATH</code>: TLS certificate and private key For secure communication</li> </ul>"},{"location":"components/ota-agent.html#example-flow","title":"Example Flow","text":"<ol> <li>Agent starts a TLS server (<code>SERVER_CRT_PATH</code> &amp; <code>SERVER_KEY_PATH</code>)</li> <li>Device (after notified) connects to the agent</li> <li>Device transmits its attestation certificate</li> <li>Agent verifies device's identity against the attestation server (<code>DICE_AUTH_URL</code>).</li> <li>On success, the agent will read the firmware from <code>NEW_FIRMWARE_PATH</code> and will send it to device</li> <li>The device applies the update after receiving the entire firmware image and reboots</li> <li>On failure, the connection will be closed by the agent and no firmware will be transmitted.</li> </ol> <p>Updates are only allowed for devices that passed DICE-based onboarding. Finally, ota-agent is not a standalone unit in the overall system layout, but rather a component used by the Flash-Job. However, one could use it as a standalone unit too. For building and running instructions see the tutorial.</p> <p> </p>"},{"location":"components/ota-service.html","title":"ESP32 OTA Component","text":"<p>OTA Service is an ESP32 Component for performing Over the Air updates. The component contains only the handlers. To setup the functions as akri endpoints handlers, use the ESP32 Akri Component. The component supports secure OTA updates for the ESP32 devices when used along with rest Cloud-Native-IoT subsystems. Actually, this component provides a function to run when a OTA HTTP request reaches the device. In this case, <code>ota-service</code> will first generate a device certificate (DICE) to authorize the board during the upcoming communication. The board is also responsible to initiate a TLS connection with the OTA Agent, whose IP address was previously extracted from the HTTP POST request. In case of successful authentication, the agent will transmit the new firmware binary artifact to the device. Finally, after writing the firmware to the first available OTA partition, <code>ota-service</code> will verify that the artifact is properly signed with the right private key, and reboot.</p>"},{"location":"components/ota-service.html#responsibilities","title":"Responsibilities","text":"<ul> <li>Prepare the board for an OTA firmware update</li> <li>Provide the handler functions to perform the OTA update</li> <li>Prove device's identity</li> <li>Receive new firmware from the agent</li> <li>Verify binary artifact's integrity</li> <li>Handle errors if the OTA update is incomplete</li> <li>Update the board's firmware</li> </ul>"},{"location":"components/ota-service.html#endpoints","title":"Endpoints","text":"<ul> <li>Setup by ESP32-Akri.</li> </ul>"},{"location":"components/ota-service.html#deployment-notes","title":"Deployment Notes","text":"<ul> <li>Packaged as an <code>ESP-IDF</code> component.</li> </ul> <p>See the tutorial</p>"},{"location":"components/ota-service.html#workflow","title":"Workflow","text":"<p>An example workflow is shown below:</p> <ol> <li>Extract Agent's IP address from the POST request</li> <li>Generate a DICE certificate to prove board's identity</li> <li>Initiate a secure TLS connection with the Agent</li> <li>Transmit the certificate</li> <li>In case of successful verificate, receive the new firmware</li> <li>Write the binary artifact on the first available partition</li> <li>Verify new firmware is valid and signed</li> <li>Reboot to update</li> </ol> <p></p>"},{"location":"components/ota-service.html#api-reference","title":"API Reference","text":"<pre><code>esp_err_t ota_request_handler(httpd_req_t *req);\n</code></pre> <p>This function can be passed as an argument in <code>akri_set_update_handler()</code> so that it (only) runs when we receive a POST request at <code>/update</code> endpoint. The function will perform all those steps described above.</p> <p>Parameters:</p> <ul> <li><code>req</code>: A pointer to the handle-object of the HTTP request. See here.</li> </ul> <p>Returns: <code>ESP_OK</code> on success, otherwise an error code.</p>"},{"location":"developer/index.html","title":"Overview","text":"<p>The Developer section is intended for contributors and advanced users who want to extend, customize, or integrate with the Cloud-Native IoT platform. It provides the internal architecture details, code structure, and tooling guidance necessary to build and maintain platform components.</p> <p>Whether you're developing new plugins, modifying the onboarding logic, or integrating with third-party systems, this guide will help you understand how the platform works under the hood.</p> <p>What you'll find here:</p> <ul> <li>Application bootstrap: How to structure and code in the logic for your application.</li> <li>Application building: How to build and package ESP32 applications using our automated CI/CD workflows.</li> <li>Firmware packaging: How the workflows package app binaries for multiple ESP32 targets as OCI images and manifests.</li> <li>Initial flash packaging: How the workflows prepare multi-arch OCI manifests for flashing devices for the first time.</li> <li>High-level Architecture as a basis to extend the platform: Guidelines for adding new device types, API endpoints, or custom discovery mechanisms.</li> </ul> <p>This section is the go-to resource for anyone looking to contribute to the platform or build custom integrations atop its core functionality.</p>"},{"location":"developer/applications.html","title":"Application development","text":""},{"location":"developer/applications.html#introduction","title":"Introduction","text":"<p>Developing IoT applications using ESP32 typically begins with flashing firmware to a single device via USB during development. This is suitable for initial prototyping or testing.</p> <pre><code>idf.py build\nidf.py --port /dev/ttyUSB0 flash monitor\n</code></pre> <p>However, as systems scale, this manual approach becomes infeasible and introduces operational challenges.</p>"},{"location":"developer/applications.html#the-challenge-of-scalability","title":"The Challenge of Scalability","text":"<p>Consider an application such as a smart air quality sensor deployed across a whole city. You might start with a handful of devices but eventually grow to manage hundreds or thousands.</p> <p>Challenges emerge when:</p> <ul> <li>A critical firmware update needs to be pushed to all devices.</li> <li>You want centralized monitoring and lifecycle management of each sensor node.</li> </ul> <p>In such cases, physically accessing and flashing each device is impractical and unscalable.</p>"},{"location":"developer/applications.html#our-approach-to-scalable-management","title":"Our Approach to Scalable Management","text":"<p>To address these limitations, we have developed the following two components as part of our Cloud-Native IoT Platform, which users can integrate into their ESP32 applications:</p> Component Purpose <code>esp32-akri</code> Enables ESP32 devices to register with Kubernetes clusters via Akri, facilitating automated discovery and management. <code>ota-service</code> Provides secure over-the-air (OTA) firmware updates for ESP32, eliminating the need for manual reflashing. <p>Together, they enable ESP32 devices to become manageable, cloud-native compute nodes.</p>"},{"location":"developer/applications.html#integration-guide","title":"Integration Guide","text":""},{"location":"developer/applications.html#1-setting-up-the-esp32-project-structure","title":"1. Setting Up the ESP32 Project Structure","text":"<p>Assume your project has the following structure:</p> <pre><code>your-project/\n\u251c\u2500\u2500 components/\n\u251c\u2500\u2500 main/\n\u2502   \u251c\u2500\u2500 main.cc\n\u2502   \u2514\u2500\u2500 CMakeLists.txt\n\u251c\u2500\u2500 CMakeLists.txt\n\u2514\u2500\u2500 ...\n</code></pre> <p>Clone the required components:</p> <pre><code>mkdir -p components &amp;&amp; cd components\ngit clone https://github.com/nubificus/ota-service\ngit clone https://github.com/nubificus/esp32-akri\n</code></pre>"},{"location":"developer/applications.html#2-registering-the-components-in-cmake","title":"2. Registering the Components in CMake","text":"<p>Modify <code>main/CMakeLists.txt</code>:</p> <pre><code>idf_component_register(SRCS \"main.cc\"\n                       INCLUDE_DIRS \".\"\n                       REQUIRES esp32-akri ota-service)\n</code></pre>"},{"location":"developer/applications.html#3-including-required-headers","title":"3. Including Required Headers","text":"<p>In <code>main.cc</code>:</p> <pre><code>extern \"C\" {\n  #include \"esp32-akri.h\"\n  #include \"ota-service.h\"\n}\n</code></pre>"},{"location":"developer/applications.html#4-providing-device-metadata-to-the-system","title":"4. Providing Device Metadata to the System","text":"<p>This function provides metadata for Akri and OTA usage:</p> <pre><code>esp_err_t info_get_handler(httpd_req_t *req)\n{\n    char json_response[128];\n    snprintf(json_response, sizeof(json_response),\n             \"{\"device\":\"%s\",\"application\":\"%s\",\"version\":\"%s\"}\",\n             DEVICE_TYPE, APPLICATION_TYPE, FIRMWARE_VERSION);\n    httpd_resp_set_type(req, \"application/json\");\n    httpd_resp_send(req, json_response, strlen(json_response));\n    return ESP_OK;\n}\n</code></pre>"},{"location":"developer/applications.html#5-handling-configuration-via-root-cmake","title":"5. Handling Configuration via Root CMake","text":"<p>Those two components require the following environment variables:</p> <ul> <li><code>FIRMWARE_VERSION</code>: A unique version identifier for the application you are working on.</li> <li><code>DEVICE_TYPE</code>: The specific ESP32 target for which you will build this application.</li> <li><code>APPLICATION_TYPE</code>: The type of application you are developing (e.g. image_classification, etc.).</li> <li><code>OTA_SECURE</code>: Set this variable when you want to use secure OTA update services.</li> </ul> <p>Edit your root <code>CMakeLists.txt</code> to handle environment configuration by adding the code below:</p> <pre><code>if(NOT DEFINED ENV{FIRMWARE_VERSION})\n    add_compile_definitions(FIRMWARE_VERSION=\"0.1.0\")\nelse()\n    add_compile_definitions(FIRMWARE_VERSION=\\\"$ENV{FIRMWARE_VERSION}\\\")\nendif()\n\nif(NOT DEFINED ENV{DEVICE_TYPE})\n    add_compile_definitions(DEVICE_TYPE=\"esp32\")\nelse()\n    add_compile_definitions(DEVICE_TYPE=\\\"$ENV{DEVICE_TYPE}\\\")\nendif()\n\nif(NOT DEFINED ENV{APPLICATION_TYPE})\n    add_compile_definitions(APPLICATION_TYPE=\"generic\")\nelse()\n    add_compile_definitions(APPLICATION_TYPE=\\\"$ENV{APPLICATION_TYPE}\\\")\nendif()\n\nif(DEFINED ENV{OTA_SECURE})\n    add_compile_definitions(OTA_SECURE=1)\nendif()\n</code></pre>"},{"location":"developer/applications.html#6-initializing-akri-and-ota-in-the-application","title":"6. Initializing Akri and OTA in the Application","text":"<p>In <code>app_main()</code>:</p> <pre><code>void app_main(void)\n{\n    int ret;\n\n    ret = akri_server_start();\n    if (ret) {\n        ESP_LOGE(\"main\", \"Cannot start Akri server\");\n        abort();\n    }\n\n    ret = akri_set_info_handler(info_get_handler);\n    if (ret) {\n        ESP_LOGE(\"main\", \"Cannot set info handler\");\n        abort();\n    }\n}\n</code></pre>"},{"location":"developer/applications.html#7-setting-environment-variables-before-build","title":"7. Setting Environment Variables Before Build","text":"<p>Before building, export the following:</p> <pre><code>export FIRMWARE_VERSION=\"0.0.1\"\nexport DEVICE_TYPE=\"esp32s3\"\nexport APPLICATION_TYPE=\"thermo\"\nexport OTA_SECURE=1\n</code></pre>"},{"location":"developer/applications.html#8-building-and-flashing-the-application","title":"8. Building and Flashing the Application","text":"<pre><code>idf.py build\nidf.py --port /dev/ttyUSB0 flash monitor\n</code></pre> <p>Once deployed, your device will be:</p> <ul> <li>Discoverable through Akri.</li> <li>OTA-ready for firmware updates.</li> <li>Exposing device metadata via HTTP.</li> </ul>"},{"location":"developer/applications.html#conclusion","title":"Conclusion","text":"<p>Integrating Akri and OTA-Service into your ESP32 firmware empowers you with production-grade capabilities, including:</p> <ul> <li>Scalable remote firmware management.</li> <li>Dynamic discovery and orchestration through Kubernetes.</li> </ul> <p>When combined with the advanced CI/CD pipeline outlined in the Build Automation section, you can achieve a streamlined development process that enhances efficiency, reduces deployment times, and ensures consistent application performance across your IoT devices.</p>"},{"location":"developer/architecture.html","title":"System Architecture","text":"<p>Our platform spans cloud, edge, and device layers with secure orchestration, discovery, and task delegation built into each layer.</p>"},{"location":"developer/architecture.html#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>+-----------------+\n| Cloud Platform  |\n+-----------------+\n         ^\n         |\n+----------------+   +------------------+    +------------------+\n| Edge Node(s)   |&lt;--| Akri + Offloader |&lt;--&gt;| Neighbor Devices |\n+----------------+   +------------------+    +------------------+\n         ^\n         |\n+----------------+     +-------------------+\n| IoT Devices    |&lt;---&gt;| Onboarding Agent  |\n+----------------+     +-------------------+\n</code></pre>"},{"location":"developer/architecture.html#key-components","title":"Key Components","text":"<ul> <li> <p>Onboarding Service: Securely verifies device identity (DICE-based)</p> </li> <li> <p>Akri: Dynamically discovers and exposes verified devices</p> </li> <li> <p>OTA Service &amp; Agent: Secure firmware update management</p> </li> <li> <p>vAccel Offloader: Enables remote compute delegation</p> </li> </ul>"},{"location":"developer/architecture.html#technology-stack","title":"Technology Stack","text":"<ul> <li>Kubernetes</li> <li>Akri + CRDs</li> <li>mbedTLS</li> <li>Rust, Go, C, Python</li> </ul>"},{"location":"developer/build_automation.html","title":"Build Automation","text":""},{"location":"developer/build_automation.html#introduction","title":"Introduction","text":"<p>Building and packaging firmware for embedded devices such as ESP32 can be deceptively complex. The process typically involves managing toolchains, setting device-specific configurations, embedding application models (like TFLite), optionally signing binaries, and deploying the resulting firmware across diverse hardware targets.</p> <p>This section explains:</p> <ul> <li>Common industry practices for firmware building and update workflows.</li> <li>How ESP-IDF-based firmware is typically built.</li> <li>How our <code>esp32-build</code> automation system simplifies this process.</li> </ul>"},{"location":"developer/build_automation.html#firmware-build-practices","title":"Firmware Build Practices","text":"<p>Cloud providers such as AWS IoT and Azure IoT Hub offer end-to-end device management platforms. Here's how firmware build &amp; update is commonly done with them:</p>"},{"location":"developer/build_automation.html#aws-iot","title":"AWS IoT","text":"<ul> <li>Build: Developers manually compile firmware using <code>ESP-IDF</code> locally or via CI.</li> <li>Store: The firmware is uploaded to an S3 bucket.</li> <li>Update: AWS IoT Device Jobs service triggers the update by instructing the device to download and apply the firmware from S3.</li> <li>Security: Optional code signing via AWS Signer. Root-of-trust is enforced at device boot.</li> </ul>"},{"location":"developer/build_automation.html#azure-iot","title":"Azure IoT","text":"<ul> <li>Build: Similarly to AWS, the firmware is compiled using local/CI toolchains.</li> <li>Store: The firmware is uploaded to Azure Blob Storage.</li> <li>Update: Azure Device Update for IoT Hub delivers the new image to registered devices via update campaigns.</li> <li>Security: Supported but tightly coupled with Microsoft's toolchain and portal-based setup.</li> </ul>"},{"location":"developer/build_automation.html#industry-vs-our-ci-based-method","title":"Industry VS Our CI-based Method","text":"Feature AWS / Azure IoT Our Approach Binary Distribution Blob Storage (S3 / Azure Blob) OCI Image Registry (Harbor, DockerHub) Device Targeting Device Shadow / Twin OCI image tags + Manifest CI/CD Integration CodeBuild, Azure DevOps (manual setup) GitHub Actions-native OTA Update Vendor-managed OTA infrastructure <code>esp32-flashjob</code> Extensibility Vendor lock-in Open, OCI-compliant, portable"},{"location":"developer/build_automation.html#esp-idf-build","title":"ESP-IDF Build","text":"<p>ESP-IDF is Espressif\u2019s official framework for building ESP32 firmware.</p> <p>A typical manual build includes:</p> <pre><code># Set up ESP-IDF environment\n. $HOME/esp/esp-idf/export.sh\n\n# Configure your target\nidf.py set-target esp32s3\n\n# Configure project settings, PSRAM, partition table, etc.\nidf.py menuconfig\n\n# Build\nidf.py build\n\n# Flash the device (via USB)\nidf.py -p /dev/ttyUSB0 flash\n\n# Monitor serial output\nidf.py -p /dev/ttyUSB0 monitor\n</code></pre> <p>Although this works well for single-target builds, it becomes cumbersome when:</p> <ul> <li>Supporting multiple hardware variants (e.g. <code>esp32s3</code>, <code>esp32s2</code>, etc.).</li> <li>Managing different RAM configurations (e.g. quad/octal PSRAM, internal RAM).</li> <li>Creating custom partition tables based not only on the app but also on the hardware target's capabilities.</li> <li>Embedding additional files (e.g. TensorFlow Lite models) into the firmware or flash partitions.</li> <li>Signing firmware for secure boot or OTA updates.</li> </ul>"},{"location":"developer/build_automation.html#ci-powered-build-with-esp32-build","title":"CI-Powered Build with <code>esp32-build</code>","text":"<p>To solve all the above challenges, we\u2019ve created <code>esp32-build</code>: a fully automated CI workflow for building and packaging firmware across many targets.</p>"},{"location":"developer/build_automation.html#overview","title":"Overview","text":"<ul> <li>Workflow: GitHub Actions <code>build.yml</code> workflow triggered by <code>ci.yml</code> when the latter is provided with a JSON input.</li> <li>Input: JSON configuration file</li> <li>Apps: List of applications to build, each with its own repository, branch, version, type, optional file paths to a machine-learning model and a prebuild script. It also allows defining custom variables that will be converted to environment variables.</li> <li>Targets: List of hardware targets (e.g., <code>esp32s3</code>, <code>esp32s2</code>).</li> <li>Builder Image: Container image containing the ESP-IDF environment.</li> <li>Keys: List of signing keys (in the form of Github Secrets) for secure boot or OTA updates.</li> <li>Output: Per-target signed firmware, flasher images, and multi-arch manifests.</li> </ul> <p>An example of the expected JSON input form is provided below:</p> <pre><code>{\n  \"apps\": [\n    {\n      \"repo\": \"nubificus/fmnist-esp-ota\",\n      \"branch\": \"main\",\n      \"version\": \"8.8.8\",\n      \"type\": \"fmnist-app\",\n      \"model\": \"models/simple_cnn_tf_frozen.tflite\",\n      \"tensor_allocation_space\": \"204800\",\n      \"load_model_from_partition\": \"1\",\n      \"prebuild\": \"scripts/prepare.sh\"\n    }\n  ],\n  \"targets\": [\"esp32s3\", \"esp32s3r2\"],\n  \"builder_image\": \"harbor.nbfc.io/nubificus/esp-idf:x86_64-slim\",\n  \"keys\": [\"ESP32_KEY3\"]\n}\n</code></pre>"},{"location":"developer/build_automation.html#building-process","title":"Building Process","text":"<p>While the building process is quite complex and involves several steps, the most significant ones are as follows:</p> <ol> <li> <p>In case the user has provided a model path in the JSON input, the first step ensures that the model is included in the final container image. The model is also uploaded to our S3 storage server.</p> </li> <li> <p>The project repository is fetched and the workflow checks out the specified branch.</p> </li> <li> <p>Any additional app variables provided by the user are defined as environment variables.</p> </li> <li> <p>If any target device has the suffixes <code>r2</code> or <code>r8</code>, the workflow will set the <code>quad_psram</code> or <code>oct_psram</code> environment variables, respectively. The user can utilize these variables in their project builder to enable the external PSRAM of their device.</p> </li> <li> <p>If the user has specified a \"prebuild\" field that points to a preparation script within the project repository, the workflow will execute it.</p> </li> <li> <p>Using the provided <code>\"builder_image\"</code>, which has the ESP-IDF framework installed, the workflow performs the actual esp32 build for each specified esp32 target device.</p> </li> <li> <p>If the <code>\"keys\"</code> field is not empty, the workflow will sign the firmware generated in the previous step for each secret key.</p> </li> <li> <p>Similar to the model, the firmware binary artifacts are also included in the container image and uploaded to our S3 storage server.</p> </li> <li> <p>For each target device, a container image containing only the firmware image    is constructed for later use by the flash job for OTA updates. However,    instead of producing multiple separate container images, the workflow outputs a    single manifest that includes all of them, allowing the user to check out their    preferred type.</p> </li> <li> <p>Finally, the workflow creates an initial flashing container image that the     user can use to physically flash the esp32 device with the previously     generated binary artifacts. This container image contains binary artifacts for     all device types, and the user can specify the desired type during the <code>docker run</code> execution. Additionally, since flashing container images are constructed     for both x86 and ARM architectures, the workflow generates a single manifest     containing both.</p> </li> </ol> <p> Figure 1: Example of workflow execution flow illustrating the creation of three firmware building jobs, three firmware container building jobs, and two flashing container building jobs for each of the three device types and two architectures. Additionally, there are two final jobs for assembling the containers into single manifests.</p>"},{"location":"developer/firmware_packaging.html","title":"Firmware Packaging","text":""},{"location":"developer/firmware_packaging.html#overview","title":"Overview","text":"<p>Our automated build workflow, handles the entire process of building, tagging, and packaging firmware for multiple ESP32 targets. The key steps are:</p> <ol> <li>Building firmware images for each target using the same base image name    <code>harbor.nbfc.io/cloud-iot/&lt;repo&gt;</code>.</li> <li>Tagging each target's firmware image with a unique identifier that includes    the target, application type, version, and commit SHA.</li> <li>Combining all target-specific images into a single OCI manifest and pushing    it to our image registry.</li> <li>Storing all artifacts in S3 buckets for easy access and backup.</li> </ol>"},{"location":"developer/firmware_packaging.html#rationale","title":"Rationale","text":"<p>In IoT deployents, especially when dealing with a large number of versatile ESP32 devices, it is crucial to optimize OTA firmware updates. Creating monlithic firmware images for each device target that include all binaries (bootloader, partition table, application) is inefficient. Obtaining only the updated application binaries and combining them into a single OCI manifest image allows for:</p> <ul> <li>Reduced bandwidth usage: Only the changed binaries are downloaded.</li> <li>Faster updates: Devices can quickly fetch and apply only the necessary   changes.</li> <li>Simplified management: All target-specific images are aggregated under a   single manifest, making it easier to manage and deploy updates.</li> </ul> <p>In order to exploit these benefits, we have also designed the <code>esp32-flashjob</code> component for performing secure OTA updates. This component uses the manifest to determine which application binary to download and apply, ensuring that devices only fetch the necessary updates without needing to reflash the entire firmware. Further information about the flashjob can be found here.</p>"},{"location":"developer/firmware_packaging.html#example-bug-fix-rollout","title":"Example: Bug Fix Rollout","text":"<p>Imagine an app has a bug in version <code>1.0.0</code>.</p> <ol> <li>You fix the bug and build a new firmware <code>1.0.1</code>.</li> <li><code>esp32-build</code> creates:</li> </ol> <p>a. New firmware images per target. b. Updated manifest at:</p> <pre><code>harbor.nbfc.io/cloud-iot/&lt;repo&gt;:&lt;app_type&gt;-1.0.1-&lt;key&gt;\n</code></pre> <ol> <li>Devices running <code>esp32-flashjob</code> detect the update and self-upgrade.</li> </ol>"},{"location":"developer/initial_flash_packaging.html","title":"Initial Flash Packaging","text":""},{"location":"developer/initial_flash_packaging.html#overview","title":"Overview","text":"<p>This guide explains how we prepare and publish OCI images for flashing devices for the first time. After the firmware artifacts are built, the <code>esp32-build</code> workflow proceeds with the generation of the initial flash images that is comprised of the following steps:</p> <ol> <li>Creation of platform-specific flash images for each requested architecture    (e.g., <code>amd64</code>, <code>arm64</code>) by copying all necessary firmware artifacts into a    container image. All images use the same base name    <code>harbor.nbfc.io/cloud-iot/&lt;repo&gt;-flash</code>.</li> <li>Tagging each platform's flash image with a unique identifier that includes    the platform architecture, application type, version, and commit SHA.</li> <li>Creation of a multi-arch manifest that allows <code>docker run</code> to automatically    select the correct architecture for the host platform.</li> </ol>"},{"location":"developer/initial_flash_packaging.html#rationale","title":"Rationale","text":"<p>Flashing a blank or factory-reset ESP32 device should be as seamless and platform-independent as possible especially when onboarding devices at scale. Traditionally, this requires knowing the exact ESP32 variant (e.g., <code>esp32s2</code>, <code>esp32s3</code>), having the correct bootloader, partition table, and app binary on hand, and running vendor-specific flashing tools per operating system or architecture. This process is not only error-prone but slows down manufacturing, debugging and deployment workflows. Our approach solves this by packaging all necessary flashing artifacts into OCI images, and combining them in a multi-architecture Docker manifest. The required files are:</p> <ul> <li><code>bootloader.bin</code></li> <li><code>partition-table.bin</code></li> <li><code>ota_data_initial.bin</code></li> <li><code>sdkconfig</code></li> <li><code>partitions.csv</code></li> <li><code>app binary</code></li> </ul>"},{"location":"developer/initial_flash_packaging.html#example-onboarding-a-new-device","title":"Example: Onboarding a New Device","text":"<p>Imagine you have a new ESP32 device that needs to be flashed for the first time. The steps are as follows:</p> <ol> <li>Build the Firmware: Use the <code>esp32-build</code> workflow to build the firmware    for your device. This will generate the necessary artifacts including the    bootloader, partition table, and application binary and bundle them into a    multi-arch OCI flash manifest.</li> <li>Obtain the Flash Image: After the build completes, you can pull the    appropriate flash image for your device type and architecture from our    registry:    <pre><code>harbor.nbfc.io/cloud-iot/&lt;repo&gt;-flash:&lt;app_type&gt;-&lt;version&gt;\n</code></pre></li> <li>Run the Flash Job: Use the provided Docker image to flash your device.    The command will look like this:</li> </ol> <pre><code>docker run --rm -it --device=&lt;PORT&gt; harbor.nbfc.io/cloud-iot/&lt;repo&gt;-flash:&lt;app_type&gt;-&lt;version&gt; \\\n--port &lt;PORT&gt; --chip &lt;DEVICE_TYPE&gt; --flash_size &lt;FLASH_SIZE&gt; \\\n[--baud &lt;BAUD&gt;] [--override_pt [normal|normal_with_model|no_factory|no_factory_with_model]]\n</code></pre> <p>The <code>--device</code> argument is a Docker option that grants the container access to the specified hardware port. The other custom arguments used in that command are explained as follows:</p> <ul> <li><code>--port</code>: Specifies the port through which the firmware will be flashed,</li> <li><code>--chip</code>: indicates the device type, which may include the suffixes <code>r2</code> and <code>r8</code>,</li> <li><code>--flash_size</code>: defines the flash size of the device being flashed,</li> <li><code>[--baud]</code>: sets the baud rate (frequency) for flashing the board and</li> <li><code>[--override_pt]</code>: allows the explicit replacement of the current partition   table (generated during the build process) with a new one based on user   preferences, expanded across the entire flash of the device. The available   options are:</li> <li><code>normal</code>: Creates three app partitions (one factory and two OTA).</li> <li><code>normal_with_model</code>: Creates three app partitions (one factory and two OTA)     along with a custom tflite model partition.</li> <li><code>no_factory</code>: Creates two app partitions (two OTA), with the app placed in     <code>ota_0</code>.</li> <li><code>no_factory_with_model</code>: Creates two app partitions (two OTA) with the app     placed in <code>ota_0</code>, along with a custom tflite model partition.</li> </ul>"},{"location":"getting-started/index.html","title":"Overview","text":"<p>Whether you're integrating ESP32 microcontrollers or Linux-based devices, our platform facilitates zero-touch provisioning using DICE-based attestation, ensuring device authenticity from the outset. With Akri-based device discovery, you can automatically detect and register devices, creating an up-to-date inventory without manual intervention.</p> <p>For developers and system integrators, the platform offers:</p> <ul> <li>Secure Device Onboarding: Leverage DICE-based mechanisms to authenticate devices during the provisioning process.</li> <li>Seamless OTA Updates: Deploy firmware updates effortlessly to both microcontroller and Linux-class devices.</li> <li>Dynamic Resource Discovery: Utilize Akri to automatically discover and manage connected devices within your network.</li> <li>Task Offloading: Enhance performance by offloading compute-intensive tasks to heterogeneous accelerators using vAccel.</li> <li>Kubernetes Integration: Manage and scale your IoT deployments using Kubernetes-native tools, including Custom Resource Definitions (CRDs) and Operators.</li> </ul> <p>To begin your journey:</p> <ul> <li>Review the Architecture Overview: Understand the core components and their interactions within the platform.</li> <li>Explore the Quickstart Guide: Follow step-by-step instructions to set up your first device and connect it to the platform.</li> <li>Dig into the Installation Guide: Follow step-by-step instructions to set up your first device and connect it to the platform.</li> <li>Dive into Component Details: Gain insights into individual modules like the OTA Service, Akri Integration, and more.</li> <li>Consult the API Documentation: Integrate your applications seamlessly using our comprehensive APIs.</li> </ul> <p>Embark on building scalable, secure, and efficient IoT solutions with the Cloud-Native IoT platform.</p>"},{"location":"getting-started/installation.html","title":"Installation","text":"<p>This document will guide you through the process of configuring a k3s cluster with all the necessary components to run our Cloud Native IoT framework, namely:</p> <ul> <li>Akri</li> <li>Attestation Server</li> <li>FlashJob Operator</li> <li>Longhorn</li> <li>MetalLB</li> </ul> <p>The cluster used while writing this document was a k3s installation on a Ubuntu 22.04 machine. The k3s cluster was configured with Calico CNI to provide networking.</p>"},{"location":"getting-started/installation.html#install-metallb-in-the-cluster","title":"Install MetalLB in the cluster","text":"<p>To ensure the IoT devices can talk to the OTA agent, we need to provide the flashjob pod with a routeable IP. We use metallb to do that.</p> <p>First, we need to apply the manifest:</p> <pre><code>VERSION=v0.13.12\nkubectl apply -f https://raw.githubusercontent.com/metallb/metallb/$VERSION/config/manifests/metallb-native.yaml\n</code></pre> <p>Next, we will create an IP pool:</p> <pre><code>cat &lt;&lt;EOF | tee ip-pool.yaml\napiVersion: metallb.io/v1beta1\nkind: IPAddressPool\nmetadata:\n  name: first-pool\n  namespace: metallb-system\nspec:\n  addresses:\n  - 192.168.5.201-192.168.5.230\nEOF\nkubectl apply -f ip-pool.yaml\n</code></pre> <p>Note: This must be a unique range in our subnet. For our e2e example, we use 192.168.5.221-230 (max 9 concurrent flashjobs).</p> <p>Finally, we will enable l2 advertisement (this will populate ARP entries across the cluster):</p> <pre><code>cat &lt;&lt;EOF | tee l2add.yaml\napiVersion: metallb.io/v1beta1\nkind: L2Advertisement\nmetadata:\n  name: example\n  namespace: metallb-system\nspec:\n  ipAddressPools:\n  - first-pool\nEOF\nkubectl apply -f l2add.yaml\n</code></pre> <p>Note: This is not needed most probably for this setup, but it's good to have it in case an ARP request does not reach the cluster correctly.</p>"},{"location":"getting-started/installation.html#install-longhorn-in-the-cluster","title":"Install longhorn in the cluster","text":"<p>The DICE auth server uses Redis as a storage backend. To ensure Redis has persistent storage across reboots an additional storage system for Kubernetes must be installed. In this case, we use Longhorn since it is suggested by the k3s maintainers.</p> <p>First, we need to install <code>open-iscsi</code> in all k3s nodes:</p> <pre><code>sudo apt update\nsudo apt install open-iscsi -y\n</code></pre> <p>Once <code>open-iscsi</code> is properly installed, we can go ahead and install <code>longhorn</code>:</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/longhorn/longhorn/v1.6.0/deploy/longhorn.yaml\n</code></pre>"},{"location":"getting-started/installation.html#install-akri-in-the-cluster","title":"Install Akri in the cluster","text":"<p>To install Akri we will use Helm:</p> <pre><code>helm repo add akri-helm-charts https://project-akri.github.io/akri/\nhelm repo update\nKUBECONFIG=/etc/rancher/k3s/k3s.yaml helm install akri akri-helm-charts/akri\n</code></pre> <p>And now, we can verify the Akri Pods are properly deployed:</p> <pre><code>$ kubectl get pods -A | grep akri\ndefault            akri-agent-daemonset-4p249                    1/1     Running     0          43s\ndefault            akri-agent-daemonset-h87nf                    1/1     Running     0          43s\ndefault            akri-controller-deployment-745f4bfc4c-hkg84   1/1     Running     0          43s\ndefault            akri-webhook-configuration-78666f968d-lf875   1/1     Running     0          43s\n</code></pre>"},{"location":"getting-started/installation.html#deploy-dice-auth-server-and-redis","title":"Deploy DICE auth server and Redis","text":"<p>To deploy the DICE auth server, we need to also deploy a Redis pod as well as a persistent volume for the Redis pod:</p> <pre><code>cat &lt;&lt;EOF | sudo tee deployment.yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: redis-data\nspec:\n  accessModes:\n    - ReadWriteOnce\n  storageClassName: longhorn\n  resources:\n    requests:\n      storage: 2Gi\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-deployment\n  labels:\n    app: redis\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n        - name: redis\n          image: redis:latest\n          ports:\n            - containerPort: 6379\n          volumeMounts:\n            - mountPath: /data\n              name: redis-storage\n          resources:\n            limits:\n              memory: \"256Mi\"\n              cpu: \"500m\"\n          command: [\"redis-server\", \"--appendonly\", \"yes\"]\n      volumes:\n        - name: redis-storage\n          persistentVolumeClaim:\n            claimName: redis-data\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: redis-service\nspec:\n  selector:\n    app: redis\n  ports:\n    - protocol: TCP\n      port: 6379  # Service port\n      targetPort: 6379  # Pod container port\n  type: ClusterIP  # Change to NodePort or LoadBalancer if external access is needed\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dice-auth-deployment\n  labels:\n    app: dice-auth\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dice-auth\n  template:\n    metadata:\n      labels:\n        app: dice-auth\n    spec:\n      containers:\n        - name: dice-auth\n          image: harbor.nbfc.io/nubificus/iot/dice-auth-server:e2e\n          imagePullPolicy: Always\n          ports:\n            - containerPort: 8000\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: dice-auth-service\nspec:\n  selector:\n    app: dice-auth\n  ports:\n    - protocol: TCP\n      port: 8000  # Service port\n      targetPort: 8000  # Pod container port\n  type: ClusterIP  # Change to NodePort or LoadBalancer if external access is needed\nEOF\nkubectl apply -f deployment.yaml\n</code></pre> <p>We should see the Dice auth and Redis Pod running:</p> <pre><code>$ kubectl get pods\nNAME                                          READY   STATUS    RESTARTS   AGE\n...\ndice-auth-deployment-5cfd8b6dc4-qhzg8         1/1     Running   0          107s\nredis-deployment-64dd9d7478-t4rmd             1/1     Running   0          39s\n</code></pre>"},{"location":"getting-started/installation.html#build-the-dice-auth-server-container-image","title":"Build the DICE auth server container image","text":"<p>In case you need to build DICE auth server container image, there is a Dockerfile in the <code>dice-auth</code> repo:</p> <pre><code>git clone https://github.com/nubificus/dice-auth.git\ncd dice-auth\nsudo podman build -t harbor.nbfc.io/nubificus/iot/dice-auth-server:latest .\nsudo podman push harbor.nbfc.io/nubificus/iot/dice-auth-server:latest\n</code></pre>"},{"location":"getting-started/installation.html#install-flashjob-operator-in-the-cluster","title":"Install Flashjob Operator in the cluster","text":""},{"location":"getting-started/installation.html#method-1-one-click-installation-via-yaml","title":"Method 1: One-Click Installation via YAML","text":"<p>We can install the operator using the official release YAML:</p> <pre><code>kubectl apply -f https://github.com/nubificus/flashjob_operator/releases/download/v1.20.1/inst  all.yaml\n</code></pre>"},{"location":"getting-started/installation.html#method-2-helm-installation","title":"Method 2: Helm Installation","text":"<p>Add the FlashJob Operator Helm repository:</p> <pre><code>helm repo add flashjob https://nubificus.github.io/flashjob_operator\nhelm repo update\n</code></pre> <p>Install the Operator using Helm:</p> <pre><code>helm install my-flashjob-operator flashjob/operator \\\n--version 1.20.1 \\\n--namespace operator-system --create-namespace \\\n--set image.repository=harbor.nbfc.io/cloud-iot/akri_operator \\\n--set image.tag=1.20.1\n</code></pre>"},{"location":"getting-started/installation.html#wrapping-up","title":"Wrapping up","text":"<p>Now, we have a fully functional cluster with all the necessary components to run our Cloud Native IoT framework. You can continue this journey by preparing an ESP32-device to be onboarded in the cluster and deploying a Discovery Handler to onboard the device!</p>"},{"location":"getting-started/prerequisites.html","title":"Prerequisites","text":"<p>Before you begin with the Cloud-Native IoT platform, make sure you have the following in place:</p>"},{"location":"getting-started/prerequisites.html#1-hardware-requirements","title":"1. Hardware Requirements","text":""},{"location":"getting-started/prerequisites.html#iot-device","title":"IoT Device","text":"<p>ESP32 / ESP32-S2 / ESP32-S3 We have tested the following device types:</p> <ul> <li>ESP32-C6</li> <li>ESP32-S2R2</li> <li>ESP32-S3</li> <li>ESP32-D0WD-V3</li> </ul> <p>Note: Use of other compatible boards is supported but not formally validated.</p> <ul> <li>Control Plane Node</li> <li>x86_64 VM or bare-metal</li> <li>2 vCPU, 4 GB RAM (min)</li> <li>Worker Nodes (optional, recommended \u00d72)</li> <li>x86_64 VM or bare-metal each</li> <li>2 vCPU, 4 GB RAM (min)</li> <li>Note: For minimal testing, a single node (control plane only) is sufficient. For production or realistic scenarios, at least two worker nodes are recommended.</li> </ul>"},{"location":"getting-started/prerequisites.html#2-host-machine-software","title":"2. Host Machine Software","text":"Tool Version Requirement Install Guide Git \u2265 2.30 Git Downloads Docker or Podman Latest stable Docker Installation Python \u2265 3.8 Python Downloads Go \u2265 1.20 Go Installation ESP-IDF Latest ESP-IDF Getting Started CMake, Ninja, build-essential (Linux) \u2013 <code>sudo apt install cmake ninja-build build-essential</code>"},{"location":"getting-started/prerequisites.html#3-kubernetes-cluster","title":"3. Kubernetes Cluster","text":"<ul> <li> <p>k3s version \u2265 1.25</p> </li> <li> <p>Quickstart Guide</p> </li> <li> <p>kubectl</p> </li> <li> <p>Install kubectl</p> </li> <li> <p>Helm</p> </li> <li>Install Helm</li> </ul>"},{"location":"getting-started/prerequisites.html#reference-docs","title":"Reference Docs","text":"<ul> <li>Architecture Overview</li> <li>ESP32 Firmware Build</li> <li>End-to-End Scenario</li> </ul> <p>Ready? Move on to the Quickstart Guide.</p>"},{"location":"getting-started/quickstart.html","title":"Quickstart Guide","text":"<p>This guide walks you through the essential steps to deploy the Cloud-Native IoT Platform in a test or development environment.</p>"},{"location":"getting-started/quickstart.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster (minikube, k3s, or full-fledged cluster)</li> <li><code>kubectl</code> &amp; <code>helm</code> installed</li> <li>containerd runtime</li> <li>ESP32 development board or Linux device (for onboarding test)</li> </ul>"},{"location":"tutorials/index.html","title":"Overview","text":"<p>This section provides step-by-step tutorials to help you get hands-on experience with the Cloud-Native IoT platform. Whether you're onboarding your first device, deploying firmware updates, or integrating with Kubernetes-native tools, these guides are designed to walk you through practical workflows in real-world scenarios.</p> <p>Each tutorial focuses on a specific component or use case, with detailed instructions, commands, and expected outcomes. These examples are ideal for developers, operators, and system integrators looking to understand the inner workings of the platform.</p> <p>What you'll find here:</p> <ul> <li>Platform Setup: Learn how to deploy and configure platform components using containers or Kubernetes manifests.</li> <li>Secure Boot: Setup ESP32 devices with Secure Boot (v1).</li> <li>Secure Boot v2: Setup ESP32 devices with Secure Boot (v2).</li> <li>Initial device flash: Flash a vanilla device.</li> <li>Device Onboarding: Securely register ESP32 and Linux-based devices using DICE attestation.</li> <li>OTA Firmware Updates: Deploy new firmware builds over-the-air, with integrity checks and rollback support.</li> <li>Akri Discovery Integration: Discover and manage devices dynamically in a Kubernetes cluster.</li> <li> <p>Advanced Scenarios: Offload compute to edge accelerators.</p> </li> <li> <p>End-to-end Scenario: Covering all the above steps.</p> </li> </ul> <p>Prerequisites: Basic familiarity with Linux, Docker, and Kubernetes is recommended.</p> <p>Start with a tutorial that fits your use case, or follow the full sequence to gain a comprehensive understanding of the platform.</p>"},{"location":"tutorials/akri-esp32.html","title":"ESP32 Akri Component","text":"<p>This is the installation tutorial page for the ESP32 Akri Component.</p>"},{"location":"tutorials/akri-esp32.html#tutorial","title":"Tutorial","text":"<pre><code>cd &lt;path-to-your-esp-idf-project&gt;\nmkdir -p components\ncd components\ngit clone https://github.com/nubificus/esp32-akri.git\n</code></pre> <p>Add the component to your project by simply adding the following line inside <code>idf_component_register()</code> of <code>&lt;path-to-your-esp-idf-project&gt;/main/CMakeLists.txt</code>:</p> <pre><code>REQUIRES esp32-akri\n</code></pre> <p>E.g:</p> <pre><code>idf_component_register(SRCS \"test.c\"\n                       INCLUDE_DIRS \".\"\n                       REQUIRES esp32-akri)\n</code></pre> <p>Afterwards, you can include the component's header file:</p> <pre><code>#include \"esp32-akri.h\"\n</code></pre>"},{"location":"tutorials/dice-auth.html","title":"Attestation Server","text":"<p>This is the installation tutorial page of the DICE Attestation Server</p>"},{"location":"tutorials/dice-auth.html#about-dice","title":"About DICE","text":"<p>Based on Google's open-dice: https://github.com/google/open-dice</p> <p>In <code>src/</code> we use the following files of <code>open-dice/src/</code>:</p> <ul> <li><code>clear_memory.c</code></li> <li><code>dice.c</code></li> <li><code>mbedtls_ops.c</code></li> <li><code>utils.c</code></li> </ul> <p>In <code>src/include/dice/</code> we use the following files of <code>open-dice/include/dice/</code>:</p> <ul> <li><code>config.h</code></li> <li><code>dice.h</code></li> <li><code>ops.h</code></li> <li><code>utils.h</code></li> </ul>"},{"location":"tutorials/dice-auth.html#build","title":"Build","text":"<p>Regarding <code>dice-auth</code> source code, the project is comprised of various sub-projects: <code>dice-auth-service</code> and utilities like <code>submit</code>, <code>list</code>, <code>del</code> and <code>gen_cert</code>.</p>"},{"location":"tutorials/dice-auth.html#submit","title":"Submit","text":"<p><code>submit</code> is a program that can be used to submit device entries to a <code>Redis</code> Database. The source code can be found in <code>src/redis_submit.c</code>. First of all, install <code>redis</code>, <code>redis-lib</code> and OpenSSL library:</p> <pre><code>sudo apt-get install redis-server libhiredis-dev libssl-dev\n\n# Now redis should run. You can verify it:\nredis-cli ping\nPONG\n</code></pre> <p>Now you can clone the repository and build <code>submit</code> by running:</p> <pre><code>git clone git@github.com:nubificus/dice-auth.git\ncd dice-auth\nmake submit\n</code></pre> <p>And now you can submit a new device entry to the database by running:</p> <pre><code>./submit UDS(MAC) [redis-IP]\n</code></pre> <p>Internally, <code>submit</code> will generate the Root certificate of the device using the unique device secret (the MAC address) and will submit a new entry to the Redis database. That entry will contain the certificate that will be used later to verify incoming attestation certificates.</p>"},{"location":"tutorials/dice-auth.html#list-del-and-gen_cert","title":"<code>list</code>, <code>del</code> and <code>gen_cert</code>","text":"<p>Correspondingly, you can also build the rest utilities, useful for listing the items of the database, removing an item based on its UDS or displaying a root certificate given its UDS.</p> <p>Use <code>make ls</code>, <code>make delete</code> or <code>make gen_cert</code> to build each one. And use them like:</p> <pre><code>./list [redis-IP]\n./del UDS [redis-IP]\n./gen_cert UDS [--pem]\n</code></pre>"},{"location":"tutorials/dice-auth.html#dice-auth-service","title":"Dice Auth Service","text":"<p>This is a simple HTTP server that authorizes incoming Attestation certificates. Actually, the server expects <code>POST</code> request that contain the attestation certificate, e.g:</p> <pre><code>curl -X POST &lt;dice-auth-http-endpoint&gt; -H \"Content-Type: text/plain\" --data-binary @/path/to/attestation.pem\n</code></pre> <p>Furthermore, the HTTP server can retrieve the IP of the Redis database from the <code>REDIS_HOST</code> or <code>REDIS_SERVICE_SERVICE_HOST</code> environment variable (in Kubernetes setups, the second variable is probably set automatically). Otherwise, it will attempt to find the database in localhost.</p>"},{"location":"tutorials/dice-auth.html#build-and-run","title":"Build and Run","text":"<pre><code>make dice_auth\nmake run\n</code></pre>"},{"location":"tutorials/dice-auth.html#cleanup","title":"Cleanup","text":"<pre><code>make clean\n</code></pre>"},{"location":"tutorials/e2e.html","title":"Cloud Native IoT Project User's guide","text":"<p>Placeholder document for the end to end scenario</p>"},{"location":"tutorials/e2e.html#end-to-end-scenario","title":"End to end scenario","text":""},{"location":"tutorials/e2e.html#steps","title":"Steps","text":"<ul> <li>Create script to assign unique and known names to USB devices (based on serialId, vendorId, mac, etc)</li> <li>Create minimal firmware containing OTA functionality and <code>/info</code> endpoint for onboarding</li> <li>Build it with Action (update action to have 2 modes)</li> <li>Flash N devices with minimal firmware (document partition table/secure boot/build settings etc)</li> <li>Create a fresh k3s with latest Akri</li> <li>Deploy our custom operator</li> <li>Deploy our DICE auth server</li> <li>Deploy an onboarding Discovery Handler</li> <li>Post their MAC addresses to DICE auth (automate process)</li> <li>Wait for onboarding Discovery Handler to discover them</li> <li>Deploy 2 additional Discovery Handlers (based on 2 different application types)</li> <li>Use operator to flash X devices with application A and Y devices with application B (leveraging panos' script)</li> <li>Use operator to repurpose 1 or more Devices for application A to B</li> <li>Use operator to upgrade 1 or more Devices to newest firmware version</li> </ul>"},{"location":"tutorials/e2e.html#future-tasks","title":"Future tasks","text":"<ul> <li>Implement Dice authentication for the Devices at the onboarding DH step</li> </ul>"},{"location":"tutorials/e2e.html#install-akri","title":"Install Akri","text":""},{"location":"tutorials/e2e.html#provision-vms","title":"Provision VMs","text":"<pre><code>incus launch images:ubuntu/22.04/cloud cniot01 --project NBFC-long-running-infra --description \"Control plane VM for Akri k3s\" -p default --target @amd64 --vm -c limits.cpu=3 -c limits.memory=4GiB -d root,size=30GiB --vm\nincus launch images:ubuntu/22.04/cloud cniot02 --project NBFC-long-running-infra --description \"Worker VM for Akri k3s\" -p default --target @amd64 --vm -c limits.cpu=2 -c limits.memory=2GiB -d root,size=20GiB --vm\n</code></pre>"},{"location":"tutorials/e2e.html#install-k3s-cluster","title":"Install k3s cluster","text":"<p>In the control-plane node:</p> <pre><code>POD_CIDR=\"10.240.32.0/19\"\nSERVICE_CIDR=\"10.240.0.0/19\"\ncurl -sfL https://get.k3s.io | INSTALL_K3S_EXEC='--flannel-backend=none' sh -s - --disable-network-policy --disable \"servicelb\" --disable \"metrics-server\" --cluster-cidr $POD_CIDR --service-cidr $SERVICE_CIDR\n\nsudo addgroup k3s-admin\nsudo adduser $USER k3s-admin\nsudo usermod -a -G k3s-admin $USER\nsudo chgrp k3s-admin /etc/rancher/k3s/k3s.yaml\nsudo chmod g+r /etc/rancher/k3s/k3s.yaml\nnewgrp k3s-admin\n\nPOD_CIDR=\"10.240.32.0/19\"\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.29.1/manifests/tigera-operator.yaml\nwget https://raw.githubusercontent.com/projectcalico/calico/v3.29.1/manifests/custom-resources.yaml\nsed -i \"s|192\\.168\\.0\\.0/16|${POD_CIDR}|g\" custom-resources.yaml\nkubectl apply -f custom-resources.yaml\nrm custom-resources.yaml\n\nsudo cat /var/lib/rancher/k3s/server/node-token\n</code></pre> <p>In the worker node:</p> <pre><code>TOKEN=\"mynodetoken\"\ncurl -sfL https://get.k3s.io | K3S_URL=https://cniot01:6443 K3S_TOKEN=$TOKEN sh -\n</code></pre>"},{"location":"tutorials/e2e.html#install-metallb-in-the-cluster","title":"Install MetalLB in the cluster","text":"<p>To ensure the IoT devices can talk to the OTA agent, we need to provide the flashjob pod with a routeable IP. We use metallb to do that.</p> <p>First, we need to apply the manifest:</p> <pre><code>VERSION=v0.13.12\nkubectl apply -f https://raw.githubusercontent.com/metallb/metallb/$VERSION/config/manifests/metallb-native.yaml\n</code></pre> <p>Next, we will create an IP pool:</p> <pre><code>cat &lt;&lt;EOF | tee ip-pool.yaml\napiVersion: metallb.io/v1beta1\nkind: IPAddressPool\nmetadata:\n  name: first-pool\n  namespace: metallb-system\nspec:\n  addresses:\n  - 192.168.5.201-192.168.5.230\nEOF\nkubectl apply -f ip-pool.yaml\n</code></pre> <p>Note: This must be a unique range in our subnet. For our e2e example we use 192.168.5.221-230 (max 9 concurrent flashjobs)</p> <p>Finally, we will enable l2 advertisement (this will populate ARP entries across the cluster):</p> <pre><code>cat &lt;&lt;EOF | tee l2add.yaml\napiVersion: metallb.io/v1beta1\nkind: L2Advertisement\nmetadata:\n  name: example\n  namespace: metallb-system\nspec:\n  ipAddressPools:\n  - first-pool\nEOF\nkubectl apply -f l2add.yaml\n</code></pre> <p>Note: This is not needed most probably for this setup, but it's good to have it in case an arp request does not reach the cluster correctly.</p>"},{"location":"tutorials/e2e.html#install-akri-in-the-cluster","title":"Install Akri in the cluster","text":"<p>To install Akri we will need Helm:</p> <pre><code>curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\n</code></pre> <p>Once Helm is installed:</p> <pre><code>helm repo add akri-helm-charts https://project-akri.github.io/akri/\nhelm repo update\nKUBECONFIG=/etc/rancher/k3s/k3s.yaml helm install akri akri-helm-charts/akri\n</code></pre> <p>Verify the Akri Pods are properly deployed:</p> <pre><code>$ kubectl get pods -A | grep akri\ndefault            akri-agent-daemonset-4p249                    1/1     Running     0          43s\ndefault            akri-agent-daemonset-h87nf                    1/1     Running     0          43s\ndefault            akri-controller-deployment-745f4bfc4c-hkg84   1/1     Running     0          43s\ndefault            akri-webhook-configuration-78666f968d-lf875   1/1     Running     0          43s\n</code></pre>"},{"location":"tutorials/e2e.html#deploy-flashjob-operator","title":"Deploy Flashjob Operator","text":"<pre><code>cd ~\nsudo apt-get install make -y\ncurl -fsSL https://scripts.gntouts.com/go.sh | bash -s go1.24.2\ngit clone -b uuid_array git@github.com:nubificus/flashjob_operator.git\ncd flashjob_operator\n\nGOPATH=$(go env GOPATH):$PWD make manifests\nGOPATH=$(go env GOPATH):$PWD make install\n\nsudo apt-get install podman -y\nsudo podman login --username gntouts --password &lt;REDACTED&gt; harbor.nbfc.io\ncat &lt;&lt;EOF | sudo tee -a /etc/containers/registries.conf\n[registries.search]\nregistries = ['docker.io']\nEOF\nsudo CONTAINER_TOOL=podman IMG=harbor.nbfc.io/nubificus/iot/flashjob-operator:e2e make docker-build docker-push\nIMG=harbor.nbfc.io/nubificus/iot/flashjob-operator:e2e make deploy\n</code></pre> <p>You should see the Operator Pod running:</p> <pre><code>$ kubectl get pods -A | grep manager\noperator-system    operator-controller-manager-c75bcc686-6lsk2   1/1     Running     0          23s\n</code></pre>"},{"location":"tutorials/e2e.html#deploy-dice-auth-server","title":"Deploy DICE auth server","text":""},{"location":"tutorials/e2e.html#build-the-dice-auth-server-container-image","title":"Build the DICE auth server container image","text":"<pre><code>cd ~\ngit clone -b feat_submit_mac git@github.com:nubificus/dice-auth.git\ncd dice-auth\nsudo podman build -t harbor.nbfc.io/nubificus/iot/dice-auth-server:e2e .\nsudo podman push harbor.nbfc.io/nubificus/iot/dice-auth-server:e2e\n</code></pre>"},{"location":"tutorials/e2e.html#deploy-dice-auth-server-and-redis","title":"Deploy DICE auth server and Redis","text":"<p>The DICE auth server uses Redis as a storage backend. To ensure Redis has persistent storage across reboots an additional storage system for Kubernetes must be installed. In this case, we use Longhorn since it is suggested by the k3s maintainers.</p> <pre><code>sudo apt update\nsudo apt install open-iscsi -y # required by longhorn, make sure to install in both nodes\nkubectl apply -f https://raw.githubusercontent.com/longhorn/longhorn/v1.6.0/deploy/longhorn.yaml\n</code></pre> <pre><code>cat &lt;&lt;EOF | sudo tee deployment.yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: redis-data\nspec:\n  accessModes:\n    - ReadWriteOnce\n  storageClassName: longhorn\n  resources:\n    requests:\n      storage: 2Gi\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-deployment\n  labels:\n    app: redis\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n        - name: redis\n          image: redis:latest\n          ports:\n            - containerPort: 6379\n          volumeMounts:\n            - mountPath: /data\n              name: redis-storage\n          resources:\n            limits:\n              memory: \"256Mi\"\n              cpu: \"500m\"\n          command: [\"redis-server\", \"--appendonly\", \"yes\"]\n      volumes:\n        - name: redis-storage\n          persistentVolumeClaim:\n            claimName: redis-data\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: redis-service\nspec:\n  selector:\n    app: redis\n  ports:\n    - protocol: TCP\n      port: 6379  # Service port\n      targetPort: 6379  # Pod container port\n  type: ClusterIP  # Change to NodePort or LoadBalancer if external access is needed\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dice-auth-deployment\n  labels:\n    app: dice-auth\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dice-auth\n  template:\n    metadata:\n      labels:\n        app: dice-auth\n    spec:\n      containers:\n        - name: dice-auth\n          image: harbor.nbfc.io/nubificus/iot/dice-auth-server:e2e\n          imagePullPolicy: Always\n          ports:\n            - containerPort: 8000\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: dice-auth-service\nspec:\n  selector:\n    app: dice-auth\n  ports:\n    - protocol: TCP\n      port: 8000  # Service port\n      targetPort: 8000  # Pod container port\n  type: ClusterIP  # Change to NodePort or LoadBalancer if external access is needed\nEOF\nkubectl apply -f deployment.yaml\n</code></pre> <p>We should see the Dice auth and Redis Pod running:</p> <pre><code>$ kubectl get pods\nNAME                                          READY   STATUS    RESTARTS   AGE\n...\ndice-auth-deployment-5cfd8b6dc4-qhzg8         1/1     Running   0          107s\nredis-deployment-64dd9d7478-t4rmd             1/1     Running   0          39s\n</code></pre>"},{"location":"tutorials/e2e.html#deploy-onboarding-discovery-handler","title":"Deploy Onboarding Discovery Handler","text":"<p>Next, we need to deploy a new Discovery Handler to onboard any devices.</p> <p>To create the new DH we need apply a new Akri Config:</p> <pre><code>controller:\n  enabled: false\nagent:\n  enabled: false\ncleanupHook:\n  enabled: false\nrbac:\n  enabled: false\nwebhookConfiguration:\n  enabled: false\nuseLatestContainers: false\ncustom:\n  configuration:\n    enabled: true\n    name: http-range-onboard # The name of akric\n    capacity: 2\n    discoveryHandlerName: http-discovery-onboard # name of discovery handler, must be unique and matching discovery.name. will be used for socket creation\n    discoveryDetails: | # make sure this is valid YAML\n      ipStart: 192.168.11.20\n      ipEnd: 192.168.11.100\n      applicationType: initial\n      secure: true\n    brokerPod:\n      image:\n        repository: docker.io/gntouts/pause\n        tag: latest\n  discovery:\n    enabled: true\n    image:\n      repository: harbor.nbfc.io/nubificus/iot/akri-discovery-handler-go\n      tag: 61d23fb\n    name: http-discovery-onboard # name of discovery handler, must be unique and matching custom.configuration.discoveryHandlerName\n</code></pre> <pre><code>helm template akri akri-helm-charts/akri -f onboardingConfig.yaml &gt; template.yaml\nkubectl apply -f ./template.yaml\n</code></pre>"},{"location":"tutorials/esp32-initial.html","title":"ESP32: Over the air update (OTA)","text":"<p>esp32-ota-update is a vanilla-type firmware for esp32 devices. It doesn't include any actual real world application, however, it can be used to load the necessary tools to perform an OTA update later.</p>"},{"location":"tutorials/esp32-initial.html#build","title":"Build","text":"<p>The following commands will build the project.</p> <p>Download esp-idf source</p> <pre><code>cd ~\ngit clone --recursive https://github.com/espressif/esp-idf.git\n</code></pre> <p>Install and set the environment variables</p> <pre><code>cd esp-idf\n./install.sh\n. ./export.sh\n# You have to run the last command every time the environment variables are lost.\n</code></pre> <p>Download the project</p> <pre><code>mkdir projects &amp;&amp; cd projects\ngit clone https://github.com/nubificus/esp32-ota-update.git --recursive\ncd esp32-ota-update\n</code></pre> <p>Security Configuration If you want to use the secure implementation, set the <code>OTA_SECURE</code> environment variable before building. Otherwise, the default configuration is the non-secure.</p> <pre><code>export OTA_SECURE=1\n</code></pre> <p>Build and Flash</p> <pre><code>export FIRMWARE_VERSION=\"0.1.0\"\nexport DEVICE_TYPE=\"esp32s2\"\nexport APPLICATION_TYPE=\"thermo\"\nexport WIFI_SSID=...\nexport WIFI_PASS=...\nidf.py build\nidf.py flash monitor\n</code></pre> <p>Create Docker image</p> <pre><code>export FIRMWARE_VERSION=\"0.1.0\"\nexport DEVICE_TYPE=\"esp32s2\"\nexport APPLICATION_TYPE=\"thermo\"\ntee Dockerfile &gt; /dev/null &lt;&lt; 'EOT'\nFROM scratch\nCOPY ./build/ota.bin /firmware/ota.bin\nLABEL \"com.urunc.iot.path\"=\"/firmware/ota.bin\"\nEOT\ndocker build --push -t harbor.nbfc.io/nubificus/$APPLICATION_TYPE-$DEVICE_TYPE-firmware:$FIRMWARE_VERSION .\nrm -f Dockerfile\n</code></pre> <p>You may have to define the port explicitly</p> <pre><code>idf.py -p &lt;PORT&gt; flash monitor\n# example: -p /dev/ttyUSB0\n</code></pre> <p>Additionally, you may have to change user's rights</p> <pre><code>sudo adduser &lt;USER&gt; dialout\nsudo chmod a+rw &lt;PORT&gt;\n</code></pre> <p>To exit ESP32 monitor</p> <pre><code>Ctr + ]\n</code></pre>"},{"location":"tutorials/esp32-initial.html#firmware-provider-app","title":"Firmware Provider App","text":""},{"location":"tutorials/esp32-initial.html#non-secure-implementation","title":"Non-secure implementation","text":"<p>In the case of the non-secure implementation, the microcontroller operates as a server, after receiving the post request. Therefore, we need a tcp client to operate as the firmware provider for the microcontroller. The following C program can do this job.</p> <pre><code>/* tcp_client.c */\n\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;errno.h&gt;\n#include &lt;sys/socket.h&gt;\n#include &lt;netinet/in.h&gt;\n#include &lt;arpa/inet.h&gt;\n\n#define SERVER_IP \"192.168.8.62\"\n#define SERVER_PORT 3333\n#define CHUNK_SIZE  1024\n\nvoid send_file(const char *filename) {\n    int sock;\n    struct sockaddr_in server_address;\n    FILE *file;\n    char buffer[CHUNK_SIZE];\n    size_t bytes_read;\n\n    /* Create socket */\n    sock = socket(AF_INET, SOCK_STREAM, 0);\n    if (sock &lt; 0) {\n        perror(\"Error: Socket creation failed\");\n        exit(EXIT_FAILURE);\n    }\n\n    /* Define the server address */\n    server_address.sin_family = AF_INET;\n    server_address.sin_port = htons(SERVER_PORT);\n    server_address.sin_addr.s_addr = inet_addr(SERVER_IP);\n\n    /* Connect to the server */\n    if (connect(sock, (struct sockaddr *)&amp;server_address, sizeof(server_address)) &lt; 0) {\n        perror(\"Error: Connection failed\");\n        close(sock);\n        exit(EXIT_FAILURE);\n    }\n\n    /* Open the file */\n    file = fopen(filename, \"rb\");\n    if (!file) {\n        perror(\"Error: File opening failed\");\n        close(sock);\n        exit(EXIT_FAILURE);\n    }\n\n    /* Read from the file and send it to the server in chunks */\n    while ((bytes_read = fread(buffer, 1, CHUNK_SIZE, file)) &gt; 0) {\n    if (send(sock, buffer, bytes_read, 0) &lt; 0) {\n            perror(\"Error: Failed to send data\");\n            break;\n        }\n    }\n\n    printf(\"File %s sent successfully\\n\", filename);\n\n    /* Close file and socket */\n    fclose(file);\n    close(sock);\n}\n\n\nint main(int argc, char *argv[]) {\n    if (argc != 2) {\n        fprintf(stderr, \"Usage: %s &lt;file_path&gt;\\n\", argv[0]);\n        exit(EXIT_FAILURE);\n    }\n\n    send_file(argv[1]);\n    return 0;\n}\n</code></pre> <p>Don't forget to change SERVER_IP. Then, you can build and run the program using the following commands:</p> <pre><code>gcc -o client tcp_client.c\n./client /path/to/file.bin\n</code></pre>"},{"location":"tutorials/esp32-initial.html#secure-implementation","title":"Secure implementation","text":"<p>If you build with <code>OTA_SECURE</code>, you will need to check the more advanced OTA Agent implementation, which works with DICE certificates and TLS connection. For more information, view the repository or the documentation.</p>"},{"location":"tutorials/esp32-initial.html#simple-firmware-to-use-for-update","title":"Simple Firmware to use for Update","text":"<p>Now we also need to create a simple firmware image, which will be sent by the server to update ESP32. You can use the <code>hello-world</code> example, located in <code>~/esp-idf/examples/get-started/hello_world/</code>. Build with the following commands:</p> <pre><code>cd ~/esp-idf/examples/get-started/hello_world/\nidf.py build\n</code></pre> <p>The new firmware image is located in <code>~/esp-idf/examples/get-started/hello_world/build/hello_world.bin</code>. You can use that file for the ota update by providing the path when running the client.</p>"},{"location":"tutorials/esp32-initial.html#multi-platform-image-building","title":"Multi-platform image building","text":"<pre><code>git clone -b feat_http_server git@github.com:nubificus/esp32-ota-update.git\ncd esp32-ota-update\nmkdir -p dist/esp32s2\ntee env.list &gt; /dev/null &lt;&lt; 'EOT'\nFIRMWARE_VERSION=0.2.0\nDEVICE_TYPE=esp32s2\nAPPLICATION_TYPE=thermo\nEOT\ndocker run --rm -v $PWD:/project -w /project espressif/idf:latest idf.py set-target esp32s2\ndocker run --rm -v $PWD:/project -w /project --env-file ./env.list espressif/idf:latest idf.py build\nsudo mv build/ota.bin dist/esp32s2/ota.bin\n\nmkdir -p dist/esp32s3\ntee env.list &gt; /dev/null &lt;&lt; 'EOT'\nFIRMWARE_VERSION=0.2.0\nDEVICE_TYPE=esp32s3\nAPPLICATION_TYPE=thermo\nEOT\ndocker run --rm -v $PWD:/project -w /project espressif/idf:latest idf.py set-target esp32s3\ndocker run --rm -v $PWD:/project -w /project --env-file ./env.list espressif/idf:latest idf.py build\nsudo mv build/ota.bin dist/esp32s3/ota.bin\n\nmkdir -p dist/esp32\ntee env.list &gt; /dev/null &lt;&lt; 'EOT'\nFIRMWARE_VERSION=0.2.0\nDEVICE_TYPE=esp32\nAPPLICATION_TYPE=thermo\nEOT\ndocker run --rm -v $PWD:/project -w /project espressif/idf:latest idf.py set-target esp32\ndocker run --rm -v $PWD:/project -w /project --env-file ./env.list espressif/idf:latest idf.py build\nsudo mv build/ota.bin dist/esp32/ota.bin\n\nsudo chown -R $USER dist\n\ntee Dockerfile &gt; /dev/null &lt;&lt; 'EOT'\nFROM scratch\nARG DEVICE\nCOPY dist/${DEVICE}/ota.bin /firmware/ota.bin\nLABEL \"com.urunc.iot.path\"=\"/firmware/ota.bin\"\nEOT\n\ndocker buildx build --platform custom/esp32 -t harbor.nbfc.io/nubificus/iot/esp32-thermo-firmware:0.2.0-esp32 --build-arg DEVICE=esp32 . --push --provenance false\ndocker buildx build --platform custom/esp32s2 -t harbor.nbfc.io/nubificus/iot/esp32-thermo-firmware:0.2.0-esp32s2 --build-arg DEVICE=esp32s2 . --push --provenance false\ndocker buildx build --platform custom/esp32s3 -t harbor.nbfc.io/nubificus/iot/esp32-thermo-firmware:0.2.0-esp32s3 --build-arg DEVICE=esp32s3 . --push --provenance false\n\ndocker manifest create harbor.nbfc.io/nubificus/iot/esp32-thermo-firmware:0.2.0 \\\n  --amend harbor.nbfc.io/nubificus/iot/esp32-thermo-firmware:0.2.0-esp32 \\\n  --amend harbor.nbfc.io/nubificus/iot/esp32-thermo-firmware:0.2.0-esp32s2 \\\n  --amend harbor.nbfc.io/nubificus/iot/esp32-thermo-firmware:0.2.0-esp32s3\n\ndocker manifest push harbor.nbfc.io/nubificus/iot/esp32-thermo-firmware:0.2.0\n</code></pre>"},{"location":"tutorials/filter_uuid.html","title":"FlashJob Operator: <code>filter_uuid.py</code> Tutorial","text":"<p>This tutorial provides a detailed guide on using the <code>filter_uuid.py</code> script to interact with Akri instances in a Kubernetes cluster, filter devices, and generate a FlashJob YAML for firmware updates using the FlashJob Operator. For instructions on deploying the FlashJob Operator, refer to the installation guide.</p>"},{"location":"tutorials/filter_uuid.html#overview","title":"Overview","text":"<p>The <code>filter_uuid.py</code> script is a Python utility designed to simplify the process of selecting Akri-discovered IoT devices in a Kubernetes cluster and generating a FlashJob YAML file for firmware flashing. It supports filtering devices by UUID, device type, and application type, allows user selection of devices, and enables gradual rollout of firmware updates in batches.</p>"},{"location":"tutorials/filter_uuid.html#prerequisites","title":"Prerequisites","text":"<p>Before using the <code>filter_uuid.py</code> script, ensure the following are in place:</p> <ul> <li>Python 3.x: Installed on your system.</li> <li>Required Python Packages:   <pre><code>pip install kubernetes pyyaml\n</code></pre></li> <li>Kubernetes Cluster: A running Kubernetes (e.g., k3s) cluster with Akri instances configured.</li> <li>kubectl: Configured with access to the cluster (ensure the correct context is set).</li> <li>FlashJob Operator: Deployed in the cluster. Refer to installation for deployment instructions.</li> <li>Akri Instances: Configured in the <code>default</code> namespace (or modify the script for other namespaces).</li> </ul>"},{"location":"tutorials/filter_uuid.html#script-overview","title":"Script Overview","text":"<p>The <code>filter_uuid.py</code> script performs the following tasks:</p> <ol> <li>Fetch Akri Instances: Retrieves Akri instances from the Kubernetes API server.</li> <li>Filter Instances: Filters devices based on user-provided criteria (UUID, device type, application type).</li> <li>User Selection: Allows interactive selection of specific or all Akri instances.</li> <li>Firmware Specification: Prompts for firmware image details.</li> <li>Gradual Rollout: Supports batch-based firmware updates with configurable batch sizes and delays.</li> <li>YAML Generation: Saves selected UUIDs and firmware details to a FlashJob YAML file.</li> <li>Apply YAML: Applies the generated YAML to the cluster using <code>kubectl</code>.</li> </ol>"},{"location":"tutorials/filter_uuid.html#step-by-step-usage","title":"Step-by-Step Usage","text":""},{"location":"tutorials/filter_uuid.html#1-run-the-script","title":"1. Run the Script","text":"<p>To use the <code>filter_uuid.py</code> script, first clone the FlashJob Operator repository:</p> <pre><code>git clone https://github.com/nubificus/flashjob_operator\ncd flashjob_operator\n</code></pre> <p>Execute the script in a terminal:</p> <pre><code>python3 filter_uuid.py\n</code></pre> <p>The script will guide you through an interactive process to filter devices, select instances, and configure firmware updates.</p>"},{"location":"tutorials/filter_uuid.html#2-filter-akri-instances","title":"2. Filter Akri Instances","text":"<p>The script prompts you to filter Akri instances based on the following criteria:</p> <ul> <li>Device Type: Filter devices by their type (e.g., <code>esp32</code>). Press Enter to skip.</li> <li>Application Type: Filter by application type (e.g., <code>thermo</code>). Press Enter to skip.</li> <li>UUID: Filter by a specific UUID. Press Enter to skip.</li> </ul> <p>Example prompt:</p> <pre><code>Enter device type to filter (or press Enter to skip): esp32\nEnter application type to filter (or press Enter to skip): thermo\nEnter UUID to filter (or press Enter to skip):\n</code></pre> <p>The script queries the Kubernetes API and lists matching Akri instances.</p>"},{"location":"tutorials/filter_uuid.html#3-select-devices","title":"3. Select Devices","text":"<p>After filtering, the script displays a list of available Akri instances, each with an index, UUID, device type, and application type. For example:</p> <pre><code>Available Akri Instances:\n[0] UUID: d95c7c2d-7dc5-427b-9bf7-51a5d299c99e, Device Type: esp32, Application Type: thermo\n[1] UUID: 44606d10-7c29-4098-9d6a-dc16f95090d1, Device Type: esp32, Application Type: thermo\n</code></pre> <p>You are prompted to select devices:</p> <ul> <li>Select All: Enter <code>y</code> to select all listed UUIDs.</li> <li>Select Specific Devices: Enter <code>n</code> and provide a comma-separated list of indices (e.g., <code>0,1</code>).</li> </ul> <p>Example:</p> <pre><code>Do you want to select all UUIDs? (y/n): y\n</code></pre>"},{"location":"tutorials/filter_uuid.html#4-enter-firmware-details","title":"4. Enter Firmware Details","text":"<p>Next, specify the firmware image to use for flashing the selected devices. Provide the full image path, including the repository and tag. For example:</p> <pre><code>Enter the firmware to use: harbor.nbfc.io/nubificus/esp32:x.x.xxxxxxx\n</code></pre>"},{"location":"tutorials/filter_uuid.html#5-configure-gradual-rollout-optional","title":"5. Configure Gradual Rollout (Optional)","text":"<p>To manage large-scale updates, the script supports gradual rollout in batches:</p> <ul> <li>Batch Size: Specify the number of devices per batch (default: <code>5</code>).</li> <li>Delay Between Batches: Specify the delay in seconds between batches (default: <code>60</code>).</li> </ul> <p>Example:</p> <pre><code>Enter the number of UUIDs per batch (default is 5): 2\nEnter the delay between batches in seconds (default is 60): 30\n</code></pre>"},{"location":"tutorials/filter_uuid.html#6-apply-the-flashjob","title":"6. Apply the FlashJob","text":"<p>The script generates a FlashJob YAML file (e.g., <code>flashjob_operator/config/samples/application_v1alpha1_flashjob.yaml</code>) with the selected UUIDs and firmware details. It then applies the YAML to the cluster using <code>kubectl</code>.</p> <p>Example output:</p> <pre><code>Applying batch 1 with UUIDs: ['d95c7c2d-7dc5-427b-9bf7-51a5d299c99e', '44606d10-7c29-4098-9d6a-dc16f95090d1']\nUUIDs saved to flashjob_operator/config/samples/application_v1alpha1_flashjob.yaml\nSuccessfully applied flashjob_operator/config/samples/application_v1alpha1_flashjob.yaml\nWaiting for 30 seconds before the next batch...\n</code></pre> <p>For each batch, the script updates the YAML with the next set of UUIDs and applies it after the specified delay.</p>"},{"location":"tutorials/filter_uuid.html#example-workflow","title":"Example Workflow","text":"<p>Here\u2019s a complete example of running the script:</p> <pre><code>$ python3 filter_uuid.py\nEnter device type to filter (or press Enter to skip): esp32\nEnter application type to filter (or press Enter to skip): thermo\nEnter UUID to filter (or press Enter to skip):\n\nAvailable Akri Instances:\n[0] UUID: d95c7c2d-7dc5-427b-9bf7-51a5d299c99e, Device Type: esp32, Application Type: thermo\n[1] UUID: 44606d10-7c29-4098-9d6a-dc16f95090d1, Device Type: esp32, Application Type: thermo\n\nDo you want to select all UUIDs? (y/n): y\nEnter the firmware to use: harbor.nbfc.io/nubificus/esp32:x.x.xxxxxxx\nEnter the number of UUIDs per batch (default is 5): 2\nEnter the delay between batches in seconds (default is 60): 30\n\nApplying batch 1 with UUIDs: ['d95c7c2d-7dc5-427b-9bf7-51a5d299c99e', '44606d10-7c29-4098-9d6a-dc16f95090d1']\nUUIDs saved to flashjob_operator/config/samples/application_v1alpha1_flashjob.yaml\nSuccessfully applied flashjob_operator/config/samples/application_v1alpha1_flashjob.yaml\nWaiting for 30 seconds before the next batch...\n</code></pre>"},{"location":"tutorials/filter_uuid.html#generated-flashjob-yaml","title":"Generated FlashJob YAML","text":"<p>The script generates a YAML file like the following, which is used by the FlashJob Operator to manage firmware updates:</p> <pre><code>apiVersion: application.flashjob.nbfc.io/v1alpha1\nkind: FlashJob\nmetadata:\n  name: flashjob\n  namespace: default\nspec:\n  applicationType: thermo\n  device: esp32\n  externalIP:\n  firmware: harbor.nbfc.io/nubificus/esp32:x.x.xxxxxxx\n  flashjobPodImage: harbor.nbfc.io/nubificus/iot/x.x.xxxxxxx\n  hostEndpoint:\n  uuid:\n    - d95c7c2d-7dc5-427b-9bf7-51a5d299c99e\n    - 44606d10-7c29-4098-9d6a-dc16f95090d1\n  version: \"0.2.0\"\n</code></pre>"},{"location":"tutorials/filter_uuid.html#script-functions","title":"Script Functions","text":"<p>The <code>filter_uuid.py</code> script includes the following key functions:</p> <ul> <li>get_akri_instances(): Queries the Kubernetes API to retrieve Akri instances.</li> <li>filter_instances(): Filters instances based on user-provided UUID, device type, and application type.</li> <li>user_select_instances(): Handles interactive selection of Akri instances.</li> <li>save_uuids_to_yaml(): Generates and saves the FlashJob YAML file with selected UUIDs and firmware details.</li> <li>apply_yaml(): Applies the generated YAML file to the cluster using <code>kubectl</code>.</li> <li>gradual_rollout(): Manages batch-based application of the YAML file with specified delays.</li> </ul>"},{"location":"tutorials/filter_uuid.html#tips-notes","title":"Tips &amp; Notes","text":"<ul> <li>Namespace: The script assumes Akri instances are in the <code>default</code> namespace. If your instances are in a different namespace, modify the script or specify the namespace in the YAML.</li> <li>kubectl Context: Ensure the <code>kubectl</code> context is set to the correct cluster before running the script.</li> <li>Troubleshooting: If the script or FlashJob application fails, check the FlashJob Operator logs:   <pre><code>kubectl logs -n operator-system deployment/flashjob-operator\n</code></pre></li> <li>Batch Configuration: Adjust batch size and delay for gradual rollout based on your cluster\u2019s capacity and device requirements.</li> </ul>"},{"location":"tutorials/filter_uuid.html#troubleshooting-common-issues","title":"Troubleshooting Common Issues","text":"<ul> <li>Error: Kubernetes API Unreachable: Verify that <code>kubectl</code> is configured correctly and the cluster is accessible.</li> <li>No Akri Instances Found: Ensure Akri is deployed and instances are registered in the <code>default</code> namespace.</li> <li>YAML Application Fails: Check the operator logs (<code>kubectl logs -n operator-system deployment/flashjob-operator</code>) and verify the firmware image is valid.</li> <li>Script Fails to Save YAML: Ensure the script has write permissions in the target directory (<code>flashjob_operator/config/samples/</code>).</li> </ul> <p>This tutorial should help you effectively use the <code>filter_uuid.py</code> script to manage firmware updates for IoT devices with the FlashJob Operator. For further details on deploying the operator, see installation.</p>"},{"location":"tutorials/onboarding.html","title":"Onboarding","text":""},{"location":"tutorials/ota-agent.html","title":"OTA Agent","text":"<p>This is the installation tutorial page for the OTA Agent.</p>"},{"location":"tutorials/ota-agent.html#tls","title":"TLS","text":"<p>The OTA Agent requires secure communication with the microcontroller device, therefore we utilize the OpenSSL tool to generate a private key and the corresponding certificate, which can be used afterwards to run our TLS server.</p> <pre><code>openssl genpkey -algorithm RSA -out key.pem\nopenssl req -new -x509 -key key.pem -out cert.pem -days 365\n</code></pre>"},{"location":"tutorials/ota-agent.html#build","title":"Build","text":"<pre><code>git clone https://github.com/nubificus/ota-agent.git --recursive\ncd ota-agent\ncd  mbedtls &amp;&amp; git submodule update --init &amp;&amp; make -j$(nproc) &amp;&amp; cd -\nmake\n\nexport DICE_AUTH_URL=...     #Attestaion Server URL\nexport NEW_FIRMWARE_PATH=... #Path to binary artifact to be used in OTA\nexport SERVER_CRT_PATH=...   #Path to TLS Server certificate\nexport SERVER_KEY_PATH=...   #Path to TLS Server private key\n./ota-agent\n</code></pre>"},{"location":"tutorials/ota-service.html","title":"ESP32 OTA Component","text":"<p>This is the installation tutorial page for the ESP32 OTA Component.</p> <p><code>ota-service</code> is an ESP32 Component for performing Over the Air updates. The component contains only the handlers. To setup the functions as akri-endpoints handlers, see ESP32 Akri Component.</p>"},{"location":"tutorials/ota-service.html#how-to-use","title":"How to use","text":"<pre><code>cd &lt;path-to-your-esp-idf-project&gt;\nmkdir -p components\ncd components\ngit clone https://github.com/nubificus/ota-service.git\n</code></pre> <p>Add the component to your project by simply adding the following line inside <code>idf_component_register()</code> of <code>&lt;path-to-your-esp-idf-project&gt;/main/CMakeLists.txt</code>:</p> <pre><code>REQUIRES ota-service\n</code></pre> <p>E.g:</p> <pre><code>idf_component_register(SRCS \"test.c\"\n                       INCLUDE_DIRS \".\"\n                       REQUIRES ota-service)\n</code></pre> <p>You may also have to add the following configuration to resolve some <code>mbedtls</code> issues:</p> <pre><code>idf.py menuconfig\n</code></pre> <p>and enable <code>Component config -&gt; mbedTLS -&gt; HKDF Algorithm (RFC 6859)</code></p> <p>Afterwards, you can include the component's header file:</p> <pre><code>#include \"ota-service.h\"\n</code></pre> <p>The component follows the secure OTA workflow when <code>OTA_SECURE</code> macro is defined. Otherwise, the update is non-secure.</p>"},{"location":"tutorials/ota-update.html","title":"OTA update","text":""},{"location":"tutorials/secure-boot-v2.html","title":"Secure Boot V2","text":"<p>Official Documentation</p> <p>This guide provides information on how to enable secure boot V2 on esp32 devices, how to generate V2 keys and how to sign images (or partition tables) based on the V2 security mechanism of esp32 devices and esp-idf framework.</p> <p>Not every esp32 device supports V2 Secure Boot. It's supported by ECO 3 onwards. Furthermore, devices that support V2 Secure Boot, probably support V1, too (see Secure-Boot.md). However, the official documentation mentions that \"It is recommended that users use Secure Boot V2 if they have a chip version that supports it. Secure Boot V2 is safer and more flexible than Secure Boot V1.\"</p>"},{"location":"tutorials/secure-boot-v2.html#guide","title":"Guide","text":""},{"location":"tutorials/secure-boot-v2.html#step-1","title":"Step 1","text":"<p>First of all, we need an ESP32 Project to use. From the esp-idf repository, you could use <code>examples/get-started/hello_world</code>. Of course, you must have installed esp-idf previously - the repository contains docs. Afterwards, to view some information about the device you are working on, run:</p> <pre><code>esptool.py flash_id\n</code></pre> <p>In the next steps, you will have to set the flash size in menuconfig, as long as the target device.</p>"},{"location":"tutorials/secure-boot-v2.html#step-2","title":"Step 2","text":"<p>Set the target device by running:</p> <pre><code>idf.py set-target &lt;dev-target&gt;\n</code></pre>"},{"location":"tutorials/secure-boot-v2.html#step-3","title":"Step 3","text":"<p>Set the flash size in your sdkconfig file by using</p> <pre><code>idf.py menuconfig\n</code></pre> <p>And set the right value in <code>Serial flasher config -&gt; Flash size</code></p>"},{"location":"tutorials/secure-boot-v2.html#step-4","title":"Step 4","text":"<p>Generate a secure boot signing key v2.</p> <p>Important The keys used to sign binary images (bootloader, application, partition table) in Secure Boot V1 are different than those in V2. This means you can't just use <code>espsecure.py generate_signing_key</code> or use an existing V1 key. The command used to generate V2 keys is the following:</p> <pre><code>espsecure.py generate_signing_key --version 2 --scheme rsa3072 &lt;output-file.pem&gt;\n</code></pre> <p>or</p> <pre><code>openssl genrsa -out &lt;output-file.pem&gt; 3072\n</code></pre> <p>Afterwards, we use use this file for signing images.</p>"},{"location":"tutorials/secure-boot-v2.html#step-5","title":"Step 5","text":"<p>Enable Secure Boot V2 in menuconfig: Run</p> <pre><code>idf.py menuconfig\n</code></pre> <p>and select the following options:</p> <pre><code>1. [*] Security features -&gt; Enable hardware Secure Boot in bootloader\n\n2. [*] Security features -&gt; Enable hardware Secure Boot in bootloader -&gt; Select\n   secure boot version -&gt; Enable Secure Boot version 2\n\n3. [*] Sign binaries during build\n\n4. Secure boot private signing key: &lt;key-path.pem&gt;\n\n5. UART ROM download mode: \"Enabled (not recommended)\"\n</code></pre> <p>Regarding the last option, enabling UART ROM download mode lets us flash the board using tools like <code>esptool.py</code> or <code>idf.py flash</code>. However, in production environments where we would like to protect our boards from physical attacks, we should probably set this option to <code>Permanently disabled (recommended)</code>.</p> <p>Furthermore, bootloader binaries are usually larger when secure boot is enabled and partition table default offset <code>0x8000</code> is not enough. You can change that to <code>0x10000</code> in <code>Partition Table -&gt; Offset of partition table</code></p> <p>Before moving forward, I would recommend you to cleanup the directory from previous builds by running:</p> <pre><code>idf.py fullclean\n</code></pre>"},{"location":"tutorials/secure-boot-v2.html#step-6","title":"Step 6","text":"<p>Now, to build the bootloader, application image and partition table (and sign them, too), run:</p> <pre><code>idf.py build\n</code></pre> <p>If you would like to build only the bootloader, you could also run:</p> <pre><code>idf.py bootloader\n</code></pre> <p>Those commands will also print instructions on how to flash the bootloader. For example, in my system, the printed message is:</p> <pre><code>==============================================================================\nBootloader built. Secure boot enabled, so bootloader not flashed automatically.\nTo sign the bootloader with additional private keys.\n    /home/ilias/.espressif/python_env/idf5.4_py3.8_env/bin/python /home/ilias/esp-idf/components/esptool_py/esptool/espsecure.py sign_data -k secure_boot_signing_key2.pem -v 2 --append_signatures -o signed_bootloader.bin build/bootloader/bootloader.bin\nSecure boot enabled, so bootloader not flashed automatically.\n    /home/ilias/.espressif/python_env/idf5.4_py3.8_env/bin/python  /home/ilias/esp-idf/components/esptool_py/esptool/esptool.py --chip esp32s2 --port=(PORT) --baud=(BAUD) --before=default_reset --after=no_reset write_flash --flash_mode dio --flash_freq 80m --flash_size keep 0x1000 /home/ilias/esp-idf/examples/get-started/blink/build/bootloader/bootloader.bin\n==============================================================================\n</code></pre> <p>As you can see, esp-idf tells us that Secure boot enabled, so bootloader not flashed automatically. Therefore, we could use recommended command to flash the bootloader. In a more generic form:</p> <pre><code>esptool.py --before=default_reset --after=no_reset write_flash --flash_mode dio --flash_freq 80m --flash_size keep 0x1000 build/bootloader/bootloader.bin\n</code></pre> <p>You may have to define explicitly <code>--chip</code> or <code>--port</code> options. In my case, they were <code>--chip esp32s2</code> and <code>--port=/dev/ttyUSB0</code>.</p>"},{"location":"tutorials/secure-boot-v2.html#step-7","title":"Step 7","text":"<p>Now, we can flash the application by using the <code>idf.py flash</code> command. If you have previously built the application using <code>idf.py build</code>, the application binary has been automatically signed and saved in <code>build</code> directory. For the hello-world example, the file is called <code>hello_world.bin</code>. However, if you previously built the bootloader with <code>idf.py bootloader</code>, you now have to run <code>idf.py build</code> to create and sign the application and the partition table. After that, go ahead and run:</p> <pre><code>idf.py flash\n</code></pre>"},{"location":"tutorials/secure-boot-v2.html#step-8","title":"Step 8","text":"<p>Finally, we can execute our application by running:</p> <pre><code>idf.py monitor\n</code></pre> <p>and you will see the output of the application on the terminal. Secure Boot is now enabled and works fine if the output is the expected.</p> <p>It's necessary not to lose your private key. Otherwise, you won't be able to reflash your board with new applications, bootloaders or partition tables.</p>"},{"location":"tutorials/secure-boot-v2.html#sign-other-images","title":"Sign other images","text":"<p>Sometimes, we may have some already built binaries but they are unsigned. For example, you may have ran <code>idf.py build</code> to a project which is not configured with the secure boot options. This project contains an unsigned application binary file located in <code>build</code> directory (say, app.bin), as well as an unsigned partition table binary file in <code>build/partition_table/</code> (say, partition-table.bin). Saying that, it is possible to sign these files without having to re-build your application. That is possible with the <code>espsecure.py sign_data</code> command. More specifically, you can run:</p> <pre><code>espsecure.py sign_data --version 2 --keyfile PRIVATE_SIGNING_KEY --output build/app-signed.bin build/app.bin\n</code></pre> <p>to sign your application and</p> <pre><code>espsecure.py sign_data --version 2 --keyfile PRIVATE_SIGNING_KEY --output build/partition_table/partition-table.bin build/partition_table/partition-table-signed.bin\n</code></pre> <p>to sign your partition table.</p> <p>Now, based on the offsets configured on the partition table (say, <code>0x10000</code> for the partition table and <code>0x20000</code> for the factory app), you can use <code>esptool.py</code> to flash the signed binaries:</p> <pre><code>esptool.py --before default_reset --after no_reset write_flash --flash_mode dio --flash_size keep --flash_freq 80m 0x10000 build/partition_table/partition-table-signed.bin 0x20000 build/app-signed.bin\n</code></pre> <p>As before, you may have to configure <code>--chip</code> and <code>--port</code>.</p>"},{"location":"tutorials/secure-boot.html","title":"Secure boot v1","text":"<p>We worked on enabling secure boot on devices supporting secure boot v1. The following steps summarize the process:</p>"},{"location":"tutorials/secure-boot.html#1-create-a-private-signing-key","title":"1. Create a private signing key","text":"<p><code>espsecure.py generate_signing_key secure_boot_signing_key.pem</code></p> <p>IMPORTANT!!! Make sure to save that key. If the key is lost, the device can't be used again after secure boot is enabled!</p>"},{"location":"tutorials/secure-boot.html#2-menuconfig","title":"2. Menuconfig","text":"<ul> <li>Security Features</li> <li>Enable hardware Secure Boot in bootloader</li> <li>Secure bootloader mode (Reflashable)</li> <li>Secure boot private signing key -&gt; Path to key</li> <li>Partition Table</li> <li>Offset -&gt; 0x10000</li> </ul>"},{"location":"tutorials/secure-boot.html#3-build-the-bootloader","title":"3. Build the bootloader","text":"<p>Better build in a new directory, so the following command prints instructions</p> <p><code>idf.py -B build-secure bootloader</code></p> <p>This command should print some similar instructions as the following ones:</p> <pre><code>Bootloader built and secure digest generated.\nSecure boot enabled, so bootloader not flashed automatically.\nBurn secure boot key to efuse using:\n    $HOME/.espressif/python_env/idf5.4_py3.8_env/bin/python $HOME/esp-idf/components/esptool_py/esptool/espefuse.py burn_key secure_boot_v1 $HOME/ilias/esp-idf/examples/get-started/hello_world/build-secure/bootloader/secure-bootloader-key-256.bin\nFirst time flash command is:\n    $HOME/.espressif/python_env/idf5.4_py3.8_env/bin/python  $HOME/esp-idf/components/esptool_py/esptool/esptool.py --chip esp32 --before=default_reset --after=no_reset write_flash --flash_mode dio --flash_freq 40m --flash_size 2MB 0x1000 $HOME/esp-idf/examples/get-started/hello_world/build-secure/bootloader/bootloader.bin\n==============================================================================\nTo reflash the bootloader after initial flash:\n    $HOME/.espressif/python_env/idf5.4_py3.8_env/bin/python  $HOME/esp-idf/components/esptool_py/esptool/esptool.py --chip esp32 --before=default_reset --after=no_reset write_flash --flash_mode dio --flash_freq 40m --flash_size 2MB 0x0 $HOME/esp-idf/examples/get-started/hello_world/build-secure/bootloader/bootloader-reflash-digest.bin\n==============================================================================\n</code></pre>"},{"location":"tutorials/secure-boot.html#4-burn-the-secure-key-on-the-device-can-only-be-written-once","title":"4. Burn the secure key on the device (Can only be written once)","text":"<p>Using the first provided command, we burn the secure key on the device's eFuse:</p> <pre><code>$HOME/.espressif/python_env/idf5.4_py3.8_env/bin/python $HOME/esp-idf/components/esptool_py/esptool/espefuse.py  burn_key secure_boot_v1 $HOME/esp-idf/examples/get-started/hello_world/build-secure/bootloader/secure-bootloader-key-256.bin\n</code></pre> <p>It will print among others: <code>Type 'BURN' (all capitals) to continue.</code></p>"},{"location":"tutorials/secure-boot.html#5-flash-the-bootloader","title":"5. Flash the bootloader","text":"<p>You may add the <code>--port</code> argument</p> <pre><code>$HOME/.espressif/python_env/idf5.4_py3.8_env/bin/python  $HOME/esp-idf/components/esptool_py/esptool/esptool.py --chip esp32 --before=default_reset --after=no_reset write_flash --flash_mode dio --flash_freq 40m --flash_size 2MB 0x1000 $HOME/esp-idf/examples/get-started/hello_world/build-secure/bootloader/bootloader.bin\n</code></pre>"},{"location":"tutorials/secure-boot.html#6-build-and-flash-the-app","title":"6. Build and flash the app","text":"<p>It will automatically sign the firmware image</p> <p><code>idf.py -B build-secure flash monitor</code></p> <p>The signed firmware is now running.</p>"},{"location":"tutorials/secure-boot.html#7-sign-another-image","title":"7. Sign another image","text":"<p>If we want to sign an already built firmware image, we can do so by using the following command:</p> <pre><code>espsecure.py sign_data --version 1 --keyfile ./my_signing_key.pem --output ./image_signed.bin image-unsigned.bin\n</code></pre>"},{"location":"tutorials/secure-boot.html#8-flash-the-signed-image","title":"8. Flash the signed image","text":"<p>Afterwards, we can flash the signed app:</p> <pre><code>export BUILD_DIR=/path/to/build_dir/\n\npython3 $HOME/esp-idf/components/esptool_py/esptool/esptool.py --chip esp32 --before default_reset --after hard_reset write_flash --flash_mode dio --flash_size detect 0x10000 $BUILD_DIR/partition_table/partition-table.bin 0x20000 /path/to/image_signed.bin\n</code></pre>"},{"location":"tutorials/setup.html","title":"Basic testbed setup","text":""},{"location":"tutorials/vaccel.html","title":"vAccel integration","text":""}]}