{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Cloud-Native IoT","text":"<p>Welcome to the documentation for our Cloud-Native IoT Platform\u2014an end-to-end system designed for secure onboarding, efficient resource discovery, over-the-air updates, and task offloading across the edge\u2013cloud continuum.</p> <p>This site serves as the central hub for all documentation related to the platform's architecture, components, APIs, and integration patterns.</p>"},{"location":"#highlights","title":"Highlights","text":"<ul> <li>Zero-touch secure device onboarding (DICE-based)</li> <li>Seamless OTA updates for ESP32 and Linux-class devices</li> <li>Akri-based device discovery and inventory creation</li> <li>vAccel-powered offloading to heterogeneous accelerators</li> <li>Kubernetes-native architecture (CRDs, Operators)</li> </ul>"},{"location":"#target-audience","title":"Target Audience","text":"<ul> <li>Platform developers</li> <li>System integrators</li> <li>Edge/cloud orchestrator maintainers</li> <li>Embedded/IoT engineers</li> </ul> <ul> <li> <p> Get started</p> <p> Start here</p> </li> <li> <p> Components</p> <p>Browse through the system basic components</p> <p> View Components</p> </li> <li> <p> Developers</p> <p>Discover how you can contribute!</p> <p> Developer</p> </li> </ul>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"api/","title":"Overview","text":"<p>The Cloud-Native IoT platform exposes a set of RESTful APIs designed to facilitate secure device onboarding, firmware updates, and device discovery through Akri. These endpoints are structured to support both microcontroller-class (e.g., ESP32) and Linux-class devices across the edge\u2013cloud continuum.</p> <p>This section provides a detailed look at two core API groups:</p> <ul> <li>Device API   The Device API handles the lifecycle of IoT devices within the platform. From onboarding to firmware updates, these endpoints are responsible for ensuring secure and seamless device interactions.</li> </ul>"},{"location":"api/openapi-spec/","title":"Device API","text":"<p>Version: 0.1.0 Base path: (Device-local address, e.g., <code>http://{device-ip}</code>)</p>"},{"location":"api/openapi-spec/#endpoints","title":"\ud83d\udccb Endpoints","text":""},{"location":"api/openapi-spec/#get-manageinfo","title":"<code>GET /manage/info</code>","text":"<p>Summary: Get device information Description: Retrieve static information about the IoT device.</p> <p>Responses:</p> <ul> <li><code>200 OK</code>: JSON representation of the device</li> </ul> <pre><code>{\n  \"device\": \"generic-iot-device\",\n  \"application\": \"example-app\",\n  \"version\": \"1.0.0\"\n}\n</code></pre>"},{"location":"api/openapi-spec/#get-manageonboard","title":"<code>GET /manage/onboard</code>","text":"<p>Summary: Retrieve attestation certificate Description: Obtain the device\u2019s attestation certificate in PEM format.</p> <p>Responses:</p> <ul> <li><code>200 OK</code>: PEM-encoded certificate (Content-Type: <code>application/x-pem-file</code>)</li> <li><code>500 Internal Server Error</code>: Certificate retrieval error</li> </ul> <p>Example Error:</p> <pre><code>{\n  \"error\": \"Internal error\",\n  \"details\": \"Stack trace or detailed error info\"\n}\n</code></pre>"},{"location":"api/openapi-spec/#post-manageupdate","title":"<code>POST /manage/update</code>","text":"<p>Summary: Start OTA firmware update Description: Initiates an Over-the-Air update using the provided image and optional arguments.</p> <p>Request Body (application/json):</p> <pre><code>{\n  \"image\": \"harbor.nbfc.io/drop/temp-sensor-capture:v0.1.0\",\n  \"params\": [\"server\", \"192.168.1.100\"]\n}\n</code></pre> <p>Responses:</p> <ul> <li><code>200 OK</code>: Update initiated</li> <li><code>400 Bad Request</code>: Invalid update request</li> <li><code>500 Internal Server Error</code>: Update process failed</li> </ul> <p>Error Example:</p> <pre><code>{\n  \"error\": \"Internal error\",\n  \"details\": \"Stack trace or detailed error info\"\n}\n</code></pre>"},{"location":"api/openapi-spec/#get-appinfo","title":"<code>GET /app/info</code>","text":"<p>Summary: Get app information Description: Retrieve static information about the deployed application on the IoT device.</p> <p>Responses:</p> <ul> <li><code>200 OK</code>: JSON representation of the app</li> </ul> <pre><code>{\n  \"device\": \"temp-sensor\",\n  \"application\": \"temp-sensor-capture\",\n  \"image\": \"harbor.nbfc.io/drop/temp-sensor-capture:v0.1.0\",\n  \"version\": \"1.0.0\"\n}\n</code></pre>"},{"location":"architecture/","title":"Architecture Overview","text":"<p>Our Cloud-Native IoT Platform is designed to securely manage heterogeneous IoT devices and applications across edge and cloud environments. It combines trusted onboarding, modular &amp; secure OTA updates, dynamic discovery based on Akri, and resource offloading within a Kubernetes-native control plane.</p>"},{"location":"architecture/#layers-of-the-architecture","title":"Layers of the Architecture","text":"<ul> <li>Device Layer: ESP32 and Linux-class devices capable of secure boot and attestation (via DICE).</li> <li>Edge Layer: Lightweight Kubernetes clusters or single-node runtimes (e.g., K3s, MicroK8s) managing Akri, OTA agents, and agents to provide compute off-loading capabilities to clients.</li> <li>Cloud/Orchestrator Layer: Manages policies, metadata, and orchestrates device lifecycle, offloading targets, and OTA operations.</li> </ul> <p>Figure 1 presents a high-level architecture diagram of our framework.</p> <p></p>"},{"location":"architecture/#key-technologies","title":"Key Technologies","text":"<ul> <li>Akri for device discovery and Kubernetes resource mapping.</li> <li>DICE Device Identifier Composition Engine) for secure onboarding.</li> <li>vAccel for portable compute offloading.</li> <li>mbedTLS for all device-to-cloud communications.</li> <li>Custom Operators/CRDs for OTA and offloading management.</li> </ul>"},{"location":"architecture/#key-components","title":"Key Components","text":"<ul> <li>Attestation Server</li> <li>OTA Service</li> <li>OTA Agent</li> <li>Discovery Endpoints</li> </ul> <p>For a component-level breakdown, see Components.</p>"},{"location":"architecture/onboarding/","title":"Onboarding Workflow","text":""},{"location":"architecture/onboarding/#required-components","title":"Required Components","text":"<ol> <li>OTA Component running on the device</li> <li>Akri Component running on the device</li> <li>DICE Attestation Server to authenticate the device credentials</li> <li>Discovery Handler to discover the device and onboard it after its verification by the Attestation Server</li> </ol>"},{"location":"architecture/onboarding/#steps-followed","title":"Steps followed","text":"<ol> <li>Start the Attestation Server and submit the UDS of the device about to update</li> <li>The flashed ESP32 device must be equipped with the OTA Component and Akri Component</li> <li>The Discovery Handler periodically sends requests on an IP address range, reaching out the devices belonging on it</li> <li>Device will then be triggered on <code>/onboard</code> with a GET request to transmit its certificate</li> <li>The Discovery Handler (after converting it from DER to PEM format) will send it to the Attestation Server</li> <li>The Attestation Server will verify the given certificate against the available Roots stored on the Redis Database</li> <li>The Attestation Server will respond with <code>200 OK</code> on success, or another HTTP error code on failure</li> <li>On success, the Discovery handler will successfully onboard the device</li> <li>On failure, the device won't be onboarded</li> </ol>"},{"location":"architecture/onboarding/#authentication","title":"Authentication","text":"<p>Attestation is validated using the DICE chain-of-trust, based on Google's Open-DICE. We use DICE certificates to verify the devices of our fleet. More information about our authentication model can be found here.</p>"},{"location":"architecture/onboarding/#onboarding-devices-in-akri","title":"Onboarding devices in Akri","text":"<p>The Akri project uses Discovery Handlers to abstract the discovery logic from the Agent, thus allowing developers to provide new functionality without modifying any Akri core component. This design choice allows intervention in the discovery process by implementing a custom Discovery Handler that verifies any discovered devices before returning them to the Agent.</p> <p>More specifically, the Discovery Handler will first verify that a device is indeed present at a given IP and that it matches the desired application type. Afterwards, it will request the device to send its certificate and will forward said certificate to the Attestation Server to ensure the device is trusted.</p> <p>If this process is successful\u2014and only then\u2014will the device be onboarded into the Akri installation and the Kubernetes cluster, allowing users to interact with it via Broker pods or any other method.</p> <p></p>"},{"location":"architecture/ota-workflow/","title":"OTA Update Workflow","text":""},{"location":"architecture/ota-workflow/#required-components","title":"Required Components","text":"<ol> <li>OTA Component running on the device</li> <li>Akri Component running on the device</li> <li>OTA Agent to communicate with the device and transmit the binary artifact</li> <li>DICE Attestation Server to authenticate the device credentials</li> </ol>"},{"location":"architecture/ota-workflow/#steps-followed","title":"Steps followed","text":"<ol> <li>Start the Attestation Server and submit the UDS of the device about to update</li> <li>Start the OTA Agent, providing the new firmware, Attestation server IP address and TLS credentials. See more here</li> <li>The flashed ESP32 device must be equipped with the OTA Component and Akri Component</li> <li>To initialize the process send a POST request to the device, containing OTA Agent's IP address</li> <li>Device (after notified) connects to the agent over TLS</li> <li>Device transmits its attestation certificate</li> <li>Agent connects to the Attestation Server and transmits the received attestation certificate</li> <li>The Attestation Server will verify the given certificate against the available Roots stored on the Redis Database</li> <li>The Attestation Server will respond with <code>200 OK</code> on success, or another HTTP error code on failure</li> <li>On success, the agent will read the firmware from the given path and transmit it to device</li> <li>The device verifies the signature of the received binary artifact, writes it to an available partition and reboots</li> <li>On failure, the connection will be closed by the agent and no firmware will be transmitted.</li> </ol>"},{"location":"components/","title":"Cloud-native IoT Project Components Overview","text":"<p>This document provides a high-level overview of the key components that make up the Cloud-native IoT project.</p>"},{"location":"components/#secure-onboarding-device-registration","title":"Secure Onboarding &amp; Device Registration","text":"<ul> <li>DICE-based Attestation server: Simple entity deployed in a secure enclave that validates DICE certificates generated from leaf devices.</li> <li>Onboarding and OTA update Service: Component that integrates with the user application and provides endpoints to propagate general and attestation information to the rest of the system.</li> <li>Enhanced Akri Discovery Handler: Facilitates dynamic discovery and inventory of IoT devices within Kubernetes clusters, based on Akri.</li> </ul>"},{"location":"components/#ota-over-the-air-update-framework","title":"OTA (Over-The-Air) Update Framework","text":"<ul> <li>OTA Agent: Manages firmware fetch and provides the update endpoint for devices.</li> <li>OTA Service: Runs on devices to securely receive, verify, and apply firmware updates.</li> <li>TLS Security: Ensures encrypted communication and integrity of update payloads.</li> </ul>"},{"location":"components/#cloud-native-infrastructure","title":"Cloud-Native Infrastructure","text":"<ul> <li>Kubernetes &amp; Operators: All components are deployed and managed using Kubernetes primitives, custom resource definitions (CRDs), and operators.</li> <li>Application building: All components are built and packaged using standard cloud-native tooling.</li> </ul>"},{"location":"components/akri-dh/","title":"Secure HTTP Discovery Handler","text":""},{"location":"components/akri-dh/#overview","title":"Overview","text":"<p>To securely integrate esp32-based devices with Akri and our project, we had to develop a custom Discovery Handler in Go. To achieve that, we developed a new Go package. You can find more about the package in the Go Akri doc. Since <code>esp32</code> devices are WiFi enabled and require connection to the internet for most use-cases, we implemented an HTTP Discovery Handler that scans a given IP range to detect which IPs belong to compatible <code>esp32</code> devices. The Discovery Handler performs a GET request for each IP in that range (at the <code>/info</code> endpoint) and verifies that the device matches a given application type, as defined in the Discovery Details of the Akri configuration.</p> <p>After that, the matching devices are also tested against our attestation server to ensure that they are indeed secure and trusted. Then, the Discovery Handler sends the list of the devices that match the desired application type and are trusted to the agent and the devices are onboarded in our Akri installation as <code>akrii</code> (Akri instances).</p>"},{"location":"components/akri-dh/#discovery-details-parsing","title":"Discovery Details parsing","text":"<p>The Discovery Details is a single string defined when creating a new Akri Configuration. Our Discovery Handler expects this string to be a valid YAML string that will be parsed into the following Go struct:</p> <pre><code>type DiscoveryDetails struct {\n  IPStart     string `yaml:\"ipStart\"` // The first IP of the IP range to scan\n  IPEnd       string `yaml:\"ipEnd\"` // The last IP of the IP range to scan\n  Application string `yaml:\"applicationType\"` // The application type to match devices\n  Secure      bool   `yaml:\"secure\"` // Whether to ensure the devices are secure with the attestation server\n}\n</code></pre> <p>An example configuration including DiscoveryDetails:</p> <pre><code>custom:\n  configuration:\n    ...\n    discoveryDetails: |\n      ipStart: 192.168.11.36\n      ipEnd: 192.168.11.45\n      applicationType: fmnist\n      secure: true\n</code></pre>"},{"location":"components/akri-dh/#expected-device-response","title":"Expected device response","text":"<p>The Discovery Handler expects a JSON response to the GET request that send to each IP in the given IP range. That JSON response is unmarshalled into the following Go struct. The application field is used to match the devices, while all the fields are propagated to the Akri agent if the device is properly \"discovered\".</p> <pre><code>type DeviceInfo struct {\n  Device      string `json:\"device\"`\n  Application string `json:\"application\"`\n  Version     string `json:\"version\"`\n}\n</code></pre> <p>An example esp32 device response:</p> <pre><code>$ curl http://192.168.11.131/info\n{\"device\":\"esp32c6\",\"application\":\"vanilla\",\"version\":\"0.0.0\"}\n</code></pre>"},{"location":"components/akri-dh/#packaging-the-discovery-handler","title":"Packaging the Discovery Handler","text":"<p>In order to deploy our Discovery Handler, we need to package it in a Docker image. A sample Dockerfile can be found in the DH repo.</p> <pre><code>FROM docker.io/library/golang:1.24.2-alpine3.21 AS builder\nWORKDIR /app\nCOPY . .\nRUN go mod tidy &amp;&amp; \\\n    go mod vendor &amp;&amp; \\\n    go mod verify\n\nRUN CGO_ENABLED=0 GOOS=linux go build -ldflags \"-s -w\" -ldflags \"-extldflags '-static'\" -o discovery-handler ./cmd/secure-http-discovery-handler\n\nFROM docker.io/library/alpine:3.21\n\nCOPY --from=builder /app/discovery-handler /discovery-handler\nENTRYPOINT [\"/discovery-handler\"]\n</code></pre>"},{"location":"components/akri-dh/#deploying-the-discovery-handler","title":"Deploying the Discovery Handler","text":"<p>After building the Discovery Handler, we need to push the Docker image into a registry. Then we can create an Akri Configuration that uses this Discovery Handler to discover compatible devices, as shown in the instructions</p>"},{"location":"components/akri-integration/","title":"Akri Integration for Onboarding","text":"<p>We extend Akri's discovery handler mechanism to incorporate device verification before exposing devices as Kubernetes resources.</p> <p>Except for the OTA Agent, which utilizes the attestation server to verify whether an incoming connection is authorized or not, we now incorporated this rationale into the Discovery handler. Therefore, a device verification is required before exposing a device as a Kubernetes resource. This enhancement ensures that only verified devices are discoverable and managed within the cluster, strengthening the overall security and preventing unauthorized devices from being represented in Kubernetes.</p> <p></p>"},{"location":"components/attestation-server/","title":"Attestation Server","text":"<p>The attestation server is actually an HTTP server connected to a Redis database. The database is used to hold all the available device root certificates with their key (ie the MAC address). Therefore, the database could be simply described by the following table:</p> Key Certificate MAC-1 Root Cert 1 MAC-2 Root Cert 2 ..... ...... MAC-N Root Cert N <p>Thus, whenever the attestation server receives an incoming POST request with an attestation certificate on its body, it traverses its database to check whether there is any certificate that verifies the given one. In case of verification, it responds with a <code>200 OK</code> HTTP code. Otherwise, the client will receive some error HTTP code.</p> <p>It's important to clarify that the Redis Database is an example solution, to avoid any misunderstanding about security concerns. One could simply utilize another tool to store the Root certificates of the devices.</p>"},{"location":"components/attestation-server/#dice","title":"Dice","text":"<p>DICE certificates are digital certificates issued as part of the DICE architecture, which is a chain-of-trust framework. We use DICE certificates to verify the devices of our fleet. For each device, there is a pair of DICE certificates: the root and the attestation certificate.</p>"},{"location":"components/attestation-server/#assumptions","title":"Assumptions","text":"<ul> <li>The device contains a Unique Device Secret coming from its Vendor, and can   only be read by the bootloader. In our case, we use the MAC, which we assume   is a UDS.</li> <li>The attestation certificate is generated by the device at early boot time   (using the UDS), and can\u2019t be generated anywhere else, since there\u2019s no   access to the UDS. In our case we generate it in application, which is not very   safe.</li> </ul>"},{"location":"components/attestation-server/#root-certificate-public","title":"Root Certificate - Public","text":"<p>The root certificate of each device is coming from its vendor. This means that every time we get a new device, we also get its root certificate, which is unique for each board, and remains the same even if we change its firmware or its bootloader. And that\u2019s because the root certificate is generated using the Unique Device Secret. More specifically, it is generated through <code>generate_uds_cert()</code>, which receives a key as input. The key buffer comes from a Key Derivation Function (KDF), using the MAC address and a 64 bytes salt (common to host and device).</p>"},{"location":"components/attestation-server/#device-attestation-certificate","title":"Device - Attestation Certificate","text":"<p>It is presumably generated in the device at early boot time (assumption 2). Except for the Unique Device Secret, the generator also uses the bootloader hash and the application hash. The verification process involves the transfer of the attestation certificate to the attestation server. The server has access to the corresponding (public) root certificate and verifies the Attestation Cert. against the Root (that is, confirm they are a pair). By following this process, we make sure that the board is authorized to receive a new firmware image and update. Essentially, the verification of an attestation certificate against the root can be achieved with the following command:</p> <pre><code>openssl verify -verbose -ignore_critical -CAfile root.pem attestation.pem\n</code></pre>"},{"location":"components/attestation-server/#workflow","title":"Workflow","text":"<ol> <li>Initialize HTTP server</li> <li>Wait for upcoming connections</li> <li>For each valid POST request (containing an attestation certificate on its body):</li> <li>Retrieve the root certificates contained in the Redis Database</li> <li>Check if any Root certificate verifies the incoming Attest. certificate</li> <li>In case of success, respond with <code>200 OK</code>. Otherwise respond with an error code</li> </ol> <p>For more information, see the tutorial.</p> <p></p>"},{"location":"components/esp32-akri/","title":"ESP32 Akri Component","text":"<p>ESP32 Component for managing the akri-related HTTP endpoints of the device. The component does not contain the handlers, only the functions to setup handlers for the akri-specific endpoints. The corresponding handler functions are contained into the <code>ota-service</code> component. Furthermore, it enables us to start (prerequisite to setup endpoint) and stop the HTTP server, as well as define handlers for generic methods and endpoints.</p>"},{"location":"components/esp32-akri/#responsibilities","title":"Responsibilities","text":"<ul> <li>Provide functions that enable the user to set handlers for various events, like information request, onboarding request and update request.</li> <li>Manage all the rest HTTP endpoints by letting the user set handlers for any endpoint, start and stop the HTTP server.</li> </ul>"},{"location":"components/esp32-akri/#deployment-notes","title":"Deployment Notes","text":"<ul> <li>Packaged as an <code>ESP-IDF</code> component.</li> </ul>"},{"location":"components/esp32-akri/#api-reference","title":"API Reference","text":"<pre><code>int akri_server_start();\n</code></pre> <p>The function can be used to initialize an underlying HTTP server, on which later one can define handler functions for any endpoint.</p> <p>Returns: <code>ESP_OK</code> on success, an error code otherwise.</p> <pre><code>int akri_server_end();\n</code></pre> <p>Correspondingly, <code>akri_server_end()</code> can be used to stop the HTTP server.</p> <p>Returns: <code>ESP_OK</code> on success, an error code otherwise.</p> <pre><code>int akri_set_update_handler(esp_err_t (*handler)(httpd_req_t *req));\n</code></pre> <p>Define a function to handle POST requests on <code>/update</code> endpoint. Keep in mind the body of the request, which should contain an IP in the following form: \"ip: X.X.X.X\"</p> <p>Parameters:</p> <ul> <li><code>handler</code>: a pointer to the function that will handle POST requests on <code>/update</code></li> </ul> <p>Returns: <code>ESP_OK</code> on success, an error code otherwise.</p> <pre><code>int akri_set_info_handler(esp_err_t (*handler)(httpd_req_t *req));\n</code></pre> <p>Define a function to handle GET requests on <code>/info</code> endpoint.</p> <p>Parameters:</p> <ul> <li><code>handler</code>: a pointer to the function that will handle GET requests on <code>/info</code></li> </ul> <p>Returns: <code>ESP_OK</code> on success, an error code otherwise.</p> <pre><code>int akri_set_onboard_handler(esp_err_t (*handler)(httpd_req_t *req));\n</code></pre> <p>Define a function to handle GET requests on <code>/onboard</code> endpoint.</p> <p>Parameters:</p> <ul> <li><code>handler</code>: a pointer to the function that will handle GET requests on <code>/onboard</code></li> </ul> <p>Returns: <code>ESP_OK</code> on success, an error code otherwise.</p> <pre><code>int akri_set_handler_generic(const char *uri,\n                             httpd_method_t method,\n                             esp_err_t (*handler)(httpd_req_t *req));\n</code></pre> <p>The generic define-handler function: You may use it to define functions to handle any endpoint of any method.</p> <p>Parameters:</p> <ul> <li><code>uri</code>: the endpoint uri to configure</li> <li><code>method</code>: the HTTP method that will be handled. See esp-idf.</li> <li><code>handler</code>: a pointer to the function that will handle <code>method</code> requests on <code>/&lt;uri&gt;</code></li> </ul> <p>Returns: <code>ESP_OK</code> on success, an error code otherwise.</p> <p>Make sure you have connected the device on the internet previously.</p>"},{"location":"components/esp32-akri/#endpoints","title":"Endpoints","text":"<p>The exported endpoints from esp32-akri are:</p> <ul> <li><code>/info</code></li> <li><code>/onboard</code></li> <li><code>/update</code></li> </ul>"},{"location":"components/esp32-akri/#info","title":"<code>/info</code>","text":"<p>By sending a GET request to <code>/info</code>, one should retrieve information about the device (device type, firmware version, firmware type etc) in JSON format.</p>"},{"location":"components/esp32-akri/#update","title":"<code>/update</code>","text":"<p>On the other side, the update should be initialized through a POST request. More specifically, the body of the request should include the IP address of the OTA agent in the form: \"ip: A.B.C.D\". The handler then will extract the IP from the request and initialize a TLS (secure) connection between the device and the Agent. If the authentication succeeds, the device will receive the new firmware.</p>"},{"location":"components/esp32-akri/#onboard","title":"<code>/onboard</code>","text":"<p>Currently, the <code>/onboard</code> endpoint waits for GET requests, and responds with the Attestation Certificate in PEM format. The purpose of this endpoint is to enable the onboarding process of the device. Important!! However, the current state is not secure at all, since the certificate is not transferred over a TLS connection, thus it could get stolen by a malicious user with the upper goal to impersonate a trusted device. Saying that, this endpoint should probably receive POST requests, containing the IP address of an external TLS server that could communicate securely with the IoT. For installation instructions see the tutorial.</p>"},{"location":"components/firmware-signing/","title":"Firmware Signing","text":"<p>Firmware authenticity and integrity are essential to prevent malicious updates and bricking attacks.</p>"},{"location":"components/firmware-signing/#signing-workflow","title":"Signing Workflow","text":"<ol> <li>Firmware is signed using an offline private key.</li> <li>OTA Service embeds signature in metadata descriptor.</li> <li>OTA Agent verifies the signature before applying the update.</li> </ol>"},{"location":"components/firmware-signing/#cryptographic-tools","title":"Cryptographic Tools","text":"<ul> <li>ed25519 or ECDSA for digital signatures</li> <li>SHA-256 checksum for integrity verification</li> <li>mbedTLS used for TLS and crypto on-device (ESP32)</li> </ul>"},{"location":"components/firmware-signing/#example-signing-script","title":"Example Signing Script","text":"<pre><code>openssl dgst -sha256 -sign fw-private.pem -out firmware.sig firmware.bin\n</code></pre> <pre><code>{\n  \"version\": \"1.3.2\",\n  \"signature\": \"base64:MEUCIQD...\",\n  \"checksum\": \"sha256:...\",\n  \"public_key_hint\": \"esp32_ca\"\n}\n</code></pre>"},{"location":"components/flashjob-pod/","title":"FlashJob Pod","text":"<p>The FlashJob Pod is a custom Pod deployed by the FlashJob Operator in order to perform the OTA update of a specific ESP32 device.</p> <p>It contains two components:</p> <ul> <li>the esp32-flashjob   component</li> <li>the ota-agent</li> </ul>"},{"location":"components/flashjob-pod/#esp32-flashjob","title":"esp32-flashjob","text":"<p>The <code>esp32-flashjob</code> component is responsible for downloading and extracting the firmware from an OCI image registry, setting up the environment and executing the ota-agent.</p>"},{"location":"components/flashjob-pod/#platform-specific-oci-images","title":"Platform-specific OCI images","text":"<p>We take advantage of multi-platform OCI manifest to help us build and distribute firmware for a number of supported devices and platforms (eg <code>esp32</code>, <code>esp32s2</code>, <code>esp32s3</code> and more).</p> <p>Using our automated build workflow we are able to build and package firmware built for each device type under a single OCI manifest.</p> <p>That way we can have the same version of a firmware built and packaged under the same OCI image tag:</p> <pre><code>$ docker buildx imagetools inspect harbor.nbfc.io/cloud-iot/nubificus/fmnist-esp-ota:resnet-4.4.4-ESP32_KEY3\nName:      harbor.nbfc.io/cloud-iot/nubificus/fmnist-esp-ota:resnet-4.4.4-ESP32_KEY3\nMediaType: application/vnd.docker.distribution.manifest.list.v2+json\nDigest:    sha256:fee40c0d537d1ac83ef003784db3ec586be25f618f5717dc4a482d558310d9d7\n\nManifests:\n  Name:      harbor.nbfc.io/cloud-iot/nubificus/fmnist-esp-ota:resnet-4.4.4-ESP32_KEY3@sha256:1a567013c7245a9cfe44b4015ef3fd805713fbf6017026d907b699c80f7c012f\n  MediaType: application/vnd.docker.distribution.manifest.v2+json\n  Platform:  custom/esp32s2r2\n\n  Name:      harbor.nbfc.io/cloud-iot/nubificus/fmnist-esp-ota:resnet-4.4.4-ESP32_KEY3@sha256:f4040645c64786b86fc5b5f7d90703d071126093d3311329acf01492492d599b\n  MediaType: application/vnd.docker.distribution.manifest.v2+json\n  Platform:  custom/esp32s3\n\n  Name:      harbor.nbfc.io/cloud-iot/nubificus/fmnist-esp-ota:resnet-4.4.4-ESP32_KEY3@sha256:a082451cc409a41e601ce08213eee1a817952a612394a08820979ac567dd0273\n  MediaType: application/vnd.docker.distribution.manifest.v2+json\n  Platform:  custom/esp32s3r8\n</code></pre>"},{"location":"components/flashjob-pod/#esp32-flashjob-workflow","title":"esp32-flashjob workflow","text":"<p>The lifecycle of the <code>esp32-flashjob</code> is the following:</p> <ul> <li>spawns and loads any information for the device and the OTA update from the   environment</li> <li>downloads and extracts the firmware package in the OCI image based on the   requested platform</li> <li>sends a request to the esp32 device to enable OTA flash mode</li> <li>executes the ota-agent capturing all logs</li> </ul>"},{"location":"components/flashjob-pod/#environment-variables","title":"Environment variables","text":"<p>In order to properly download the firmware and setup the environment for ota-agent with the correct parameters, <code>eps32-flashjob</code> requires the following environment variables to be set by the flashjob operator or Akri:</p> <ul> <li><code>DEVICE</code>: The device type (eg esp32s3/esp32s2)</li> <li><code>HOST</code> or <code>HOST_ENDPOINT_*</code>: The IP address of the device</li> <li><code>FIRMWARE</code>: The OCI image with the tag</li> <li><code>DICE_AUTH_SERVICE_SERVICE_HOST</code>: The IP address of the attestation server</li> </ul>"},{"location":"components/flashjob/","title":"FlashJob","text":""},{"location":"components/go-akri/","title":"Akri Discovery Handler package for Go","text":""},{"location":"components/go-akri/#overview","title":"Overview","text":"<p>As stated in Akri documentation, a Discovery Handler is anything that implements the DiscoveryHandler service and Registration client defined in the Akri's discovery gRPC proto file. To enable the discovery of resources (aka devices), we need to implement a Discovery Handler (DH), which performs the actual discovery on behalf of the Agent.</p> <p>The Discovery Handler component has the following lifecycle:</p> <ul> <li>Register with the agent   Upon starting, creates a Registration client and registers itself   with the agent</li> <li>Start DiscoveryHandler service   After registering, creates a DiscoveryHandler service and listens   for Discovery requests</li> <li>Perform discovery   Upon receiving a Discovery request from the agent, parses the Discovery details,   performs the relevant discovery based on said details and returns   a streaming Response containing discovered devices. This is then repeated in a loop   to ensure that the Akri agent is updated with the latest devices.</li> </ul> <p>Akri provides a Discovery Handler template as well as a walk-through on how to implement a custom Discovery Handler. This is very helpful if you are looking to build a Discovery Handler in Rust.</p> <p>To develop a custom Discovery Handler in Go, we created a new Go package (similar to Akri's template) that streamlines the Discovery Handler's lifecycle. This approach requires users to only define the custom device discovery logic and discovery details parsing.</p>"},{"location":"components/go-akri/#usage","title":"Usage","text":"<p>The only logic we need to implement is the actual discovery process. The rest is taken care of by the package.</p>"},{"location":"components/go-akri/#discovery-function","title":"Discovery Function","text":"<p>The Discovery logic must be implemented in a <code>DiscoverFunc</code> as shown below and must be passed to a new DiscoveryApp instance.</p> <pre><code>type DiscoverFunc func(string) ([]*pb.Device, error)\n</code></pre> <p>The input string is the raw discovery details. The developer is responsible to parse them (and set them at deploy time). This function should return a list containing the discovered devices and an error, if any occurred.</p> <p>A sample discovery function can be found in the go-akri repo:</p> <pre><code>func discovery(_ string) ([]*pb.Device, error) {\n    device := &amp;pb.Device{\n        Id: \"dummy-device\",\n        Properties: map[string]string{\n            \"AKRI_HTTP\":        \"http\",\n            \"VERSION\":          \"0.0.1\",\n        },\n        Mounts:      []*pb.Mount{},\n        DeviceSpecs: []*pb.DeviceSpec{},\n    }\n    devices := []*pb.Device{device}\n    return devices, nil\n}\n</code></pre>"},{"location":"components/go-akri/#running-the-app","title":"Running the App","text":"<p>To run the app, we need to define a minimal new DiscoveryApp instance, configure it with the desired discovery function and options and run it:</p> <pre><code>package main\n\nimport (\n    akri \"github.com/nubificus/go-akri/pkg/discovery-handler\"\n    \"github.com/nubificus/go-akri/pkg/pb\"\n)\n\nfunc discovery(_ string) ([]*pb.Device, error) {\n    return nil, nil\n}\n\nfunc main() {\n    app := akri.NewApp(discovery, akri.WithLogLevel(akri.DebugLevel))\n    app.Run()\n}\n</code></pre>"},{"location":"components/go-akri/#configuration-options","title":"Configuration options","text":"<p>The available configuration options are the following:</p>"},{"location":"components/go-akri/#withregisterretries","title":"WithRegisterRetries","text":"<p><code>WithRegisterRetries</code> sets the amount of retries for registering the discovery handler with the Akri agent. (Default is 10)</p>"},{"location":"components/go-akri/#withgrpcshutdowndelay","title":"WithgRPCShutdownDelay","text":"<p><code>WithgRPCShutdownDelay</code> sets the forced shutdown delay for the gRPC server. Normally the gRPC server will shutdown gracefully, but if that takes longer than the forcedGRPCShutdownDelay, the server will stop immediately. (Default is 5 seconds)</p>"},{"location":"components/go-akri/#withdiscoversleep","title":"WithDiscoverSleep","text":"<p><code>WithDiscoverSleep</code> sets the sleep duration between discovery scans. (Default is 30 seconds)</p>"},{"location":"components/go-akri/#withloglevel","title":"WithLogLevel","text":"<p><code>WithLogLevel</code> sets the log level for the discovery handler app. (Default is INFO)</p>"},{"location":"components/go-akri/#withshared","title":"WithShared","text":"<p><code>WithShared</code> sets whether the discovered devices could be used by multiple nodes or can only be ever be discovered by a single node. (Default is false)</p>"},{"location":"components/go-akri/#grpc-code-generation","title":"gRPC code generation","text":"<p>Note: If you are not intending to dig deeper into the package internals (eg. to bring the package up to date with the latest Akri release the package), feel free to skip this section.</p> <p>The first step to build or update this package is to generate the gRPC Client/Service code in Go based on the Akri proto file. The easiest way to achieve this is by using our protobuf generator tool, which is packaged in a Docker image.</p> <p>You can list the latest Akri tags:</p> <pre><code>$ docker run --rm harbor.nbfc.io/nubificus/akri-protobuf:latest --list\n\ud83d\udce6 Latest tags (sorted, limited to 5):\nv0.13.8\nv0.12.20\nv0.12.9\nv0.10.4\nv0.8.23\n</code></pre> <p>You can generate the Go code under <code>/pkg/pb</code> from a specific Akri tag:</p> <pre><code>$ mkdir -p $PWD/pkg/pb\n$ docker run --rm --user $(id -u):$(id -g) -v $PWD/pkg/pb:/out harbor.nbfc.io/nubificus/akri-protobuf:latest v0.12.20\nAkri target tag: v0.12.20\nDownloading protobuf file from https://raw.githubusercontent.com/project-akri/akri/v0.12.20/discovery-utils/proto/discovery.proto\nModifying protobuf file...\nGenerating Go code from protobuf file...\nGo code generated successfully\n</code></pre> <p>Or you can use the latest release by omitting the tag parameter:</p> <pre><code>$ mkdir -p $PWD/pkg/pb\n$ docker run --rm --user $(id -u):$(id -g) -v $PWD/pkg/pb:/out harbor.nbfc.io/nubificus/akri-protobuf:latest\nWarning: No target tag provided.\nUsing latest tag as default.\nAkri target tag: v0.13.8\nDownloading protobuf file from https://raw.githubusercontent.com/project-akri/akri/v0.13.8/discovery-utils/proto/discovery.proto\nModifying protobuf file...\nGenerating Go code from protobuf file...\nGo code generated successfully\n</code></pre>"},{"location":"components/mbedtls/","title":"mbedTLS","text":""},{"location":"components/ota-agent/","title":"OTA Agent","text":"<p>The OTA agent is responsible for communicating with the device and for authenticating it. Actually, the program operates as a TLS server (thus, the communication is secure) and waits for an upcoming connection from the microcontroller that has been requested to update its firmware. As being described in Figures 1 and 2, when it's about to update, the microcontroller will receive a POST request to its <code>/update</code> endpoint. The request will contain an IP address on its body, like <code>ip: A.B.C.D</code>. This IP belongs to the agent, which should have been executed earlier. The agent requires the following arguments to run, which are given as environment variables:</p> <ul> <li><code>NEW_FIRMWARE_PATH</code>: The path to the firmware that will be sent to the   microcontroller (on success)</li> <li><code>DICE_AUTH_URL</code>: The URL to connect to Dice-Auth HTTP server, to authenticate   the connected microcontroller. Under the hood, the agent will send the   received Attestation Certificate, while Dice-Auth will verify it against the   saved Root certificates.</li> <li><code>SERVER_CRT_PATH</code>: The certificate to be used by the TLS server.</li> <li><code>SERVER_KEY_PATH</code>: The private key to be used by the TLS server.</li> </ul> <p>The OTA Agent runs on each device and manages update retrieval and installation in a secure and verifiable manner.</p>"},{"location":"components/ota-agent/#responsibilities","title":"Responsibilities","text":"<ul> <li>Verify the connected device against an attestation server</li> <li>On success, transmit the firmware to leaf device</li> <li>On failure, close the connection</li> </ul>"},{"location":"components/ota-agent/#configuration","title":"Configuration","text":"<ul> <li><code>DICE_AUTH_URL</code>: URL of the attestation server</li> <li><code>NEW_FIRMWARE_PATH</code>: Where to find the new firmware to be used in OTA update</li> <li><code>SERVER_CRT_PATH</code> &amp; <code>SERVER_KEY_PATH</code>: TLS certificate and private key For secure communication</li> </ul>"},{"location":"components/ota-agent/#example-flow","title":"Example Flow","text":"<ol> <li>Agent starts a TLS server (<code>SERVER_CRT_PATH</code> &amp; <code>SERVER_KEY_PATH</code>)</li> <li>Device (after notified) connects to the agent</li> <li>Device transmits its attestation certificate</li> <li>Agent verifies device's identity against the attestation server (<code>DICE_AUTH_URL</code>).</li> <li>On success, the agent will read the firmware from <code>NEW_FIRMWARE_PATH</code> and will send it to device</li> <li>The device applies the update after receiving the entire firmware image and reboots</li> <li>On failure, the connection will be closed by the agent and no firmware will be transmitted.</li> </ol> <p>Updates are only allowed for devices that passed DICE-based onboarding. Finally, ota-agent is not a standalone unit in the overall system layout, but rather a component used by the Flash-Job. However, one could use it as a standalone unit too. For building and running instructions see the tutorial.</p> <p> </p>"},{"location":"components/ota-service/","title":"ESP32 OTA Component","text":"<p>OTA Service is an ESP32 Component for performing Over the Air updates. The component contains only the handlers. To setup the functions as akri endpoints handlers, use the ESP32 Akri Component. The component supports secure OTA updates for the ESP32 devices when used along with rest Cloud-Native-IoT subsystems. Actually, this component provides a function to run when a OTA HTTP request reaches the device. In this case, <code>ota-service</code> will first generate a device certificate (DICE) to authorize the board during the upcoming communication. The board is also responsible to initiate a TLS connection with the OTA Agent, whose IP address was previously extracted from the HTTP POST request. In case of successful authentication, the agent will transmit the new firmware binary artifact to the device. Finally, after writing the firmware to the first available OTA partition, <code>ota-service</code> will verify that the artifact is properly signed with the right private key, and reboot.</p>"},{"location":"components/ota-service/#responsibilities","title":"Responsibilities","text":"<ul> <li>Prepare the board for an OTA firmware update</li> <li>Provide the handler functions to perform the OTA update</li> <li>Prove device's identity</li> <li>Receive new firmware from the agent</li> <li>Verify binary artifact's integrity</li> <li>Handle errors if the OTA update is incomplete</li> <li>Update the board's firmware</li> </ul>"},{"location":"components/ota-service/#endpoints","title":"Endpoints","text":"<ul> <li>Setup by ESP32-Akri.</li> </ul>"},{"location":"components/ota-service/#deployment-notes","title":"Deployment Notes","text":"<ul> <li>Packaged as an <code>ESP-IDF</code> component.</li> </ul> <p>See the tutorial</p>"},{"location":"components/ota-service/#workflow","title":"Workflow","text":"<p>An example workflow is shown below:</p> <ol> <li>Extract Agent's IP address from the POST request</li> <li>Generate a DICE certificate to prove board's identity</li> <li>Initiate a secure TLS connection with the Agent</li> <li>Transmit the certificate</li> <li>In case of successful verificate, receive the new firmware</li> <li>Write the binary artifact on the first available partition</li> <li>Verify new firmware is valid and signed</li> <li>Reboot to update</li> </ol> <p></p>"},{"location":"components/ota-service/#api-reference","title":"API Reference","text":"<pre><code>esp_err_t ota_request_handler(httpd_req_t *req);\n</code></pre> <p>This function can be passed as an argument in <code>akri_set_update_handler()</code> so that it (only) runs when we receive a POST request at <code>/update</code> endpoint. The function will perform all those steps described above.</p> <p>Parameters:</p> <ul> <li><code>req</code>: A pointer to the handle-object of the HTTP request. See here.</li> </ul> <p>Returns: <code>ESP_OK</code> on success, otherwise an error code.</p>"},{"location":"developer/","title":"Overview","text":"<p>The Developer section is intended for contributors and advanced users who want to extend, customize, or integrate with the Cloud-Native IoT platform. It provides the internal architecture details, code structure, and tooling guidance necessary to build and maintain platform components.</p> <p>Whether you're developing new plugins, modifying the onboarding logic, or integrating with third-party systems, this guide will help you understand how the platform works under the hood.</p> <p>What you'll find here:</p> <ul> <li>Application bootstrap: How to structure and code in the logic for your application.</li> <li>Application building: How to build and package ESP32 applications using our automated CI/CD workflows.</li> <li>Firmware packaging: How the workflows package app binaries for multiple ESP32 targets as OCI images and manifests.</li> <li>Initial flash packaging: How the workflows prepare multi-arch OCI manifests for flashing devices for the first time.</li> <li>High-level Architecture as a basis to extend the platform: Guidelines for adding new device types, API endpoints, or custom discovery mechanisms.</li> </ul> <p>This section is the go-to resource for anyone looking to contribute to the platform or build custom integrations atop its core functionality.</p>"},{"location":"developer/applications/","title":"Application development","text":""},{"location":"developer/applications/#introduction","title":"Introduction","text":"<p>Developing IoT applications using ESP32 typically begins with flashing firmware to a single device via USB during development. This is suitable for initial prototyping or testing.</p> <pre><code>idf.py build\nidf.py --port /dev/ttyUSB0 flash monitor\n</code></pre> <p>However, as systems scale, this manual approach becomes infeasible and introduces operational challenges.</p>"},{"location":"developer/applications/#the-challenge-of-scalability","title":"The Challenge of Scalability","text":"<p>Consider an application such as a smart air quality sensor deployed across a whole city. You might start with a handful of devices but eventually grow to manage hundreds or thousands.</p> <p>Challenges emerge when: - A critical firmware update needs to be pushed to all devices. - You want centralized monitoring and lifecycle management of each sensor node.</p> <p>In such cases, physically accessing and flashing each device is impractical and unscalable.</p>"},{"location":"developer/applications/#our-approach-to-scalable-management","title":"Our Approach to Scalable Management","text":"<p>To address these limitations, we have developed the following two components as part of our Cloud-Native IoT Platform, which users can integrate into their ESP32 applications:</p> Component Purpose <code>esp32-akri</code> Enables ESP32 devices to register with Kubernetes clusters via Akri, facilitating automated discovery and management. <code>ota-service</code> Provides secure over-the-air (OTA) firmware updates for ESP32, eliminating the need for manual reflashing. <p>Together, they enable ESP32 devices to become manageable, cloud-native compute nodes.</p>"},{"location":"developer/applications/#integration-guide","title":"Integration Guide","text":""},{"location":"developer/applications/#1-setting-up-the-esp32-project-structure","title":"1. Setting Up the ESP32 Project Structure","text":"<p>Assume your project has the following structure:</p> <pre><code>your-project/\n\u251c\u2500\u2500 components/\n\u251c\u2500\u2500 main/\n\u2502   \u251c\u2500\u2500 main.cc\n\u2502   \u2514\u2500\u2500 CMakeLists.txt\n\u251c\u2500\u2500 CMakeLists.txt\n\u2514\u2500\u2500 ...\n</code></pre> <p>Clone the required components:</p> <pre><code>mkdir -p components &amp;&amp; cd components\ngit clone https://github.com/nubificus/ota-service\ngit clone https://github.com/nubificus/esp32-akri\n</code></pre>"},{"location":"developer/applications/#2-registering-the-components-in-cmake","title":"2. Registering the Components in CMake","text":"<p>Modify <code>main/CMakeLists.txt</code>:</p> <pre><code>idf_component_register(SRCS \"main.cc\"\n                       INCLUDE_DIRS \".\"\n                       REQUIRES esp32-akri ota-service)\n</code></pre>"},{"location":"developer/applications/#3-including-required-headers","title":"3. Including Required Headers","text":"<p>In <code>main.cc</code>:</p> <pre><code>extern \"C\" {\n  #include \"esp32-akri.h\"\n  #include \"ota-service.h\"\n}\n</code></pre>"},{"location":"developer/applications/#4-providing-device-metadata-to-the-system","title":"4. Providing Device Metadata to the System","text":"<p>This function provides metadata for Akri and OTA usage:</p> <pre><code>esp_err_t info_get_handler(httpd_req_t *req)\n{\n    char json_response[128];\n    snprintf(json_response, sizeof(json_response),\n             \"{\"device\":\"%s\",\"application\":\"%s\",\"version\":\"%s\"}\",\n             DEVICE_TYPE, APPLICATION_TYPE, FIRMWARE_VERSION);\n    httpd_resp_set_type(req, \"application/json\");\n    httpd_resp_send(req, json_response, strlen(json_response));\n    return ESP_OK;\n}\n</code></pre>"},{"location":"developer/applications/#5-handling-configuration-via-root-cmake","title":"5. Handling Configuration via Root CMake","text":"<p>Those two components require the following environment variables: * <code>FIRMWARE_VERSION</code>: A unique version identifier for the application you are working on. * <code>DEVICE_TYPE</code>: The specific ESP32 target for which you will build this application. * <code>APPLICATION_TYPE</code>: The type of application you are developing (e.g. image_classification, etc.). * <code>OTA_SECURE</code>: Set this variable when you want to use secure OTA update services.</p> <p>Edit your root <code>CMakeLists.txt</code> to handle environment configuration by adding the code below:</p> <pre><code>if(NOT DEFINED ENV{FIRMWARE_VERSION})\n    add_compile_definitions(FIRMWARE_VERSION=\"0.1.0\")\nelse()\n    add_compile_definitions(FIRMWARE_VERSION=\\\"$ENV{FIRMWARE_VERSION}\\\")\nendif()\n\nif(NOT DEFINED ENV{DEVICE_TYPE})\n    add_compile_definitions(DEVICE_TYPE=\"esp32\")\nelse()\n    add_compile_definitions(DEVICE_TYPE=\\\"$ENV{DEVICE_TYPE}\\\")\nendif()\n\nif(NOT DEFINED ENV{APPLICATION_TYPE})\n    add_compile_definitions(APPLICATION_TYPE=\"generic\")\nelse()\n    add_compile_definitions(APPLICATION_TYPE=\\\"$ENV{APPLICATION_TYPE}\\\")\nendif()\n\nif(DEFINED ENV{OTA_SECURE})\n    add_compile_definitions(OTA_SECURE=1)\nendif()\n</code></pre>"},{"location":"developer/applications/#6-initializing-akri-and-ota-in-the-application","title":"6. Initializing Akri and OTA in the Application","text":"<p>In <code>app_main()</code>:</p> <pre><code>void app_main(void)\n{\n    int ret;\n\n    ret = akri_server_start();\n    if (ret) {\n        ESP_LOGE(\"main\", \"Cannot start Akri server\");\n        abort();\n    }\n\n    ret = akri_set_info_handler(info_get_handler);\n    if (ret) {\n        ESP_LOGE(\"main\", \"Cannot set info handler\");\n        abort();\n    }\n}\n</code></pre>"},{"location":"developer/applications/#7-setting-environment-variables-before-build","title":"7. Setting Environment Variables Before Build","text":"<p>Before building, export the following:</p> <pre><code>export FIRMWARE_VERSION=\"0.0.1\"\nexport DEVICE_TYPE=\"esp32s3\"\nexport APPLICATION_TYPE=\"thermo\"\nexport OTA_SECURE=1\n</code></pre>"},{"location":"developer/applications/#8-building-and-flashing-the-application","title":"8. Building and Flashing the Application","text":"<pre><code>idf.py build\nidf.py --port /dev/ttyUSB0 flash monitor\n</code></pre> <p>Once deployed, your device will be: - Discoverable through Akri. - OTA-ready for firmware updates. - Exposing device metadata via HTTP.</p>"},{"location":"developer/applications/#conclusion","title":"Conclusion","text":"<p>Integrating Akri and OTA-Service into your ESP32 firmware empowers you with production-grade capabilities, including:</p> <ul> <li>Scalable remote firmware management.</li> <li>Dynamic discovery and orchestration through Kubernetes.</li> </ul> <p>When combined with the advanced CI/CD pipeline outlined in the Build Automation section, you can achieve a streamlined development process that enhances efficiency, reduces deployment times, and ensures consistent application performance across your IoT devices.</p>"},{"location":"developer/architecture/","title":"System Architecture","text":"<p>Our platform spans cloud, edge, and device layers with secure orchestration, discovery, and task delegation built into each layer.</p>"},{"location":"developer/architecture/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>+-----------------+\n| Cloud Platform  |\n+-----------------+\n         ^\n         |\n+----------------+   +------------------+    +------------------+\n| Edge Node(s)   |&lt;--| Akri + Offloader |&lt;--&gt;| Neighbor Devices |\n+----------------+   +------------------+    +------------------+\n         ^\n         |\n+----------------+     +-------------------+\n| IoT Devices    |&lt;---&gt;| Onboarding Agent  |\n+----------------+     +-------------------+\n</code></pre>"},{"location":"developer/architecture/#key-components","title":"Key Components","text":"<ul> <li> <p>Onboarding Service: Securely verifies device identity (DICE-based)</p> </li> <li> <p>Akri: Dynamically discovers and exposes verified devices</p> </li> <li> <p>OTA Service &amp; Agent: Secure firmware update management</p> </li> <li> <p>vAccel Offloader: Enables remote compute delegation</p> </li> </ul>"},{"location":"developer/architecture/#technology-stack","title":"Technology Stack","text":"<ul> <li>Kubernetes</li> <li>Akri + CRDs</li> <li>mbedTLS</li> <li>Rust, Go, C, Python</li> </ul>"},{"location":"developer/build_automation/","title":"Build Automation","text":""},{"location":"developer/build_automation/#introduction","title":"Introduction","text":"<p>Building and packaging firmware for embedded devices such as ESP32 can be deceptively complex. The process typically involves managing toolchains, setting device-specific configurations, embedding application models (like TFLite), optionally signing binaries, and deploying the resulting firmware across diverse hardware targets.</p> <p>This section explains: - Common industry practices for firmware building and update workflows. - How ESP-IDF-based firmware is typically built. - How our <code>esp32-build</code> automation system simplifies this process.</p>"},{"location":"developer/build_automation/#firmware-build-practices","title":"Firmware Build Practices","text":"<p>Cloud providers such as AWS IoT and Azure IoT Hub offer end-to-end device management platforms. Here's how firmware build &amp; update is commonly done with them:</p>"},{"location":"developer/build_automation/#aws-iot","title":"AWS IoT","text":"<ul> <li>Build: Developers manually compile firmware using <code>ESP-IDF</code> locally or via CI.</li> <li>Store: The firmware is uploaded to an S3 bucket.</li> <li>Update: AWS IoT Device Jobs service triggers the update by instructing the device to download and apply the firmware from S3.</li> <li>Security: Optional code signing via AWS Signer. Root-of-trust is enforced at device boot.</li> </ul>"},{"location":"developer/build_automation/#azure-iot","title":"Azure IoT","text":"<ul> <li>Build: Similarly to AWS, the firmware is compiled using local/CI toolchains.</li> <li>Store: The firmware is uploaded to Azure Blob Storage.</li> <li>Update: Azure Device Update for IoT Hub delivers the new image to registered devices via update campaigns.</li> <li>Security: Supported but tightly coupled with Microsoft's toolchain and portal-based setup.</li> </ul>"},{"location":"developer/build_automation/#industry-vs-our-ci-based-method","title":"Industry VS Our CI-based Method","text":"Feature AWS / Azure IoT Our Approach Binary Distribution Blob Storage (S3 / Azure Blob) OCI Image Registry (Harbor, DockerHub) Device Targeting Device Shadow / Twin OCI image tags + Manifest CI/CD Integration CodeBuild, Azure DevOps (manual setup) GitHub Actions-native OTA Update Vendor-managed OTA infrastructure <code>esp32-flashjob</code> Extensibility Vendor lock-in Open, OCI-compliant, portable"},{"location":"developer/build_automation/#esp-idf-build","title":"ESP-IDF Build","text":"<p>ESP-IDF is Espressif\u2019s official framework for building ESP32 firmware.</p> <p>A typical manual build includes:</p> <pre><code># Set up ESP-IDF environment\n. $HOME/esp/esp-idf/export.sh\n\n# Configure your target\nidf.py set-target esp32s3\n\n# Configure project settings, PSRAM, partition table, etc.\nidf.py menuconfig\n\n# Build\nidf.py build\n\n# Flash the device (via USB)\nidf.py -p /dev/ttyUSB0 flash\n\n# Monitor serial output\nidf.py -p /dev/ttyUSB0 monitor\n</code></pre> <p>Although this works well for single-target builds, it becomes cumbersome when: - Supporting multiple hardware variants (e.g. <code>esp32s3</code>, <code>esp32s2</code>, etc.). - Managing different RAM configurations (e.g. quad/octal PSRAM, internal RAM). - Creating custom partition tables based not only on the app but also on the hardware target's capabilities. - Embedding additional files (e.g. TensorFlow Lite models) into the firmware or flash partitions. - Signing firmware for secure boot or OTA updates.</p>"},{"location":"developer/build_automation/#ci-powered-build-with-esp32-build","title":"CI-Powered Build with <code>esp32-build</code>","text":"<p>To solve all the above challenges, we\u2019ve created <code>esp32-build</code>: a fully automated CI workflow for building and packaging firmware across many targets.</p>"},{"location":"developer/build_automation/#overview","title":"Overview","text":"<ul> <li>Workflow: GitHub Actions <code>build.yml</code> workflow triggered by <code>ci.yml</code> when the latter is provided with a JSON input.</li> <li>Input: JSON configuration file</li> <li>Apps: List of applications to build, each with its own repository, branch, version, type, optional file paths to a machine-learning model and a prebuild script. It also allows defining custom variables that will be converted to environment variables.</li> <li>Targets: List of hardware targets (e.g., <code>esp32s3</code>, <code>esp32s2</code>).</li> <li>Builder Image: Container image containing the ESP-IDF environment.</li> <li>Keys: List of signing keys (in the form of Github Secrets) for secure boot or OTA updates.</li> <li>Output: Per-target signed firmware, flasher images, and multi-arch manifests.</li> </ul> <p>An example of the expected JSON input form is provided below:</p> <pre><code>{\n  \"apps\": [\n    {\n      \"repo\": \"nubificus/fmnist-esp-ota\",\n      \"branch\": \"main\",\n      \"version\": \"8.8.8\",\n      \"type\": \"fmnist-app\",\n      \"model\": \"models/simple_cnn_tf_frozen.tflite\",\n      \"tensor_allocation_space\": \"204800\",\n      \"load_model_from_partition\": \"1\",\n      \"prebuild\": \"scripts/prepare.sh\"\n    }\n  ],\n  \"targets\": [\"esp32s3\", \"esp32s3r2\"],\n  \"builder_image\": \"harbor.nbfc.io/nubificus/esp-idf:x86_64-slim\",\n  \"keys\": [\"ESP32_KEY3\"]\n}\n</code></pre>"},{"location":"developer/build_automation/#building-process","title":"Building Process","text":"<p>While the building process is quite complex and involves several steps, the most significant ones are as follows:</p> <ol> <li> <p>In case the user has provided a model path in the JSON input, the first step ensures that the model is included in the final container image. The model is also uploaded to our S3 storage server.</p> </li> <li> <p>The project repository is fetched and the workflow checks out the specified branch.</p> </li> <li> <p>Any additional app variables provided by the user are defined as environment variables.</p> </li> <li> <p>If any target device has the suffixes <code>r2</code> or <code>r8</code>, the workflow will set the <code>quad_psram</code> or <code>oct_psram</code> environment variables, respectively. The user can utilize these variables in their project builder to enable the external PSRAM of their device. </p> </li> <li> <p>If the user has specified a \"prebuild\" field that points to a preparation script within the project repository, the workflow will execute it.</p> </li> <li> <p>Using the provided <code>\"builder_image\"</code>, which has the ESP-IDF framework installed, the workflow performs the actual esp32 build for each specified esp32 target device.</p> </li> <li> <p>If the <code>\"keys\"</code> field is not empty, the workflow will sign the firmware generated in the previous step for each secret key.</p> </li> <li> <p>Similar to the model, the firmware binary artifacts are also included in the container image and uploaded to our S3 storage server.</p> </li> <li> <p>For each target device, a container image containing only the firmware image    is constructed for later use by the flash job for OTA updates. However,    instead of producing multiple separate container images, the workflow outputs a    single manifest that includes all of them, allowing the user to check out their    preferred type.</p> </li> <li> <p>Finally, the workflow creates an initial flashing container image that the     user can use to physically flash the esp32 device with the previously     generated binary artifacts. This container image contains binary artifacts for     all device types, and the user can specify the desired type during the <code>docker     run</code> execution. Additionally, since flashing container images are constructed     for both x86 and ARM architectures, the workflow generates a single manifest     containing both.</p> </li> </ol> <p> Figure 1: Example of workflow execution flow illustrating the creation of three firmware building jobs, three firmware container building jobs, and two flashing container building jobs for each of the three device types and two architectures. Additionally, there are two final jobs for assembling the containers into single manifests.</p>"},{"location":"developer/firmware_packaging/","title":"Firmware Packaging","text":""},{"location":"developer/firmware_packaging/#overview","title":"Overview","text":"<p>Our automated build workflow, handles the entire process of building, tagging, and packaging firmware for multiple ESP32 targets. The key steps are: 1. Building firmware images for each target using the same base image name    <code>harbor.nbfc.io/cloud-iot/&lt;repo&gt;</code>. 2. Tagging each target's firmware image with a unique identifier that includes    the target, application type, version, and commit SHA. 3. Combining all target-specific images into a single OCI manifest and pushing    it to our image registry. 4. Storing all artifacts in S3 buckets for easy access and backup.</p>"},{"location":"developer/firmware_packaging/#rationale","title":"Rationale","text":"<p>In IoT deployents, especially when dealing with a large number of versatile ESP32 devices, it is crucial to optimize OTA firmware updates. Creating monlithic firmware images for each device target that include all binaries (bootloader, partition table, application) is inefficient. Obtaining only the updated application binaries and combining them into a single OCI manifest image allows for: - Reduced bandwidth usage: Only the changed binaries are downloaded. - Faster updates: Devices can quickly fetch and apply only the necessary   changes. - Simplified management: All target-specific images are aggregated under a   single manifest, making it easier to manage and deploy updates.</p> <p>In order to exploit these benefits, we have also designed the <code>esp32-flashjob</code> component for performing secure OTA updates. This component uses the manifest to determine which application binary to download and apply, ensuring that devices only fetch the necessary updates without needing to reflash the entire firmware. Further information about the flashjob can be found here.</p>"},{"location":"developer/firmware_packaging/#example-bug-fix-rollout","title":"Example: Bug Fix Rollout","text":"<p>Imagine an app has a bug in version <code>1.0.0</code>.</p> <ol> <li>You fix the bug and build a new firmware <code>1.0.1</code>.</li> <li><code>esp32-build</code> creates:<ul> <li>New firmware images per target.</li> <li>Updated manifest at: <pre><code>harbor.nbfc.io/cloud-iot/&lt;repo&gt;:&lt;app_type&gt;-1.0.1-&lt;key&gt;\n</code></pre></li> </ul> </li> <li>Devices running <code>esp32-flashjob</code> detect the update and self-upgrade.</li> </ol>"},{"location":"developer/initial_flash_packaging/","title":"Initial Flash Packaging","text":""},{"location":"developer/initial_flash_packaging/#overview","title":"Overview","text":"<p>This guide explains how we prepare and publish OCI images for flashing devices for the first time. After the firmware artifacts are built, the <code>esp32-build</code> workflow proceeds with the generation of the initial flash images that is comprised of the following steps: 1. Creation of platform-specific flash images for each requested architecture    (e.g., <code>amd64</code>, <code>arm64</code>) by copying all necessary firmware artifacts into a    container image. All images use the same base name    <code>harbor.nbfc.io/cloud-iot/&lt;repo&gt;-flash</code>. 2. Tagging each platform's flash image with a unique identifier that includes    the platform architecture, application type, version, and commit SHA. 3. Creation of a multi-arch manifest that allows <code>docker run</code> to automatically    select the correct architecture for the host platform.</p>"},{"location":"developer/initial_flash_packaging/#rationale","title":"Rationale","text":"<p>Flashing a blank or factory-reset ESP32 device should be as seamless and platform-independent as possible especially when onboarding devices at scale. Traditionally, this requires knowing the exact ESP32 variant (e.g., <code>esp32s2</code>, <code>esp32s3</code>), having the correct bootloader, partition table, and app binary on hand, and running vendor-specific flashing tools per operating system or architecture. This process is not only error-prone but slows down manufacturing, debugging and deployment workflows. Our approach solves this by packaging all necessary flashing artifacts into OCI images, and combining them in a multi-architecture Docker manifest. The required files are:</p> <ul> <li><code>bootloader.bin</code></li> <li><code>partition-table.bin</code></li> <li><code>ota_data_initial.bin</code></li> <li><code>sdkconfig</code></li> <li><code>partitions.csv</code></li> <li><code>app binary</code></li> </ul>"},{"location":"developer/initial_flash_packaging/#example-onboarding-a-new-device","title":"Example: Onboarding a New Device","text":"<p>Imagine you have a new ESP32 device that needs to be flashed for the first time. The steps are as follows: 1. Build the Firmware: Use the <code>esp32-build</code> workflow to build the firmware    for your device. This will generate the necessary artifacts including the    bootloader, partition table, and application binary and bundle them into a    multi-arch OCI flash manifest. 2. Obtain the Flash Image: After the build completes, you can pull the    appropriate flash image for your device type and architecture from our    registry:    <pre><code>harbor.nbfc.io/cloud-iot/&lt;repo&gt;-flash:&lt;app_type&gt;-&lt;version&gt;\n</code></pre> 3. Run the Flash Job: Use the provided Docker image to flash your device.    The command will look like this:</p> <pre><code>docker run --rm -it --device=&lt;PORT&gt; harbor.nbfc.io/cloud-iot/&lt;repo&gt;-flash:&lt;app_type&gt;-&lt;version&gt; \\\n--port &lt;PORT&gt; --chip &lt;DEVICE_TYPE&gt; --flash_size &lt;FLASH_SIZE&gt; \\\n[--baud &lt;BAUD&gt;] [--override_pt [normal|normal_with_model|no_factory|no_factory_with_model]]\n</code></pre> <p>The <code>--device</code> argument is a Docker option that grants the container access to the specified hardware port. The other custom arguments used in that command are explained as follows:</p> <ul> <li><code>--port</code>: Specifies the port through which the firmware will be flashed,</li> <li><code>--chip</code>: indicates the device type, which may include the suffixes <code>r2</code> and <code>r8</code>,</li> <li><code>--flash_size</code>: defines the flash size of the device being flashed,</li> <li><code>[--baud]</code>: sets the baud rate (frequency) for flashing the board and</li> <li><code>[--override_pt]</code>: allows the explicit replacement of the current partition   table (generated during the build process) with a new one based on user   preferences, expanded across the entire flash of the device. The available   options are:</li> <li><code>normal</code>: Creates three app partitions (one factory and two OTA).</li> <li><code>normal_with_model</code>: Creates three app partitions (one factory and two OTA)     along with a custom tflite model partition.</li> <li><code>no_factory</code>: Creates two app partitions (two OTA), with the app placed in     <code>ota_0</code>.</li> <li><code>no_factory_with_model</code>: Creates two app partitions (two OTA) with the app     placed in <code>ota_0</code>, along with a custom tflite model partition.</li> </ul>"},{"location":"getting-started/","title":"Overview","text":"<p>Whether you're integrating ESP32 microcontrollers or Linux-based devices, our platform facilitates zero-touch provisioning using DICE-based attestation, ensuring device authenticity from the outset. With Akri-based device discovery, you can automatically detect and register devices, creating an up-to-date inventory without manual intervention.</p> <p>For developers and system integrators, the platform offers:</p> <ul> <li>Secure Device Onboarding: Leverage DICE-based mechanisms to authenticate devices during the provisioning process.</li> <li>Seamless OTA Updates: Deploy firmware updates effortlessly to both microcontroller and Linux-class devices.</li> <li>Dynamic Resource Discovery: Utilize Akri to automatically discover and manage connected devices within your network.</li> <li>Task Offloading: Enhance performance by offloading compute-intensive tasks to heterogeneous accelerators using vAccel.</li> <li>Kubernetes Integration: Manage and scale your IoT deployments using Kubernetes-native tools, including Custom Resource Definitions (CRDs) and Operators.</li> </ul> <p>To begin your journey:</p> <ul> <li>Review the Architecture Overview: Understand the core components and their interactions within the platform.</li> <li>Explore the Quickstart Guide: Follow step-by-step instructions to set up your first device and connect it to the platform.</li> <li>Dig into the Installation Guide: Follow step-by-step instructions to set up your first device and connect it to the platform.</li> <li>Dive into Component Details: Gain insights into individual modules like the OTA Service, Akri Integration, and more.</li> <li>Consult the API Documentation: Integrate your applications seamlessly using our comprehensive APIs.</li> </ul> <p>Embark on building scalable, secure, and efficient IoT solutions with the Cloud-Native IoT platform.</p>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This document will guide you through the process of configuring a k3s cluster with all the necessary components to run our Cloud Native IoT framework, namely:</p> <ul> <li>Akri</li> <li>Attestation Server</li> <li>FlashJob Operator</li> <li>Longhorn</li> <li>MetalLB</li> </ul> <p>The cluster used while writing this document was a k3s installation on a Ubuntu 22.04 machine. The k3s cluster was configured with Calico CNI to provide networking.</p>"},{"location":"getting-started/installation/#install-metallb-in-the-cluster","title":"Install MetalLB in the cluster","text":"<p>To ensure the IoT devices can talk to the OTA agent, we need to provide the flashjob pod with a routeable IP. We use metallb to do that.</p> <p>First, we need to apply the manifest:</p> <pre><code>VERSION=v0.13.12\nkubectl apply -f https://raw.githubusercontent.com/metallb/metallb/$VERSION/config/manifests/metallb-native.yaml\n</code></pre> <p>Next, we will create an IP pool:</p> <pre><code>cat &lt;&lt;EOF | tee ip-pool.yaml\napiVersion: metallb.io/v1beta1\nkind: IPAddressPool\nmetadata:\n  name: first-pool\n  namespace: metallb-system\nspec:\n  addresses:\n  - 192.168.5.201-192.168.5.230\nEOF\nkubectl apply -f ip-pool.yaml\n</code></pre> <p>Note: This must be a unique range in our subnet. For our e2e example, we use 192.168.5.221-230 (max 9 concurrent flashjobs).</p> <p>Finally, we will enable l2 advertisement (this will populate ARP entries across the cluster):</p> <pre><code>cat &lt;&lt;EOF | tee l2add.yaml\napiVersion: metallb.io/v1beta1\nkind: L2Advertisement\nmetadata:\n  name: example\n  namespace: metallb-system\nspec:\n  ipAddressPools:\n  - first-pool\nEOF\nkubectl apply -f l2add.yaml\n</code></pre> <p>Note: This is not needed most probably for this setup, but it's good to have it in case an ARP request does not reach the cluster correctly.</p>"},{"location":"getting-started/installation/#install-longhorn-in-the-cluster","title":"Install longhorn in the cluster","text":"<p>The DICE auth server uses Redis as a storage backend. To ensure Redis has persistent storage across reboots an additional storage system for Kubernetes must be installed. In this case, we use Longhorn since it is suggested by the k3s maintainers.</p> <p>First, we need to install <code>open-iscsi</code> in all k3s nodes:</p> <pre><code>sudo apt update\nsudo apt install open-iscsi -y\n</code></pre> <p>Once <code>open-iscsi</code> is properly installed, we can go ahead and install <code>longhorn</code>:</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/longhorn/longhorn/v1.6.0/deploy/longhorn.yaml\n</code></pre>"},{"location":"getting-started/installation/#install-akri-in-the-cluster","title":"Install Akri in the cluster","text":"<p>To install Akri we will use Helm:</p> <pre><code>helm repo add akri-helm-charts https://project-akri.github.io/akri/\nhelm repo update\nKUBECONFIG=/etc/rancher/k3s/k3s.yaml helm install akri akri-helm-charts/akri\n</code></pre> <p>And now, we can verify the Akri Pods are properly deployed:</p> <pre><code>$ kubectl get pods -A | grep akri\ndefault            akri-agent-daemonset-4p249                    1/1     Running     0          43s\ndefault            akri-agent-daemonset-h87nf                    1/1     Running     0          43s\ndefault            akri-controller-deployment-745f4bfc4c-hkg84   1/1     Running     0          43s\ndefault            akri-webhook-configuration-78666f968d-lf875   1/1     Running     0          43s\n</code></pre>"},{"location":"getting-started/installation/#deploy-dice-auth-server-and-redis","title":"Deploy DICE auth server and Redis","text":"<p>To deploy the DICE auth server, we need to also deploy a Redis pod as well as a persistent volume for the Redis pod:</p> <pre><code>cat &lt;&lt;EOF | sudo tee deployment.yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: redis-data\nspec:\n  accessModes:\n    - ReadWriteOnce\n  storageClassName: longhorn\n  resources:\n    requests:\n      storage: 2Gi\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-deployment\n  labels:\n    app: redis\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n        - name: redis\n          image: redis:latest\n          ports:\n            - containerPort: 6379\n          volumeMounts:\n            - mountPath: /data\n              name: redis-storage\n          resources:\n            limits:\n              memory: \"256Mi\"\n              cpu: \"500m\"\n          command: [\"redis-server\", \"--appendonly\", \"yes\"]\n      volumes:\n        - name: redis-storage\n          persistentVolumeClaim:\n            claimName: redis-data\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: redis-service\nspec:\n  selector:\n    app: redis\n  ports:\n    - protocol: TCP\n      port: 6379  # Service port\n      targetPort: 6379  # Pod container port\n  type: ClusterIP  # Change to NodePort or LoadBalancer if external access is needed\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dice-auth-deployment\n  labels:\n    app: dice-auth\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dice-auth\n  template:\n    metadata:\n      labels:\n        app: dice-auth\n    spec:\n      containers:\n        - name: dice-auth\n          image: harbor.nbfc.io/nubificus/iot/dice-auth-server:e2e\n          imagePullPolicy: Always\n          ports:\n            - containerPort: 8000\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: dice-auth-service\nspec:\n  selector:\n    app: dice-auth\n  ports:\n    - protocol: TCP\n      port: 8000  # Service port\n      targetPort: 8000  # Pod container port\n  type: ClusterIP  # Change to NodePort or LoadBalancer if external access is needed\nEOF\nkubectl apply -f deployment.yaml\n</code></pre> <p>We should see the Dice auth and Redis Pod running:</p> <pre><code>$ kubectl get pods\nNAME                                          READY   STATUS    RESTARTS   AGE\n...\ndice-auth-deployment-5cfd8b6dc4-qhzg8         1/1     Running   0          107s\nredis-deployment-64dd9d7478-t4rmd             1/1     Running   0          39s\n</code></pre>"},{"location":"getting-started/installation/#build-the-dice-auth-server-container-image","title":"Build the DICE auth server container image","text":"<p>In case you need to build DICE auth server container image, there is a Dockerfile in the <code>dice-auth</code> repo:</p> <pre><code>git clone https://github.com/nubificus/dice-auth.git\ncd dice-auth\nsudo podman build -t harbor.nbfc.io/nubificus/iot/dice-auth-server:latest .\nsudo podman push harbor.nbfc.io/nubificus/iot/dice-auth-server:latest\n</code></pre>"},{"location":"getting-started/installation/#install-flashjob-operator-in-the-cluster","title":"Install Flashjob Operator in the cluster","text":""},{"location":"getting-started/installation/#method-1-one-click-installation-via-yaml","title":"Method 1: One-Click Installation via YAML","text":"<p>We can install the operator using the official release YAML:</p> <pre><code>kubectl apply -f https://github.com/nubificus/flashjob_operator/releases/download/v1.20.1/inst  all.yaml\n</code></pre>"},{"location":"getting-started/installation/#method-2-helm-installation","title":"Method 2: Helm Installation","text":"<p>Add the FlashJob Operator Helm repository:</p> <pre><code>helm repo add flashjob https://nubificus.github.io/flashjob_operator\nhelm repo update\n</code></pre> <p>Install the Operator using Helm:</p> <pre><code>helm install my-flashjob-operator flashjob/operator \\\n--version 1.20.1 \\\n--namespace operator-system --create-namespace \\\n--set image.repository=harbor.nbfc.io/cloud-iot/akri_operator \\\n--set image.tag=1.20.1\n</code></pre>"},{"location":"getting-started/installation/#wrapping-up","title":"Wrapping up","text":"<p>Now, we have a fully functional cluster with all the necessary components to run our Cloud Native IoT framework. You can continue this journey by preparing an ESP32-device to be onboarded in the cluster!</p>"},{"location":"getting-started/prerequisites/","title":"Prerequisites","text":""},{"location":"getting-started/quickstart/","title":"Quickstart Guide","text":"<p>This guide walks you through the essential steps to deploy the Cloud-Native IoT Platform in a test or development environment.</p>"},{"location":"getting-started/quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster (minikube, k3s, or full-fledged cluster)</li> <li><code>kubectl</code> &amp; <code>helm</code> installed</li> <li>containerd runtime</li> <li>ESP32 development board or Linux device (for onboarding test)</li> </ul>"},{"location":"tutorials/","title":"Overview","text":"<p>This section provides step-by-step tutorials to help you get hands-on experience with the Cloud-Native IoT platform. Whether you're onboarding your first device, deploying firmware updates, or integrating with Kubernetes-native tools, these guides are designed to walk you through practical workflows in real-world scenarios.</p> <p>Each tutorial focuses on a specific component or use case, with detailed instructions, commands, and expected outcomes. These examples are ideal for developers, operators, and system integrators looking to understand the inner workings of the platform.</p> <p>What you'll find here:</p> <ul> <li>Platform Setup: Learn how to deploy and configure platform components using containers or Kubernetes manifests.</li> <li>Secure Boot: Setup ESP32 devices with Secure Boot (v1).</li> <li>Secure Boot v2: Setup ESP32 devices with Secure Boot (v2).</li> <li>Initial device flash: Flash a vanilla device.</li> <li>Device Onboarding: Securely register ESP32 and Linux-based devices using DICE attestation.</li> <li>OTA Firmware Updates: Deploy new firmware builds over-the-air, with integrity checks and rollback support.</li> <li>Akri Discovery Integration: Discover and manage devices dynamically in a Kubernetes cluster.</li> <li> <p>Advanced Scenarios: Offload compute to edge accelerators.</p> </li> <li> <p>End-to-end Scenario: Covering all the above steps.</p> </li> </ul> <p>Prerequisites: Basic familiarity with Linux, Docker, and Kubernetes is recommended.</p> <p>Start with a tutorial that fits your use case, or follow the full sequence to gain a comprehensive understanding of the platform.</p>"},{"location":"tutorials/akri-esp32/","title":"ESP32 Akri Component","text":"<p>This is the installation tutorial page for the ESP32 Akri Component.</p>"},{"location":"tutorials/akri-esp32/#tutorial","title":"Tutorial","text":"<pre><code>cd &lt;path-to-your-esp-idf-project&gt;\nmkdir -p components\ncd components\ngit clone https://github.com/nubificus/esp32-akri.git\n</code></pre> <p>Add the component to your project by simply adding the following line inside <code>idf_component_register()</code> of <code>&lt;path-to-your-esp-idf-project&gt;/main/CMakeLists.txt</code>:</p> <pre><code>REQUIRES esp32-akri\n</code></pre> <p>E.g:</p> <pre><code>idf_component_register(SRCS \"test.c\"\n                       INCLUDE_DIRS \".\"\n                       REQUIRES esp32-akri)\n</code></pre> <p>Afterwards, you can include the component's header file:</p> <pre><code>#include \"esp32-akri.h\"\n</code></pre>"},{"location":"tutorials/dice-auth/","title":"Attestation Server","text":"<p>This is the installation tutorial page of the DICE Attestation Server</p>"},{"location":"tutorials/dice-auth/#about-dice","title":"About DICE","text":"<p>Based on Google's open-dice: https://github.com/google/open-dice</p> <p>In <code>src/</code> we use the following files of <code>open-dice/src/</code>:</p> <ul> <li><code>clear_memory.c</code></li> <li><code>dice.c</code></li> <li><code>mbedtls_ops.c</code></li> <li><code>utils.c</code></li> </ul> <p>In <code>src/include/dice/</code> we use the following files of <code>open-dice/include/dice/</code>:</p> <ul> <li><code>config.h</code></li> <li><code>dice.h</code></li> <li><code>ops.h</code></li> <li><code>utils.h</code></li> </ul>"},{"location":"tutorials/dice-auth/#build","title":"Build","text":"<p>Regarding <code>dice-auth</code> source code, the project is comprised of various sub-projects: <code>dice-auth-service</code> and utilities like <code>submit</code>, <code>list</code>, <code>del</code> and <code>gen_cert</code>.</p>"},{"location":"tutorials/dice-auth/#submit","title":"Submit","text":"<p><code>submit</code> is a program that can be used to submit device entries to a <code>Redis</code> Database. The source code can be found in <code>src/redis_submit.c</code>. First of all, install <code>redis</code>, <code>redis-lib</code> and OpenSSL library:</p> <pre><code>sudo apt-get install redis-server libhiredis-dev libssl-dev\n\n# Now redis should run. You can verify it:\nredis-cli ping\nPONG\n</code></pre> <p>Now you can clone the repository and build <code>submit</code> by running:</p> <pre><code>git clone git@github.com:nubificus/dice-auth.git\ncd dice-auth\nmake submit\n</code></pre> <p>And now you can submit a new device entry to the database by running:</p> <pre><code>./submit UDS(MAC) [redis-IP]\n</code></pre> <p>Internally, <code>submit</code> will generate the Root certificate of the device using the unique device secret (the MAC address) and will submit a new entry to the Redis database. That entry will contain the certificate that will be used later to verify incoming attestation certificates.</p>"},{"location":"tutorials/dice-auth/#list-del-and-gen_cert","title":"<code>list</code>, <code>del</code> and <code>gen_cert</code>","text":"<p>Correspondingly, you can also build the rest utilities, useful for listing the items of the database, removing an item based on its UDS or displaying a root certificate given its UDS.</p> <p>Use <code>make ls</code>, <code>make delete</code> or <code>make gen_cert</code> to build each one. And use them like:</p> <pre><code>./list [redis-IP]\n./del UDS [redis-IP]\n./gen_cert UDS [--pem]\n</code></pre>"},{"location":"tutorials/dice-auth/#dice-auth-service","title":"Dice Auth Service","text":"<p>This is a simple HTTP server that authorizes incoming Attestation certificates. Actually, the server expects <code>POST</code> request that contain the attestation certificate, e.g:</p> <pre><code>curl -X POST &lt;dice-auth-http-endpoint&gt; -H \"Content-Type: text/plain\" --data-binary @/path/to/attestation.pem\n</code></pre> <p>Furthermore, the HTTP server can retrieve the IP of the Redis database from the <code>REDIS_HOST</code> or <code>REDIS_SERVICE_SERVICE_HOST</code> environment variable (in Kubernetes setups, the second variable is probably set automatically). Otherwise, it will attempt to find the database in localhost.</p>"},{"location":"tutorials/dice-auth/#build-and-run","title":"Build and Run","text":"<pre><code>make dice_auth\nmake run\n</code></pre>"},{"location":"tutorials/dice-auth/#cleanup","title":"Cleanup","text":"<pre><code>make clean\n</code></pre>"},{"location":"tutorials/e2e/","title":"Cloud Native IoT Project User's guide","text":"<p>Placeholder document for the end to end scenario</p>"},{"location":"tutorials/e2e/#end-to-end-scenario","title":"End to end scenario","text":""},{"location":"tutorials/e2e/#steps","title":"Steps","text":"<ul> <li>Create script to assign unique and known names to USB devices (based on serialId, vendorId, mac, etc)</li> <li>Create minimal firmware containing OTA functionality and <code>/info</code> endpoint for onboarding</li> <li>Build it with Action (update action to have 2 modes)</li> <li>Flash N devices with minimal firmware (document partition table/secure boot/build settings etc)</li> <li>Create a fresh k3s with latest Akri</li> <li>Deploy our custom operator</li> <li>Deploy our DICE auth server</li> <li>Deploy an onboarding Discovery Handler</li> <li>Post their MAC addresses to DICE auth (automate process)</li> <li>Wait for onboarding Discovery Handler to discover them</li> <li>Deploy 2 additional Discovery Handlers (based on 2 different application types)</li> <li>Use operator to flash X devices with application A and Y devices with application B (leveraging panos' script)</li> <li>Use operator to repurpose 1 or more Devices for application A to B</li> <li>Use operator to upgrade 1 or more Devices to newest firmware version</li> </ul>"},{"location":"tutorials/e2e/#future-tasks","title":"Future tasks","text":"<ul> <li>Implement Dice authentication for the Devices at the onboarding DH step</li> </ul>"},{"location":"tutorials/e2e/#install-akri","title":"Install Akri","text":""},{"location":"tutorials/e2e/#provision-vms","title":"Provision VMs","text":"<pre><code>incus launch images:ubuntu/22.04/cloud cniot01 --project NBFC-long-running-infra --description \"Control plane VM for Akri k3s\" -p default --target @amd64 --vm -c limits.cpu=3 -c limits.memory=4GiB -d root,size=30GiB --vm\nincus launch images:ubuntu/22.04/cloud cniot02 --project NBFC-long-running-infra --description \"Worker VM for Akri k3s\" -p default --target @amd64 --vm -c limits.cpu=2 -c limits.memory=2GiB -d root,size=20GiB --vm\n</code></pre>"},{"location":"tutorials/e2e/#install-k3s-cluster","title":"Install k3s cluster","text":"<p>In the control-plane node:</p> <pre><code>POD_CIDR=\"10.240.32.0/19\"\nSERVICE_CIDR=\"10.240.0.0/19\"\ncurl -sfL https://get.k3s.io | INSTALL_K3S_EXEC='--flannel-backend=none' sh -s - --disable-network-policy --disable \"servicelb\" --disable \"metrics-server\" --cluster-cidr $POD_CIDR --service-cidr $SERVICE_CIDR\n\nsudo addgroup k3s-admin\nsudo adduser $USER k3s-admin\nsudo usermod -a -G k3s-admin $USER\nsudo chgrp k3s-admin /etc/rancher/k3s/k3s.yaml\nsudo chmod g+r /etc/rancher/k3s/k3s.yaml\nnewgrp k3s-admin\n\nPOD_CIDR=\"10.240.32.0/19\"\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.29.1/manifests/tigera-operator.yaml\nwget https://raw.githubusercontent.com/projectcalico/calico/v3.29.1/manifests/custom-resources.yaml\nsed -i \"s|192\\.168\\.0\\.0/16|${POD_CIDR}|g\" custom-resources.yaml\nkubectl apply -f custom-resources.yaml\nrm custom-resources.yaml\n\nsudo cat /var/lib/rancher/k3s/server/node-token\n</code></pre> <p>In the worker node:</p> <pre><code>TOKEN=\"mynodetoken\"\ncurl -sfL https://get.k3s.io | K3S_URL=https://cniot01:6443 K3S_TOKEN=$TOKEN sh -\n</code></pre>"},{"location":"tutorials/e2e/#install-metallb-in-the-cluster","title":"Install MetalLB in the cluster","text":"<p>To ensure the IoT devices can talk to the OTA agent, we need to provide the flashjob pod with a routeable IP. We use metallb to do that.</p> <p>First, we need to apply the manifest:</p> <pre><code>VERSION=v0.13.12\nkubectl apply -f https://raw.githubusercontent.com/metallb/metallb/$VERSION/config/manifests/metallb-native.yaml\n</code></pre> <p>Next, we will create an IP pool:</p> <pre><code>cat &lt;&lt;EOF | tee ip-pool.yaml\napiVersion: metallb.io/v1beta1\nkind: IPAddressPool\nmetadata:\n  name: first-pool\n  namespace: metallb-system\nspec:\n  addresses:\n  - 192.168.5.201-192.168.5.230\nEOF\nkubectl apply -f ip-pool.yaml\n</code></pre> <p>Note: This must be a unique range in our subnet. For our e2e example we use 192.168.5.221-230 (max 9 concurrent flashjobs)</p> <p>Finally, we will enable l2 advertisement (this will populate ARP entries across the cluster):</p> <pre><code>cat &lt;&lt;EOF | tee l2add.yaml\napiVersion: metallb.io/v1beta1\nkind: L2Advertisement\nmetadata:\n  name: example\n  namespace: metallb-system\nspec:\n  ipAddressPools:\n  - first-pool\nEOF\nkubectl apply -f l2add.yaml\n</code></pre> <p>Note: This is not needed most probably for this setup, but it's good to have it in case an arp request does not reach the cluster correctly.</p>"},{"location":"tutorials/e2e/#install-akri-in-the-cluster","title":"Install Akri in the cluster","text":"<p>To install Akri we will need Helm:</p> <pre><code>curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\n</code></pre> <p>Once Helm is installed:</p> <pre><code>helm repo add akri-helm-charts https://project-akri.github.io/akri/\nhelm repo update\nKUBECONFIG=/etc/rancher/k3s/k3s.yaml helm install akri akri-helm-charts/akri\n</code></pre> <p>Verify the Akri Pods are properly deployed:</p> <pre><code>$ kubectl get pods -A | grep akri\ndefault            akri-agent-daemonset-4p249                    1/1     Running     0          43s\ndefault            akri-agent-daemonset-h87nf                    1/1     Running     0          43s\ndefault            akri-controller-deployment-745f4bfc4c-hkg84   1/1     Running     0          43s\ndefault            akri-webhook-configuration-78666f968d-lf875   1/1     Running     0          43s\n</code></pre>"},{"location":"tutorials/e2e/#deploy-flashjob-operator","title":"Deploy Flashjob Operator","text":"<pre><code>cd ~\nsudo apt-get install make -y\ncurl -fsSL https://scripts.gntouts.com/go.sh | bash -s go1.24.2\ngit clone -b uuid_array git@github.com:nubificus/flashjob_operator.git\ncd flashjob_operator\n\nGOPATH=$(go env GOPATH):$PWD make manifests\nGOPATH=$(go env GOPATH):$PWD make install\n\nsudo apt-get install podman -y\nsudo podman login --username gntouts --password &lt;REDACTED&gt; harbor.nbfc.io\ncat &lt;&lt;EOF | sudo tee -a /etc/containers/registries.conf\n[registries.search]\nregistries = ['docker.io']\nEOF\nsudo CONTAINER_TOOL=podman IMG=harbor.nbfc.io/nubificus/iot/flashjob-operator:e2e make docker-build docker-push\nIMG=harbor.nbfc.io/nubificus/iot/flashjob-operator:e2e make deploy\n</code></pre> <p>You should see the Operator Pod running:</p> <pre><code>$ kubectl get pods -A | grep manager\noperator-system    operator-controller-manager-c75bcc686-6lsk2   1/1     Running     0          23s\n</code></pre>"},{"location":"tutorials/e2e/#deploy-dice-auth-server","title":"Deploy DICE auth server","text":""},{"location":"tutorials/e2e/#build-the-dice-auth-server-container-image","title":"Build the DICE auth server container image","text":"<pre><code>cd ~\ngit clone -b feat_submit_mac git@github.com:nubificus/dice-auth.git\ncd dice-auth\nsudo podman build -t harbor.nbfc.io/nubificus/iot/dice-auth-server:e2e .\nsudo podman push harbor.nbfc.io/nubificus/iot/dice-auth-server:e2e\n</code></pre>"},{"location":"tutorials/e2e/#deploy-dice-auth-server-and-redis","title":"Deploy DICE auth server and Redis","text":"<p>The DICE auth server uses Redis as a storage backend. To ensure Redis has persistent storage across reboots an additional storage system for Kubernetes must be installed. In this case, we use Longhorn since it is suggested by the k3s maintainers.</p> <pre><code>sudo apt update\nsudo apt install open-iscsi -y # required by longhorn, make sure to install in both nodes\nkubectl apply -f https://raw.githubusercontent.com/longhorn/longhorn/v1.6.0/deploy/longhorn.yaml\n</code></pre> <pre><code>cat &lt;&lt;EOF | sudo tee deployment.yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: redis-data\nspec:\n  accessModes:\n    - ReadWriteOnce\n  storageClassName: longhorn\n  resources:\n    requests:\n      storage: 2Gi\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-deployment\n  labels:\n    app: redis\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n        - name: redis\n          image: redis:latest\n          ports:\n            - containerPort: 6379\n          volumeMounts:\n            - mountPath: /data\n              name: redis-storage\n          resources:\n            limits:\n              memory: \"256Mi\"\n              cpu: \"500m\"\n          command: [\"redis-server\", \"--appendonly\", \"yes\"]\n      volumes:\n        - name: redis-storage\n          persistentVolumeClaim:\n            claimName: redis-data\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: redis-service\nspec:\n  selector:\n    app: redis\n  ports:\n    - protocol: TCP\n      port: 6379  # Service port\n      targetPort: 6379  # Pod container port\n  type: ClusterIP  # Change to NodePort or LoadBalancer if external access is needed\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dice-auth-deployment\n  labels:\n    app: dice-auth\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dice-auth\n  template:\n    metadata:\n      labels:\n        app: dice-auth\n    spec:\n      containers:\n        - name: dice-auth\n          image: harbor.nbfc.io/nubificus/iot/dice-auth-server:e2e\n          imagePullPolicy: Always\n          ports:\n            - containerPort: 8000\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: dice-auth-service\nspec:\n  selector:\n    app: dice-auth\n  ports:\n    - protocol: TCP\n      port: 8000  # Service port\n      targetPort: 8000  # Pod container port\n  type: ClusterIP  # Change to NodePort or LoadBalancer if external access is needed\nEOF\nkubectl apply -f deployment.yaml\n</code></pre> <p>We should see the Dice auth and Redis Pod running:</p> <pre><code>$ kubectl get pods\nNAME                                          READY   STATUS    RESTARTS   AGE\n...\ndice-auth-deployment-5cfd8b6dc4-qhzg8         1/1     Running   0          107s\nredis-deployment-64dd9d7478-t4rmd             1/1     Running   0          39s\n</code></pre>"},{"location":"tutorials/e2e/#deploy-onboarding-discovery-handler","title":"Deploy Onboarding Discovery Handler","text":"<p>Next, we need to deploy a new Discovery Handler to onboard any devices.</p> <p>To create the new DH we need apply a new Akri Config:</p> <pre><code>controller:\n  enabled: false\nagent:\n  enabled: false\ncleanupHook:\n  enabled: false\nrbac:\n  enabled: false\nwebhookConfiguration:\n  enabled: false\nuseLatestContainers: false\ncustom:\n  configuration:\n    enabled: true\n    name: http-range-onboard # The name of akric\n    capacity: 2\n    discoveryHandlerName: http-discovery-onboard # name of discovery handler, must be unique and matching discovery.name. will be used for socket creation\n    discoveryDetails: | # make sure this is valid YAML\n      ipStart: 192.168.11.20\n      ipEnd: 192.168.11.100\n      applicationType: initial\n      secure: true\n    brokerPod:\n      image:\n        repository: docker.io/gntouts/pause\n        tag: latest\n  discovery:\n    enabled: true\n    image:\n      repository: harbor.nbfc.io/nubificus/iot/akri-discovery-handler-go\n      tag: 61d23fb\n    name: http-discovery-onboard # name of discovery handler, must be unique and matching custom.configuration.discoveryHandlerName\n</code></pre> <pre><code>helm template akri akri-helm-charts/akri -f onboardingConfig.yaml &gt; template.yaml\nkubectl apply -f ./template.yaml\n</code></pre>"},{"location":"tutorials/esp32-initial/","title":"ESP32: Over the air update (OTA)","text":"<p>esp32-ota-update is a vanilla-type firmware for esp32 devices. It doesn't include any actual real world application, however, it can be used to load the necessary tools to perform an OTA update later.</p>"},{"location":"tutorials/esp32-initial/#build","title":"Build","text":"<p>The following commands will build the project.</p> <p>Download esp-idf source</p> <pre><code>cd ~\ngit clone --recursive https://github.com/espressif/esp-idf.git\n</code></pre> <p>Install and set the environment variables</p> <pre><code>cd esp-idf\n./install.sh\n. ./export.sh\n# You have to run the last command every time the environment variables are lost.\n</code></pre> <p>Download the project</p> <pre><code>mkdir projects &amp;&amp; cd projects\ngit clone https://github.com/nubificus/esp32-ota-update.git --recursive\ncd esp32-ota-update\n</code></pre> <p>Security Configuration If you want to use the secure implementation, set the <code>OTA_SECURE</code> environment variable before building. Otherwise, the default configuration is the non-secure.</p> <pre><code>export OTA_SECURE=1\n</code></pre> <p>Build and Flash</p> <pre><code>export FIRMWARE_VERSION=\"0.1.0\"\nexport DEVICE_TYPE=\"esp32s2\"\nexport APPLICATION_TYPE=\"thermo\"\nexport WIFI_SSID=...\nexport WIFI_PASS=...\nidf.py build\nidf.py flash monitor\n</code></pre> <p>Create Docker image</p> <pre><code>export FIRMWARE_VERSION=\"0.1.0\"\nexport DEVICE_TYPE=\"esp32s2\"\nexport APPLICATION_TYPE=\"thermo\"\ntee Dockerfile &gt; /dev/null &lt;&lt; 'EOT'\nFROM scratch\nCOPY ./build/ota.bin /firmware/ota.bin\nLABEL \"com.urunc.iot.path\"=\"/firmware/ota.bin\"\nEOT\ndocker build --push -t harbor.nbfc.io/nubificus/$APPLICATION_TYPE-$DEVICE_TYPE-firmware:$FIRMWARE_VERSION .\nrm -f Dockerfile\n</code></pre> <p>You may have to define the port explicitly</p> <pre><code>idf.py -p &lt;PORT&gt; flash monitor\n# example: -p /dev/ttyUSB0\n</code></pre> <p>Additionally, you may have to change user's rights</p> <pre><code>sudo adduser &lt;USER&gt; dialout\nsudo chmod a+rw &lt;PORT&gt;\n</code></pre> <p>To exit ESP32 monitor</p> <pre><code>Ctr + ]\n</code></pre>"},{"location":"tutorials/esp32-initial/#firmware-provider-app","title":"Firmware Provider App","text":""},{"location":"tutorials/esp32-initial/#non-secure-implementation","title":"Non-secure implementation","text":"<p>In the case of the non-secure implementation, the microcontroller operates as a server, after receiving the post request. Therefore, we need a tcp client to operate as the firmware provider for the microcontroller. The following C program can do this job.</p> <pre><code>/* tcp_client.c */\n\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;errno.h&gt;\n#include &lt;sys/socket.h&gt;\n#include &lt;netinet/in.h&gt;\n#include &lt;arpa/inet.h&gt;\n\n#define SERVER_IP \"192.168.8.62\"\n#define SERVER_PORT 3333\n#define CHUNK_SIZE  1024\n\nvoid send_file(const char *filename) {\n    int sock;\n    struct sockaddr_in server_address;\n    FILE *file;\n    char buffer[CHUNK_SIZE];\n    size_t bytes_read;\n\n    /* Create socket */\n    sock = socket(AF_INET, SOCK_STREAM, 0);\n    if (sock &lt; 0) {\n        perror(\"Error: Socket creation failed\");\n        exit(EXIT_FAILURE);\n    }\n\n    /* Define the server address */\n    server_address.sin_family = AF_INET;\n    server_address.sin_port = htons(SERVER_PORT);\n    server_address.sin_addr.s_addr = inet_addr(SERVER_IP);\n\n    /* Connect to the server */\n    if (connect(sock, (struct sockaddr *)&amp;server_address, sizeof(server_address)) &lt; 0) {\n        perror(\"Error: Connection failed\");\n        close(sock);\n        exit(EXIT_FAILURE);\n    }\n\n    /* Open the file */\n    file = fopen(filename, \"rb\");\n    if (!file) {\n        perror(\"Error: File opening failed\");\n        close(sock);\n        exit(EXIT_FAILURE);\n    }\n\n    /* Read from the file and send it to the server in chunks */\n    while ((bytes_read = fread(buffer, 1, CHUNK_SIZE, file)) &gt; 0) {\n    if (send(sock, buffer, bytes_read, 0) &lt; 0) {\n            perror(\"Error: Failed to send data\");\n            break;\n        }\n    }\n\n    printf(\"File %s sent successfully\\n\", filename);\n\n    /* Close file and socket */\n    fclose(file);\n    close(sock);\n}\n\n\nint main(int argc, char *argv[]) {\n    if (argc != 2) {\n        fprintf(stderr, \"Usage: %s &lt;file_path&gt;\\n\", argv[0]);\n        exit(EXIT_FAILURE);\n    }\n\n    send_file(argv[1]);\n    return 0;\n}\n</code></pre> <p>Don't forget to change SERVER_IP. Then, you can build and run the program using the following commands:</p> <pre><code>gcc -o client tcp_client.c\n./client /path/to/file.bin\n</code></pre>"},{"location":"tutorials/esp32-initial/#secure-implementation","title":"Secure implementation","text":"<p>If you build with <code>OTA_SECURE</code>, you will need to check the more advanced OTA Agent implementation, which works with DICE certificates and TLS connection. For more information, view the repository or the documentation.</p>"},{"location":"tutorials/esp32-initial/#simple-firmware-to-use-for-update","title":"Simple Firmware to use for Update","text":"<p>Now we also need to create a simple firmware image, which will be sent by the server to update ESP32. You can use the <code>hello-world</code> example, located in <code>~/esp-idf/examples/get-started/hello_world/</code>. Build with the following commands:</p> <pre><code>cd ~/esp-idf/examples/get-started/hello_world/\nidf.py build\n</code></pre> <p>The new firmware image is located in <code>~/esp-idf/examples/get-started/hello_world/build/hello_world.bin</code>. You can use that file for the ota update by providing the path when running the client.</p>"},{"location":"tutorials/esp32-initial/#multi-platform-image-building","title":"Multi-platform image building","text":"<pre><code>git clone -b feat_http_server git@github.com:nubificus/esp32-ota-update.git\ncd esp32-ota-update\nmkdir -p dist/esp32s2\ntee env.list &gt; /dev/null &lt;&lt; 'EOT'\nFIRMWARE_VERSION=0.2.0\nDEVICE_TYPE=esp32s2\nAPPLICATION_TYPE=thermo\nEOT\ndocker run --rm -v $PWD:/project -w /project espressif/idf:latest idf.py set-target esp32s2\ndocker run --rm -v $PWD:/project -w /project --env-file ./env.list espressif/idf:latest idf.py build\nsudo mv build/ota.bin dist/esp32s2/ota.bin\n\nmkdir -p dist/esp32s3\ntee env.list &gt; /dev/null &lt;&lt; 'EOT'\nFIRMWARE_VERSION=0.2.0\nDEVICE_TYPE=esp32s3\nAPPLICATION_TYPE=thermo\nEOT\ndocker run --rm -v $PWD:/project -w /project espressif/idf:latest idf.py set-target esp32s3\ndocker run --rm -v $PWD:/project -w /project --env-file ./env.list espressif/idf:latest idf.py build\nsudo mv build/ota.bin dist/esp32s3/ota.bin\n\nmkdir -p dist/esp32\ntee env.list &gt; /dev/null &lt;&lt; 'EOT'\nFIRMWARE_VERSION=0.2.0\nDEVICE_TYPE=esp32\nAPPLICATION_TYPE=thermo\nEOT\ndocker run --rm -v $PWD:/project -w /project espressif/idf:latest idf.py set-target esp32\ndocker run --rm -v $PWD:/project -w /project --env-file ./env.list espressif/idf:latest idf.py build\nsudo mv build/ota.bin dist/esp32/ota.bin\n\nsudo chown -R $USER dist\n\ntee Dockerfile &gt; /dev/null &lt;&lt; 'EOT'\nFROM scratch\nARG DEVICE\nCOPY dist/${DEVICE}/ota.bin /firmware/ota.bin\nLABEL \"com.urunc.iot.path\"=\"/firmware/ota.bin\"\nEOT\n\ndocker buildx build --platform custom/esp32 -t harbor.nbfc.io/nubificus/iot/esp32-thermo-firmware:0.2.0-esp32 --build-arg DEVICE=esp32 . --push --provenance false\ndocker buildx build --platform custom/esp32s2 -t harbor.nbfc.io/nubificus/iot/esp32-thermo-firmware:0.2.0-esp32s2 --build-arg DEVICE=esp32s2 . --push --provenance false\ndocker buildx build --platform custom/esp32s3 -t harbor.nbfc.io/nubificus/iot/esp32-thermo-firmware:0.2.0-esp32s3 --build-arg DEVICE=esp32s3 . --push --provenance false\n\ndocker manifest create harbor.nbfc.io/nubificus/iot/esp32-thermo-firmware:0.2.0 \\\n  --amend harbor.nbfc.io/nubificus/iot/esp32-thermo-firmware:0.2.0-esp32 \\\n  --amend harbor.nbfc.io/nubificus/iot/esp32-thermo-firmware:0.2.0-esp32s2 \\\n  --amend harbor.nbfc.io/nubificus/iot/esp32-thermo-firmware:0.2.0-esp32s3\n\ndocker manifest push harbor.nbfc.io/nubificus/iot/esp32-thermo-firmware:0.2.0\n</code></pre>"},{"location":"tutorials/onboarding/","title":"Onboarding","text":""},{"location":"tutorials/ota-agent/","title":"OTA Agent","text":"<p>This is the installation tutorial page for the OTA Agent.</p>"},{"location":"tutorials/ota-agent/#tls","title":"TLS","text":"<p>The OTA Agent requires secure communication with the microcontroller device, therefore we utilize the OpenSSL tool to generate a private key and the corresponding certificate, which can be used afterwards to run our TLS server.</p> <pre><code>openssl genpkey -algorithm RSA -out key.pem\nopenssl req -new -x509 -key key.pem -out cert.pem -days 365\n</code></pre>"},{"location":"tutorials/ota-agent/#build","title":"Build","text":"<pre><code>git clone https://github.com/nubificus/ota-agent.git --recursive\ncd ota-agent\ncd  mbedtls &amp;&amp; git submodule update --init &amp;&amp; make -j$(nproc) &amp;&amp; cd -\nmake\n\nexport DICE_AUTH_URL=...     #Attestaion Server URL\nexport NEW_FIRMWARE_PATH=... #Path to binary artifact to be used in OTA\nexport SERVER_CRT_PATH=...   #Path to TLS Server certificate\nexport SERVER_KEY_PATH=...   #Path to TLS Server private key\n./ota-agent\n</code></pre>"},{"location":"tutorials/ota-service/","title":"ESP32 OTA Component","text":"<p>This is the installation tutorial page for the ESP32 OTA Component.</p> <p><code>ota-service</code> is an ESP32 Component for performing Over the Air updates. The component contains only the handlers. To setup the functions as akri-endpoints handlers, see ESP32 Akri Component.</p>"},{"location":"tutorials/ota-service/#how-to-use","title":"How to use","text":"<pre><code>cd &lt;path-to-your-esp-idf-project&gt;\nmkdir -p components\ncd components\ngit clone https://github.com/nubificus/ota-service.git\n</code></pre> <p>Add the component to your project by simply adding the following line inside <code>idf_component_register()</code> of <code>&lt;path-to-your-esp-idf-project&gt;/main/CMakeLists.txt</code>:</p> <pre><code>REQUIRES ota-service\n</code></pre> <p>E.g:</p> <pre><code>idf_component_register(SRCS \"test.c\"\n                       INCLUDE_DIRS \".\"\n                       REQUIRES ota-service)\n</code></pre> <p>You may also have to add the following configuration to resolve some <code>mbedtls</code> issues:</p> <pre><code>idf.py menuconfig\n</code></pre> <p>and enable <code>Component config -&gt; mbedTLS -&gt; HKDF Algorithm (RFC 6859)</code></p> <p>Afterwards, you can include the component's header file:</p> <pre><code>#include \"ota-service.h\"\n</code></pre> <p>The component follows the secure OTA workflow when <code>OTA_SECURE</code> macro is defined. Otherwise, the update is non-secure.</p>"},{"location":"tutorials/ota-update/","title":"OTA update","text":""},{"location":"tutorials/secure-boot-v2/","title":"Secure Boot V2","text":"<p>Official Documentation</p> <p>This guide provides information on how to enable secure boot V2 on esp32 devices, how to generate V2 keys and how to sign images (or partition tables) based on the V2 security mechanism of esp32 devices and esp-idf framework.</p> <p>Not every esp32 device supports V2 Secure Boot. It's supported by ECO 3 onwards. Furthermore, devices that support V2 Secure Boot, probably support V1, too (see Secure-Boot.md). However, the official documentation mentions that \"It is recommended that users use Secure Boot V2 if they have a chip version that supports it. Secure Boot V2 is safer and more flexible than Secure Boot V1.\"</p>"},{"location":"tutorials/secure-boot-v2/#guide","title":"Guide","text":""},{"location":"tutorials/secure-boot-v2/#step-1","title":"Step 1","text":"<p>First of all, we need an ESP32 Project to use. From the esp-idf repository, you could use <code>examples/get-started/hello_world</code>. Of course, you must have installed esp-idf previously - the repository contains docs. Afterwards, to view some information about the device you are working on, run:</p> <pre><code>esptool.py flash_id\n</code></pre> <p>In the next steps, you will have to set the flash size in menuconfig, as long as the target device.</p>"},{"location":"tutorials/secure-boot-v2/#step-2","title":"Step 2","text":"<p>Set the target device by running:</p> <pre><code>idf.py set-target &lt;dev-target&gt;\n</code></pre>"},{"location":"tutorials/secure-boot-v2/#step-3","title":"Step 3","text":"<p>Set the flash size in your sdkconfig file by using</p> <pre><code>idf.py menuconfig\n</code></pre> <p>And set the right value in <code>Serial flasher config -&gt; Flash size</code></p>"},{"location":"tutorials/secure-boot-v2/#step-4","title":"Step 4","text":"<p>Generate a secure boot signing key v2.</p> <p>Important The keys used to sign binary images (bootloader, application, partition table) in Secure Boot V1 are different than those in V2. This means you can't just use <code>espsecure.py generate_signing_key</code> or use an existing V1 key. The command used to generate V2 keys is the following:</p> <pre><code>espsecure.py generate_signing_key --version 2 --scheme rsa3072 &lt;output-file.pem&gt;\n</code></pre> <p>or</p> <pre><code>openssl genrsa -out &lt;output-file.pem&gt; 3072\n</code></pre> <p>Afterwards, we use use this file for signing images.</p>"},{"location":"tutorials/secure-boot-v2/#step-5","title":"Step 5","text":"<p>Enable Secure Boot V2 in menuconfig: Run</p> <pre><code>idf.py menuconfig\n</code></pre> <p>and select the following options:</p> <pre><code>1. [*] Security features -&gt; Enable hardware Secure Boot in bootloader\n\n2. [*] Security features -&gt; Enable hardware Secure Boot in bootloader -&gt; Select\n   secure boot version -&gt; Enable Secure Boot version 2\n\n3. [*] Sign binaries during build\n\n4. Secure boot private signing key: &lt;key-path.pem&gt;\n\n5. UART ROM download mode: \"Enabled (not recommended)\"\n</code></pre> <p>Regarding the last option, enabling UART ROM download mode lets us flash the board using tools like <code>esptool.py</code> or <code>idf.py flash</code>. However, in production environments where we would like to protect our boards from physical attacks, we should probably set this option to <code>Permanently disabled (recommended)</code>.</p> <p>Furthermore, bootloader binaries are usually larger when secure boot is enabled and partition table default offset <code>0x8000</code> is not enough. You can change that to <code>0x10000</code> in <code>Partition Table -&gt; Offset of partition table</code></p> <p>Before moving forward, I would recommend you to cleanup the directory from previous builds by running:</p> <pre><code>idf.py fullclean\n</code></pre>"},{"location":"tutorials/secure-boot-v2/#step-6","title":"Step 6","text":"<p>Now, to build the bootloader, application image and partition table (and sign them, too), run:</p> <pre><code>idf.py build\n</code></pre> <p>If you would like to build only the bootloader, you could also run:</p> <pre><code>idf.py bootloader\n</code></pre> <p>Those commands will also print instructions on how to flash the bootloader. For example, in my system, the printed message is:</p> <pre><code>==============================================================================\nBootloader built. Secure boot enabled, so bootloader not flashed automatically.\nTo sign the bootloader with additional private keys.\n    /home/ilias/.espressif/python_env/idf5.4_py3.8_env/bin/python /home/ilias/esp-idf/components/esptool_py/esptool/espsecure.py sign_data -k secure_boot_signing_key2.pem -v 2 --append_signatures -o signed_bootloader.bin build/bootloader/bootloader.bin\nSecure boot enabled, so bootloader not flashed automatically.\n    /home/ilias/.espressif/python_env/idf5.4_py3.8_env/bin/python  /home/ilias/esp-idf/components/esptool_py/esptool/esptool.py --chip esp32s2 --port=(PORT) --baud=(BAUD) --before=default_reset --after=no_reset write_flash --flash_mode dio --flash_freq 80m --flash_size keep 0x1000 /home/ilias/esp-idf/examples/get-started/blink/build/bootloader/bootloader.bin\n==============================================================================\n</code></pre> <p>As you can see, esp-idf tells us that Secure boot enabled, so bootloader not flashed automatically. Therefore, we could use recommended command to flash the bootloader. In a more generic form:</p> <pre><code>esptool.py --before=default_reset --after=no_reset write_flash --flash_mode dio --flash_freq 80m --flash_size keep 0x1000 build/bootloader/bootloader.bin\n</code></pre> <p>You may have to define explicitly <code>--chip</code> or <code>--port</code> options. In my case, they were <code>--chip esp32s2</code> and <code>--port=/dev/ttyUSB0</code>.</p>"},{"location":"tutorials/secure-boot-v2/#step-7","title":"Step 7","text":"<p>Now, we can flash the application by using the <code>idf.py flash</code> command. If you have previously built the application using <code>idf.py build</code>, the application binary has been automatically signed and saved in <code>build</code> directory. For the hello-world example, the file is called <code>hello_world.bin</code>. However, if you previously built the bootloader with <code>idf.py bootloader</code>, you now have to run <code>idf.py build</code> to create and sign the application and the partition table. After that, go ahead and run:</p> <pre><code>idf.py flash\n</code></pre>"},{"location":"tutorials/secure-boot-v2/#step-8","title":"Step 8","text":"<p>Finally, we can execute our application by running:</p> <pre><code>idf.py monitor\n</code></pre> <p>and you will see the output of the application on the terminal. Secure Boot is now enabled and works fine if the output is the expected.</p> <p>It's necessary not to lose your private key. Otherwise, you won't be able to reflash your board with new applications, bootloaders or partition tables.</p>"},{"location":"tutorials/secure-boot-v2/#sign-other-images","title":"Sign other images","text":"<p>Sometimes, we may have some already built binaries but they are unsigned. For example, you may have ran <code>idf.py build</code> to a project which is not configured with the secure boot options. This project contains an unsigned application binary file located in <code>build</code> directory (say, app.bin), as well as an unsigned partition table binary file in <code>build/partition_table/</code> (say, partition-table.bin). Saying that, it is possible to sign these files without having to re-build your application. That is possible with the <code>espsecure.py sign_data</code> command. More specifically, you can run:</p> <pre><code>espsecure.py sign_data --version 2 --keyfile PRIVATE_SIGNING_KEY --output build/app-signed.bin build/app.bin\n</code></pre> <p>to sign your application and</p> <pre><code>espsecure.py sign_data --version 2 --keyfile PRIVATE_SIGNING_KEY --output build/partition_table/partition-table.bin build/partition_table/partition-table-signed.bin\n</code></pre> <p>to sign your partition table.</p> <p>Now, based on the offsets configured on the partition table (say, <code>0x10000</code> for the partition table and <code>0x20000</code> for the factory app), you can use <code>esptool.py</code> to flash the signed binaries:</p> <pre><code>esptool.py --before default_reset --after no_reset write_flash --flash_mode dio --flash_size keep --flash_freq 80m 0x10000 build/partition_table/partition-table-signed.bin 0x20000 build/app-signed.bin\n</code></pre> <p>As before, you may have to configure <code>--chip</code> and <code>--port</code>.</p>"},{"location":"tutorials/secure-boot/","title":"Secure boot v1","text":"<p>We worked on enabling secure boot on devices supporting secure boot v1. The following steps summarize the process:</p>"},{"location":"tutorials/secure-boot/#1-create-a-private-signing-key","title":"1. Create a private signing key","text":"<p><code>espsecure.py generate_signing_key secure_boot_signing_key.pem</code></p> <p>IMPORTANT!!! Make sure to save that key. If the key is lost, the device can't be used again after secure boot is enabled!</p>"},{"location":"tutorials/secure-boot/#2-menuconfig","title":"2. Menuconfig","text":"<ul> <li>Security Features</li> <li>Enable hardware Secure Boot in bootloader</li> <li>Secure bootloader mode (Reflashable)</li> <li>Secure boot private signing key -&gt; Path to key</li> <li>Partition Table</li> <li>Offset -&gt; 0x10000</li> </ul>"},{"location":"tutorials/secure-boot/#3-build-the-bootloader","title":"3. Build the bootloader","text":"<p>Better build in a new directory, so the following command prints instructions</p> <p><code>idf.py -B build-secure bootloader</code></p> <p>This command should print some similar instructions as the following ones:</p> <pre><code>Bootloader built and secure digest generated.\nSecure boot enabled, so bootloader not flashed automatically.\nBurn secure boot key to efuse using:\n    $HOME/.espressif/python_env/idf5.4_py3.8_env/bin/python $HOME/esp-idf/components/esptool_py/esptool/espefuse.py burn_key secure_boot_v1 $HOME/ilias/esp-idf/examples/get-started/hello_world/build-secure/bootloader/secure-bootloader-key-256.bin\nFirst time flash command is:\n    $HOME/.espressif/python_env/idf5.4_py3.8_env/bin/python  $HOME/esp-idf/components/esptool_py/esptool/esptool.py --chip esp32 --before=default_reset --after=no_reset write_flash --flash_mode dio --flash_freq 40m --flash_size 2MB 0x1000 $HOME/esp-idf/examples/get-started/hello_world/build-secure/bootloader/bootloader.bin\n==============================================================================\nTo reflash the bootloader after initial flash:\n    $HOME/.espressif/python_env/idf5.4_py3.8_env/bin/python  $HOME/esp-idf/components/esptool_py/esptool/esptool.py --chip esp32 --before=default_reset --after=no_reset write_flash --flash_mode dio --flash_freq 40m --flash_size 2MB 0x0 $HOME/esp-idf/examples/get-started/hello_world/build-secure/bootloader/bootloader-reflash-digest.bin\n==============================================================================\n</code></pre>"},{"location":"tutorials/secure-boot/#4-burn-the-secure-key-on-the-device-can-only-be-written-once","title":"4. Burn the secure key on the device (Can only be written once)","text":"<p>Using the first provided command, we burn the secure key on the device's eFuse:</p> <pre><code>$HOME/.espressif/python_env/idf5.4_py3.8_env/bin/python $HOME/esp-idf/components/esptool_py/esptool/espefuse.py  burn_key secure_boot_v1 $HOME/esp-idf/examples/get-started/hello_world/build-secure/bootloader/secure-bootloader-key-256.bin\n</code></pre> <p>It will print among others: <code>Type 'BURN' (all capitals) to continue.</code></p>"},{"location":"tutorials/secure-boot/#5-flash-the-bootloader","title":"5. Flash the bootloader","text":"<p>You may add the <code>--port</code> argument</p> <pre><code>$HOME/.espressif/python_env/idf5.4_py3.8_env/bin/python  $HOME/esp-idf/components/esptool_py/esptool/esptool.py --chip esp32 --before=default_reset --after=no_reset write_flash --flash_mode dio --flash_freq 40m --flash_size 2MB 0x1000 $HOME/esp-idf/examples/get-started/hello_world/build-secure/bootloader/bootloader.bin\n</code></pre>"},{"location":"tutorials/secure-boot/#6-build-and-flash-the-app","title":"6. Build and flash the app","text":"<p>It will automatically sign the firmware image</p> <p><code>idf.py -B build-secure flash monitor</code></p> <p>The signed firmware is now running.</p>"},{"location":"tutorials/secure-boot/#7-sign-another-image","title":"7. Sign another image","text":"<p>If we want to sign an already built firmware image, we can do so by using the following command:</p> <pre><code>espsecure.py sign_data --version 1 --keyfile ./my_signing_key.pem --output ./image_signed.bin image-unsigned.bin\n</code></pre>"},{"location":"tutorials/secure-boot/#8-flash-the-signed-image","title":"8. Flash the signed image","text":"<p>Afterwards, we can flash the signed app:</p> <pre><code>export BUILD_DIR=/path/to/build_dir/\n\npython3 $HOME/esp-idf/components/esptool_py/esptool/esptool.py --chip esp32 --before default_reset --after hard_reset write_flash --flash_mode dio --flash_size detect 0x10000 $BUILD_DIR/partition_table/partition-table.bin 0x20000 /path/to/image_signed.bin\n</code></pre>"},{"location":"tutorials/setup/","title":"Basic testbed setup","text":""},{"location":"tutorials/vaccel/","title":"vAccel integration","text":""}]}